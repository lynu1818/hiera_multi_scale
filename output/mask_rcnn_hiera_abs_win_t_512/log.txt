[09/22 10:33:37] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 10:33:38] detectron2 INFO: Environment info:
-------------------------------  ---------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    No: torch.cuda.is_available() == False
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=0, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 10:33:38] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 10:33:38] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 10:33:38] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 10:33:38] d2.utils.env INFO: Using a generated random seed 40073864
[09/22 11:14:11] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 11:14:12] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 11:14:12] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 11:14:12] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 11:14:12] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 11:14:12] d2.utils.env INFO: Using a generated random seed 13906958
[09/22 11:14:13] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 11:14:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 11:14:13] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 11:14:14] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 11:14:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 11:14:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 11:14:14] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 11:14:14] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 11:14:14] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 11:14:14] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 11:18:38] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 11:18:38] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 11:18:38] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 11:18:38] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 11:18:38] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 11:18:38] d2.utils.env INFO: Using a generated random seed 40418785
[09/22 11:18:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 11:18:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 11:18:40] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 11:18:40] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 11:18:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 11:18:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 11:18:40] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 11:18:40] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 11:18:40] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 11:18:41] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:04:31] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:04:32] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:04:32] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:04:32] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:04:32] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:04:32] d2.utils.env INFO: Using a generated random seed 33783839
[09/22 12:04:32] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:04:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:04:33] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:04:33] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:04:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:04:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:04:33] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:04:34] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:04:34] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:04:34] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:07:23] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:07:23] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:07:23] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:07:23] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:07:23] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:07:23] d2.utils.env INFO: Using a generated random seed 25588518
[09/22 12:07:24] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:07:24] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:07:25] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:07:25] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:07:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:07:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:07:25] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:07:25] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:07:25] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:07:26] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:08:38] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:08:39] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:08:39] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:08:39] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:08:39] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:08:39] d2.utils.env INFO: Using a generated random seed 40920142
[09/22 12:08:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:08:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:08:40] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:08:41] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:08:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:08:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:08:41] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:08:41] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:08:41] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:08:41] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:21:49] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:21:50] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:21:50] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:21:50] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:21:50] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:21:50] d2.utils.env INFO: Using a generated random seed 51971546
[09/22 12:21:51] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:21:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:21:51] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:21:52] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:21:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:21:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:21:52] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:21:52] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:21:52] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:21:52] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:46:56] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:46:57] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:46:57] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:46:57] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:46:57] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:46:57] d2.utils.env INFO: Using a generated random seed 58752394
[09/22 12:46:57] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:46:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:46:58] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:46:58] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:46:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:46:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:46:58] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:46:59] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:46:59] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:46:59] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:51:24] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:51:24] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:51:24] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:51:24] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:51:24] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:51:24] d2.utils.env INFO: Using a generated random seed 26475517
[09/22 12:51:25] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:51:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:51:26] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:51:26] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:51:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:51:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:51:26] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:51:26] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:51:26] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:51:27] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:52:08] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:52:09] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:52:09] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:52:09] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:52:09] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:52:09] d2.utils.env INFO: Using a generated random seed 11079500
[09/22 12:52:10] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:52:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:52:10] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:52:11] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:52:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:52:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:52:11] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:52:11] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:52:11] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:52:11] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:54:09] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 12:54:10] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 12:54:10] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 12:54:10] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 12:54:10] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 12:54:10] d2.utils.env INFO: Using a generated random seed 11952167
[09/22 12:54:11] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:54:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 12:54:11] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 12:54:12] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 12:54:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 12:54:12] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 12:54:12] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 12:54:12] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 12:54:12] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 12:54:12] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 12:54:15] d2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0011 s/iter. Inference: 0.2084 s/iter. Eval: 0.0176 s/iter. Total: 0.2271 s/iter. ETA=0:18:52
[09/22 12:54:20] d2.evaluation.evaluator INFO: Inference done 33/5000. Dataloading: 0.0012 s/iter. Inference: 0.2146 s/iter. Eval: 0.0134 s/iter. Total: 0.2292 s/iter. ETA=0:18:58
[09/22 12:54:25] d2.evaluation.evaluator INFO: Inference done 56/5000. Dataloading: 0.0011 s/iter. Inference: 0.2118 s/iter. Eval: 0.0150 s/iter. Total: 0.2280 s/iter. ETA=0:18:47
[09/22 12:54:31] d2.evaluation.evaluator INFO: Inference done 79/5000. Dataloading: 0.0012 s/iter. Inference: 0.2117 s/iter. Eval: 0.0144 s/iter. Total: 0.2273 s/iter. ETA=0:18:38
[09/22 12:54:36] d2.evaluation.evaluator INFO: Inference done 102/5000. Dataloading: 0.0012 s/iter. Inference: 0.2089 s/iter. Eval: 0.0161 s/iter. Total: 0.2262 s/iter. ETA=0:18:27
[09/22 12:54:41] d2.evaluation.evaluator INFO: Inference done 125/5000. Dataloading: 0.0012 s/iter. Inference: 0.2080 s/iter. Eval: 0.0161 s/iter. Total: 0.2252 s/iter. ETA=0:18:18
[09/22 12:54:46] d2.evaluation.evaluator INFO: Inference done 147/5000. Dataloading: 0.0012 s/iter. Inference: 0.2094 s/iter. Eval: 0.0164 s/iter. Total: 0.2270 s/iter. ETA=0:18:21
[09/22 12:54:51] d2.evaluation.evaluator INFO: Inference done 170/5000. Dataloading: 0.0012 s/iter. Inference: 0.2089 s/iter. Eval: 0.0165 s/iter. Total: 0.2265 s/iter. ETA=0:18:14
[09/22 12:54:56] d2.evaluation.evaluator INFO: Inference done 192/5000. Dataloading: 0.0012 s/iter. Inference: 0.2090 s/iter. Eval: 0.0167 s/iter. Total: 0.2269 s/iter. ETA=0:18:11
[09/22 12:55:01] d2.evaluation.evaluator INFO: Inference done 216/5000. Dataloading: 0.0012 s/iter. Inference: 0.2081 s/iter. Eval: 0.0162 s/iter. Total: 0.2255 s/iter. ETA=0:17:58
[09/22 12:55:06] d2.evaluation.evaluator INFO: Inference done 239/5000. Dataloading: 0.0012 s/iter. Inference: 0.2080 s/iter. Eval: 0.0161 s/iter. Total: 0.2253 s/iter. ETA=0:17:52
[09/22 12:55:12] d2.evaluation.evaluator INFO: Inference done 261/5000. Dataloading: 0.0012 s/iter. Inference: 0.2088 s/iter. Eval: 0.0162 s/iter. Total: 0.2262 s/iter. ETA=0:17:51
[09/22 12:55:17] d2.evaluation.evaluator INFO: Inference done 285/5000. Dataloading: 0.0012 s/iter. Inference: 0.2080 s/iter. Eval: 0.0160 s/iter. Total: 0.2252 s/iter. ETA=0:17:41
[09/22 12:55:22] d2.evaluation.evaluator INFO: Inference done 307/5000. Dataloading: 0.0012 s/iter. Inference: 0.2084 s/iter. Eval: 0.0161 s/iter. Total: 0.2256 s/iter. ETA=0:17:38
[09/22 12:55:27] d2.evaluation.evaluator INFO: Inference done 329/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0162 s/iter. Total: 0.2259 s/iter. ETA=0:17:35
[09/22 12:55:32] d2.evaluation.evaluator INFO: Inference done 351/5000. Dataloading: 0.0012 s/iter. Inference: 0.2090 s/iter. Eval: 0.0163 s/iter. Total: 0.2265 s/iter. ETA=0:17:32
[09/22 12:55:37] d2.evaluation.evaluator INFO: Inference done 373/5000. Dataloading: 0.0012 s/iter. Inference: 0.2094 s/iter. Eval: 0.0164 s/iter. Total: 0.2270 s/iter. ETA=0:17:30
[09/22 12:55:42] d2.evaluation.evaluator INFO: Inference done 397/5000. Dataloading: 0.0012 s/iter. Inference: 0.2087 s/iter. Eval: 0.0161 s/iter. Total: 0.2260 s/iter. ETA=0:17:20
[09/22 12:55:47] d2.evaluation.evaluator INFO: Inference done 420/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0159 s/iter. Total: 0.2256 s/iter. ETA=0:17:13
[09/22 12:55:52] d2.evaluation.evaluator INFO: Inference done 443/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0157 s/iter. Total: 0.2253 s/iter. ETA=0:17:06
[09/22 12:55:58] d2.evaluation.evaluator INFO: Inference done 466/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0155 s/iter. Total: 0.2252 s/iter. ETA=0:17:01
[09/22 12:56:03] d2.evaluation.evaluator INFO: Inference done 488/5000. Dataloading: 0.0012 s/iter. Inference: 0.2089 s/iter. Eval: 0.0155 s/iter. Total: 0.2256 s/iter. ETA=0:16:58
[09/22 12:56:08] d2.evaluation.evaluator INFO: Inference done 511/5000. Dataloading: 0.0012 s/iter. Inference: 0.2087 s/iter. Eval: 0.0157 s/iter. Total: 0.2256 s/iter. ETA=0:16:52
[09/22 12:56:13] d2.evaluation.evaluator INFO: Inference done 534/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0157 s/iter. Total: 0.2255 s/iter. ETA=0:16:47
[09/22 12:56:18] d2.evaluation.evaluator INFO: Inference done 556/5000. Dataloading: 0.0012 s/iter. Inference: 0.2087 s/iter. Eval: 0.0159 s/iter. Total: 0.2257 s/iter. ETA=0:16:43
[09/22 12:56:23] d2.evaluation.evaluator INFO: Inference done 578/5000. Dataloading: 0.0012 s/iter. Inference: 0.2088 s/iter. Eval: 0.0159 s/iter. Total: 0.2260 s/iter. ETA=0:16:39
[09/22 12:56:28] d2.evaluation.evaluator INFO: Inference done 602/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0159 s/iter. Total: 0.2256 s/iter. ETA=0:16:32
[09/22 12:56:34] d2.evaluation.evaluator INFO: Inference done 624/5000. Dataloading: 0.0012 s/iter. Inference: 0.2088 s/iter. Eval: 0.0159 s/iter. Total: 0.2259 s/iter. ETA=0:16:28
[09/22 12:56:39] d2.evaluation.evaluator INFO: Inference done 646/5000. Dataloading: 0.0012 s/iter. Inference: 0.2089 s/iter. Eval: 0.0160 s/iter. Total: 0.2261 s/iter. ETA=0:16:24
[09/22 12:56:44] d2.evaluation.evaluator INFO: Inference done 668/5000. Dataloading: 0.0012 s/iter. Inference: 0.2089 s/iter. Eval: 0.0162 s/iter. Total: 0.2263 s/iter. ETA=0:16:20
[09/22 12:56:49] d2.evaluation.evaluator INFO: Inference done 691/5000. Dataloading: 0.0012 s/iter. Inference: 0.2091 s/iter. Eval: 0.0160 s/iter. Total: 0.2263 s/iter. ETA=0:16:14
[09/22 12:56:54] d2.evaluation.evaluator INFO: Inference done 713/5000. Dataloading: 0.0012 s/iter. Inference: 0.2094 s/iter. Eval: 0.0159 s/iter. Total: 0.2265 s/iter. ETA=0:16:11
[09/22 12:56:59] d2.evaluation.evaluator INFO: Inference done 735/5000. Dataloading: 0.0012 s/iter. Inference: 0.2095 s/iter. Eval: 0.0161 s/iter. Total: 0.2268 s/iter. ETA=0:16:07
[09/22 12:57:04] d2.evaluation.evaluator INFO: Inference done 757/5000. Dataloading: 0.0012 s/iter. Inference: 0.2096 s/iter. Eval: 0.0160 s/iter. Total: 0.2268 s/iter. ETA=0:16:02
[09/22 12:57:10] d2.evaluation.evaluator INFO: Inference done 780/5000. Dataloading: 0.0012 s/iter. Inference: 0.2097 s/iter. Eval: 0.0159 s/iter. Total: 0.2269 s/iter. ETA=0:15:57
[09/22 12:57:15] d2.evaluation.evaluator INFO: Inference done 801/5000. Dataloading: 0.0012 s/iter. Inference: 0.2099 s/iter. Eval: 0.0160 s/iter. Total: 0.2272 s/iter. ETA=0:15:53
[09/22 12:57:20] d2.evaluation.evaluator INFO: Inference done 824/5000. Dataloading: 0.0012 s/iter. Inference: 0.2100 s/iter. Eval: 0.0158 s/iter. Total: 0.2271 s/iter. ETA=0:15:48
[09/22 12:57:25] d2.evaluation.evaluator INFO: Inference done 846/5000. Dataloading: 0.0012 s/iter. Inference: 0.2102 s/iter. Eval: 0.0159 s/iter. Total: 0.2273 s/iter. ETA=0:15:44
[09/22 12:57:30] d2.evaluation.evaluator INFO: Inference done 868/5000. Dataloading: 0.0012 s/iter. Inference: 0.2103 s/iter. Eval: 0.0158 s/iter. Total: 0.2274 s/iter. ETA=0:15:39
[09/22 12:57:35] d2.evaluation.evaluator INFO: Inference done 890/5000. Dataloading: 0.0012 s/iter. Inference: 0.2104 s/iter. Eval: 0.0158 s/iter. Total: 0.2274 s/iter. ETA=0:15:34
[09/22 12:57:40] d2.evaluation.evaluator INFO: Inference done 912/5000. Dataloading: 0.0012 s/iter. Inference: 0.2103 s/iter. Eval: 0.0160 s/iter. Total: 0.2275 s/iter. ETA=0:15:30
[09/22 12:57:45] d2.evaluation.evaluator INFO: Inference done 934/5000. Dataloading: 0.0012 s/iter. Inference: 0.2104 s/iter. Eval: 0.0159 s/iter. Total: 0.2276 s/iter. ETA=0:15:25
[09/22 12:57:50] d2.evaluation.evaluator INFO: Inference done 956/5000. Dataloading: 0.0012 s/iter. Inference: 0.2105 s/iter. Eval: 0.0159 s/iter. Total: 0.2276 s/iter. ETA=0:15:20
[09/22 12:57:55] d2.evaluation.evaluator INFO: Inference done 978/5000. Dataloading: 0.0012 s/iter. Inference: 0.2106 s/iter. Eval: 0.0160 s/iter. Total: 0.2278 s/iter. ETA=0:15:16
[09/22 12:58:01] d2.evaluation.evaluator INFO: Inference done 1001/5000. Dataloading: 0.0012 s/iter. Inference: 0.2107 s/iter. Eval: 0.0159 s/iter. Total: 0.2278 s/iter. ETA=0:15:10
[09/22 12:58:06] d2.evaluation.evaluator INFO: Inference done 1023/5000. Dataloading: 0.0012 s/iter. Inference: 0.2107 s/iter. Eval: 0.0160 s/iter. Total: 0.2279 s/iter. ETA=0:15:06
[09/22 12:58:11] d2.evaluation.evaluator INFO: Inference done 1045/5000. Dataloading: 0.0012 s/iter. Inference: 0.2108 s/iter. Eval: 0.0160 s/iter. Total: 0.2280 s/iter. ETA=0:15:01
[09/22 12:58:16] d2.evaluation.evaluator INFO: Inference done 1067/5000. Dataloading: 0.0012 s/iter. Inference: 0.2110 s/iter. Eval: 0.0160 s/iter. Total: 0.2282 s/iter. ETA=0:14:57
[09/22 12:58:21] d2.evaluation.evaluator INFO: Inference done 1088/5000. Dataloading: 0.0012 s/iter. Inference: 0.2112 s/iter. Eval: 0.0160 s/iter. Total: 0.2284 s/iter. ETA=0:14:53
[09/22 12:58:26] d2.evaluation.evaluator INFO: Inference done 1110/5000. Dataloading: 0.0012 s/iter. Inference: 0.2113 s/iter. Eval: 0.0159 s/iter. Total: 0.2285 s/iter. ETA=0:14:48
[09/22 12:58:31] d2.evaluation.evaluator INFO: Inference done 1132/5000. Dataloading: 0.0012 s/iter. Inference: 0.2114 s/iter. Eval: 0.0159 s/iter. Total: 0.2286 s/iter. ETA=0:14:44
[09/22 12:58:36] d2.evaluation.evaluator INFO: Inference done 1154/5000. Dataloading: 0.0012 s/iter. Inference: 0.2115 s/iter. Eval: 0.0159 s/iter. Total: 0.2286 s/iter. ETA=0:14:39
[09/22 12:58:42] d2.evaluation.evaluator INFO: Inference done 1175/5000. Dataloading: 0.0012 s/iter. Inference: 0.2118 s/iter. Eval: 0.0159 s/iter. Total: 0.2289 s/iter. ETA=0:14:35
[09/22 12:58:47] d2.evaluation.evaluator INFO: Inference done 1197/5000. Dataloading: 0.0012 s/iter. Inference: 0.2119 s/iter. Eval: 0.0159 s/iter. Total: 0.2290 s/iter. ETA=0:14:30
[09/22 12:58:52] d2.evaluation.evaluator INFO: Inference done 1218/5000. Dataloading: 0.0012 s/iter. Inference: 0.2120 s/iter. Eval: 0.0160 s/iter. Total: 0.2292 s/iter. ETA=0:14:27
[09/22 12:58:57] d2.evaluation.evaluator INFO: Inference done 1240/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2294 s/iter. ETA=0:14:22
[09/22 12:59:02] d2.evaluation.evaluator INFO: Inference done 1262/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0161 s/iter. Total: 0.2295 s/iter. ETA=0:14:17
[09/22 12:59:07] d2.evaluation.evaluator INFO: Inference done 1284/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0161 s/iter. Total: 0.2296 s/iter. ETA=0:14:13
[09/22 12:59:12] d2.evaluation.evaluator INFO: Inference done 1307/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0161 s/iter. Total: 0.2294 s/iter. ETA=0:14:07
[09/22 12:59:18] d2.evaluation.evaluator INFO: Inference done 1330/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2293 s/iter. ETA=0:14:01
[09/22 12:59:23] d2.evaluation.evaluator INFO: Inference done 1351/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0161 s/iter. Total: 0.2295 s/iter. ETA=0:13:57
[09/22 12:59:28] d2.evaluation.evaluator INFO: Inference done 1373/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0161 s/iter. Total: 0.2295 s/iter. ETA=0:13:52
[09/22 12:59:33] d2.evaluation.evaluator INFO: Inference done 1395/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0161 s/iter. Total: 0.2296 s/iter. ETA=0:13:47
[09/22 12:59:38] d2.evaluation.evaluator INFO: Inference done 1418/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2294 s/iter. ETA=0:13:41
[09/22 12:59:43] d2.evaluation.evaluator INFO: Inference done 1440/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0160 s/iter. Total: 0.2294 s/iter. ETA=0:13:36
[09/22 12:59:48] d2.evaluation.evaluator INFO: Inference done 1463/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2293 s/iter. ETA=0:13:30
[09/22 12:59:53] d2.evaluation.evaluator INFO: Inference done 1485/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2293 s/iter. ETA=0:13:25
[09/22 12:59:58] d2.evaluation.evaluator INFO: Inference done 1508/5000. Dataloading: 0.0012 s/iter. Inference: 0.2120 s/iter. Eval: 0.0160 s/iter. Total: 0.2292 s/iter. ETA=0:13:20
[09/22 13:00:03] d2.evaluation.evaluator INFO: Inference done 1531/5000. Dataloading: 0.0012 s/iter. Inference: 0.2119 s/iter. Eval: 0.0160 s/iter. Total: 0.2291 s/iter. ETA=0:13:14
[09/22 13:00:09] d2.evaluation.evaluator INFO: Inference done 1552/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2294 s/iter. ETA=0:13:10
[09/22 13:00:14] d2.evaluation.evaluator INFO: Inference done 1574/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0160 s/iter. Total: 0.2294 s/iter. ETA=0:13:05
[09/22 13:00:19] d2.evaluation.evaluator INFO: Inference done 1595/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0161 s/iter. Total: 0.2296 s/iter. ETA=0:13:01
[09/22 13:00:24] d2.evaluation.evaluator INFO: Inference done 1617/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0161 s/iter. Total: 0.2297 s/iter. ETA=0:12:56
[09/22 13:00:29] d2.evaluation.evaluator INFO: Inference done 1639/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0161 s/iter. Total: 0.2297 s/iter. ETA=0:12:51
[09/22 13:00:34] d2.evaluation.evaluator INFO: Inference done 1661/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0161 s/iter. Total: 0.2296 s/iter. ETA=0:12:46
[09/22 13:00:39] d2.evaluation.evaluator INFO: Inference done 1684/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0161 s/iter. Total: 0.2296 s/iter. ETA=0:12:41
[09/22 13:00:44] d2.evaluation.evaluator INFO: Inference done 1706/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0161 s/iter. Total: 0.2297 s/iter. ETA=0:12:36
[09/22 13:00:49] d2.evaluation.evaluator INFO: Inference done 1727/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0161 s/iter. Total: 0.2298 s/iter. ETA=0:12:32
[09/22 13:00:55] d2.evaluation.evaluator INFO: Inference done 1750/5000. Dataloading: 0.0012 s/iter. Inference: 0.2125 s/iter. Eval: 0.0160 s/iter. Total: 0.2297 s/iter. ETA=0:12:26
[09/22 13:01:00] d2.evaluation.evaluator INFO: Inference done 1773/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0160 s/iter. Total: 0.2296 s/iter. ETA=0:12:20
[09/22 13:01:05] d2.evaluation.evaluator INFO: Inference done 1796/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0159 s/iter. Total: 0.2295 s/iter. ETA=0:12:15
[09/22 13:01:10] d2.evaluation.evaluator INFO: Inference done 1818/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0160 s/iter. Total: 0.2296 s/iter. ETA=0:12:10
[09/22 13:01:15] d2.evaluation.evaluator INFO: Inference done 1840/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0160 s/iter. Total: 0.2296 s/iter. ETA=0:12:05
[09/22 13:01:20] d2.evaluation.evaluator INFO: Inference done 1862/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0160 s/iter. Total: 0.2296 s/iter. ETA=0:12:00
[09/22 13:01:25] d2.evaluation.evaluator INFO: Inference done 1884/5000. Dataloading: 0.0012 s/iter. Inference: 0.2125 s/iter. Eval: 0.0160 s/iter. Total: 0.2297 s/iter. ETA=0:11:55
[09/22 13:01:30] d2.evaluation.evaluator INFO: Inference done 1906/5000. Dataloading: 0.0012 s/iter. Inference: 0.2125 s/iter. Eval: 0.0160 s/iter. Total: 0.2297 s/iter. ETA=0:11:50
[09/22 13:01:36] d2.evaluation.evaluator INFO: Inference done 1928/5000. Dataloading: 0.0012 s/iter. Inference: 0.2126 s/iter. Eval: 0.0159 s/iter. Total: 0.2297 s/iter. ETA=0:11:45
[09/22 13:01:41] d2.evaluation.evaluator INFO: Inference done 1951/5000. Dataloading: 0.0012 s/iter. Inference: 0.2125 s/iter. Eval: 0.0159 s/iter. Total: 0.2297 s/iter. ETA=0:11:40
[09/22 13:01:46] d2.evaluation.evaluator INFO: Inference done 1973/5000. Dataloading: 0.0012 s/iter. Inference: 0.2126 s/iter. Eval: 0.0159 s/iter. Total: 0.2297 s/iter. ETA=0:11:35
[09/22 13:01:51] d2.evaluation.evaluator INFO: Inference done 1995/5000. Dataloading: 0.0012 s/iter. Inference: 0.2126 s/iter. Eval: 0.0160 s/iter. Total: 0.2298 s/iter. ETA=0:11:30
[09/22 13:01:56] d2.evaluation.evaluator INFO: Inference done 2016/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0160 s/iter. Total: 0.2299 s/iter. ETA=0:11:26
[09/22 13:02:01] d2.evaluation.evaluator INFO: Inference done 2037/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0160 s/iter. Total: 0.2300 s/iter. ETA=0:11:21
[09/22 13:02:06] d2.evaluation.evaluator INFO: Inference done 2060/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0160 s/iter. Total: 0.2300 s/iter. ETA=0:11:16
[09/22 13:02:12] d2.evaluation.evaluator INFO: Inference done 2083/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0160 s/iter. Total: 0.2299 s/iter. ETA=0:11:10
[09/22 13:02:17] d2.evaluation.evaluator INFO: Inference done 2105/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0160 s/iter. Total: 0.2300 s/iter. ETA=0:11:05
[09/22 13:02:22] d2.evaluation.evaluator INFO: Inference done 2128/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0159 s/iter. Total: 0.2299 s/iter. ETA=0:11:00
[09/22 13:02:27] d2.evaluation.evaluator INFO: Inference done 2150/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0160 s/iter. Total: 0.2299 s/iter. ETA=0:10:55
[09/22 13:02:32] d2.evaluation.evaluator INFO: Inference done 2172/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0160 s/iter. Total: 0.2299 s/iter. ETA=0:10:50
[09/22 13:02:37] d2.evaluation.evaluator INFO: Inference done 2195/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0159 s/iter. Total: 0.2299 s/iter. ETA=0:10:44
[09/22 13:02:42] d2.evaluation.evaluator INFO: Inference done 2217/5000. Dataloading: 0.0012 s/iter. Inference: 0.2127 s/iter. Eval: 0.0160 s/iter. Total: 0.2299 s/iter. ETA=0:10:39
[09/22 13:02:48] d2.evaluation.evaluator INFO: Inference done 2239/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0160 s/iter. Total: 0.2300 s/iter. ETA=0:10:35
[09/22 13:02:53] d2.evaluation.evaluator INFO: Inference done 2260/5000. Dataloading: 0.0012 s/iter. Inference: 0.2130 s/iter. Eval: 0.0160 s/iter. Total: 0.2302 s/iter. ETA=0:10:30
[09/22 13:02:58] d2.evaluation.evaluator INFO: Inference done 2282/5000. Dataloading: 0.0012 s/iter. Inference: 0.2130 s/iter. Eval: 0.0159 s/iter. Total: 0.2301 s/iter. ETA=0:10:25
[09/22 13:03:03] d2.evaluation.evaluator INFO: Inference done 2305/5000. Dataloading: 0.0012 s/iter. Inference: 0.2129 s/iter. Eval: 0.0159 s/iter. Total: 0.2301 s/iter. ETA=0:10:20
[09/22 13:03:08] d2.evaluation.evaluator INFO: Inference done 2327/5000. Dataloading: 0.0012 s/iter. Inference: 0.2129 s/iter. Eval: 0.0159 s/iter. Total: 0.2300 s/iter. ETA=0:10:14
[09/22 13:03:13] d2.evaluation.evaluator INFO: Inference done 2350/5000. Dataloading: 0.0012 s/iter. Inference: 0.2130 s/iter. Eval: 0.0158 s/iter. Total: 0.2300 s/iter. ETA=0:10:09
[09/22 13:03:18] d2.evaluation.evaluator INFO: Inference done 2372/5000. Dataloading: 0.0012 s/iter. Inference: 0.2130 s/iter. Eval: 0.0158 s/iter. Total: 0.2300 s/iter. ETA=0:10:04
[09/22 13:03:23] d2.evaluation.evaluator INFO: Inference done 2394/5000. Dataloading: 0.0012 s/iter. Inference: 0.2130 s/iter. Eval: 0.0158 s/iter. Total: 0.2300 s/iter. ETA=0:09:59
[09/22 13:03:28] d2.evaluation.evaluator INFO: Inference done 2415/5000. Dataloading: 0.0012 s/iter. Inference: 0.2130 s/iter. Eval: 0.0159 s/iter. Total: 0.2301 s/iter. ETA=0:09:54
[09/22 13:03:34] d2.evaluation.evaluator INFO: Inference done 2436/5000. Dataloading: 0.0012 s/iter. Inference: 0.2131 s/iter. Eval: 0.0159 s/iter. Total: 0.2303 s/iter. ETA=0:09:50
[09/22 13:03:39] d2.evaluation.evaluator INFO: Inference done 2457/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0159 s/iter. Total: 0.2304 s/iter. ETA=0:09:45
[09/22 13:03:44] d2.evaluation.evaluator INFO: Inference done 2480/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0159 s/iter. Total: 0.2303 s/iter. ETA=0:09:40
[09/22 13:03:49] d2.evaluation.evaluator INFO: Inference done 2503/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0159 s/iter. Total: 0.2303 s/iter. ETA=0:09:34
[09/22 13:03:54] d2.evaluation.evaluator INFO: Inference done 2524/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0159 s/iter. Total: 0.2303 s/iter. ETA=0:09:30
[09/22 13:03:59] d2.evaluation.evaluator INFO: Inference done 2547/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0159 s/iter. Total: 0.2303 s/iter. ETA=0:09:24
[09/22 13:04:04] d2.evaluation.evaluator INFO: Inference done 2569/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0160 s/iter. Total: 0.2304 s/iter. ETA=0:09:20
[09/22 13:04:10] d2.evaluation.evaluator INFO: Inference done 2592/5000. Dataloading: 0.0012 s/iter. Inference: 0.2131 s/iter. Eval: 0.0160 s/iter. Total: 0.2304 s/iter. ETA=0:09:14
[09/22 13:04:15] d2.evaluation.evaluator INFO: Inference done 2614/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0160 s/iter. Total: 0.2304 s/iter. ETA=0:09:09
[09/22 13:04:20] d2.evaluation.evaluator INFO: Inference done 2635/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0160 s/iter. Total: 0.2305 s/iter. ETA=0:09:05
[09/22 13:04:25] d2.evaluation.evaluator INFO: Inference done 2657/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0160 s/iter. Total: 0.2306 s/iter. ETA=0:09:00
[09/22 13:04:30] d2.evaluation.evaluator INFO: Inference done 2679/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0160 s/iter. Total: 0.2306 s/iter. ETA=0:08:55
[09/22 13:04:35] d2.evaluation.evaluator INFO: Inference done 2701/5000. Dataloading: 0.0012 s/iter. Inference: 0.2134 s/iter. Eval: 0.0159 s/iter. Total: 0.2305 s/iter. ETA=0:08:50
[09/22 13:04:40] d2.evaluation.evaluator INFO: Inference done 2723/5000. Dataloading: 0.0012 s/iter. Inference: 0.2134 s/iter. Eval: 0.0159 s/iter. Total: 0.2306 s/iter. ETA=0:08:44
[09/22 13:04:46] d2.evaluation.evaluator INFO: Inference done 2746/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0159 s/iter. Total: 0.2305 s/iter. ETA=0:08:39
[09/22 13:04:51] d2.evaluation.evaluator INFO: Inference done 2768/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0159 s/iter. Total: 0.2305 s/iter. ETA=0:08:34
[09/22 13:04:56] d2.evaluation.evaluator INFO: Inference done 2790/5000. Dataloading: 0.0012 s/iter. Inference: 0.2134 s/iter. Eval: 0.0159 s/iter. Total: 0.2305 s/iter. ETA=0:08:29
[09/22 13:05:01] d2.evaluation.evaluator INFO: Inference done 2812/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0159 s/iter. Total: 0.2305 s/iter. ETA=0:08:24
[09/22 13:05:06] d2.evaluation.evaluator INFO: Inference done 2834/5000. Dataloading: 0.0012 s/iter. Inference: 0.2134 s/iter. Eval: 0.0159 s/iter. Total: 0.2305 s/iter. ETA=0:08:19
[09/22 13:05:11] d2.evaluation.evaluator INFO: Inference done 2856/5000. Dataloading: 0.0012 s/iter. Inference: 0.2134 s/iter. Eval: 0.0159 s/iter. Total: 0.2306 s/iter. ETA=0:08:14
[09/22 13:05:16] d2.evaluation.evaluator INFO: Inference done 2878/5000. Dataloading: 0.0012 s/iter. Inference: 0.2134 s/iter. Eval: 0.0159 s/iter. Total: 0.2306 s/iter. ETA=0:08:09
[09/22 13:05:21] d2.evaluation.evaluator INFO: Inference done 2899/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2307 s/iter. ETA=0:08:04
[09/22 13:05:26] d2.evaluation.evaluator INFO: Inference done 2921/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2307 s/iter. ETA=0:07:59
[09/22 13:05:31] d2.evaluation.evaluator INFO: Inference done 2943/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2307 s/iter. ETA=0:07:54
[09/22 13:05:37] d2.evaluation.evaluator INFO: Inference done 2966/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2306 s/iter. ETA=0:07:49
[09/22 13:05:42] d2.evaluation.evaluator INFO: Inference done 2988/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2306 s/iter. ETA=0:07:44
[09/22 13:05:47] d2.evaluation.evaluator INFO: Inference done 3011/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2306 s/iter. ETA=0:07:38
[09/22 13:05:52] d2.evaluation.evaluator INFO: Inference done 3032/5000. Dataloading: 0.0012 s/iter. Inference: 0.2135 s/iter. Eval: 0.0159 s/iter. Total: 0.2307 s/iter. ETA=0:07:33
[09/22 13:05:57] d2.evaluation.evaluator INFO: Inference done 3054/5000. Dataloading: 0.0012 s/iter. Inference: 0.2136 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:07:28
[09/22 13:06:02] d2.evaluation.evaluator INFO: Inference done 3076/5000. Dataloading: 0.0012 s/iter. Inference: 0.2136 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:07:23
[09/22 13:06:07] d2.evaluation.evaluator INFO: Inference done 3098/5000. Dataloading: 0.0012 s/iter. Inference: 0.2136 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:07:18
[09/22 13:06:12] d2.evaluation.evaluator INFO: Inference done 3120/5000. Dataloading: 0.0012 s/iter. Inference: 0.2136 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:07:13
[09/22 13:06:17] d2.evaluation.evaluator INFO: Inference done 3141/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:07:08
[09/22 13:06:22] d2.evaluation.evaluator INFO: Inference done 3163/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:07:03
[09/22 13:06:27] d2.evaluation.evaluator INFO: Inference done 3185/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:06:58
[09/22 13:06:33] d2.evaluation.evaluator INFO: Inference done 3207/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0158 s/iter. Total: 0.2307 s/iter. ETA=0:06:53
[09/22 13:06:38] d2.evaluation.evaluator INFO: Inference done 3229/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0158 s/iter. Total: 0.2308 s/iter. ETA=0:06:48
[09/22 13:06:43] d2.evaluation.evaluator INFO: Inference done 3251/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0158 s/iter. Total: 0.2308 s/iter. ETA=0:06:43
[09/22 13:06:48] d2.evaluation.evaluator INFO: Inference done 3272/5000. Dataloading: 0.0012 s/iter. Inference: 0.2137 s/iter. Eval: 0.0159 s/iter. Total: 0.2308 s/iter. ETA=0:06:38
[09/22 13:06:53] d2.evaluation.evaluator INFO: Inference done 3293/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:06:34
[09/22 13:06:58] d2.evaluation.evaluator INFO: Inference done 3315/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:06:29
[09/22 13:07:03] d2.evaluation.evaluator INFO: Inference done 3337/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:06:24
[09/22 13:07:08] d2.evaluation.evaluator INFO: Inference done 3359/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:06:19
[09/22 13:07:14] d2.evaluation.evaluator INFO: Inference done 3381/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:06:14
[09/22 13:07:19] d2.evaluation.evaluator INFO: Inference done 3403/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0160 s/iter. Total: 0.2310 s/iter. ETA=0:06:08
[09/22 13:07:24] d2.evaluation.evaluator INFO: Inference done 3425/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0160 s/iter. Total: 0.2310 s/iter. ETA=0:06:03
[09/22 13:07:29] d2.evaluation.evaluator INFO: Inference done 3446/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0160 s/iter. Total: 0.2311 s/iter. ETA=0:05:59
[09/22 13:07:34] d2.evaluation.evaluator INFO: Inference done 3468/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0160 s/iter. Total: 0.2311 s/iter. ETA=0:05:54
[09/22 13:07:39] d2.evaluation.evaluator INFO: Inference done 3491/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:48
[09/22 13:07:44] d2.evaluation.evaluator INFO: Inference done 3513/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:43
[09/22 13:07:49] d2.evaluation.evaluator INFO: Inference done 3536/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:38
[09/22 13:07:54] d2.evaluation.evaluator INFO: Inference done 3558/5000. Dataloading: 0.0012 s/iter. Inference: 0.2138 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:33
[09/22 13:08:00] d2.evaluation.evaluator INFO: Inference done 3580/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:28
[09/22 13:08:05] d2.evaluation.evaluator INFO: Inference done 3602/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:22
[09/22 13:08:10] d2.evaluation.evaluator INFO: Inference done 3624/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2310 s/iter. ETA=0:05:17
[09/22 13:08:15] d2.evaluation.evaluator INFO: Inference done 3646/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:05:12
[09/22 13:08:20] d2.evaluation.evaluator INFO: Inference done 3668/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:05:07
[09/22 13:08:25] d2.evaluation.evaluator INFO: Inference done 3690/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:05:02
[09/22 13:08:31] d2.evaluation.evaluator INFO: Inference done 3712/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:04:57
[09/22 13:08:36] d2.evaluation.evaluator INFO: Inference done 3734/5000. Dataloading: 0.0012 s/iter. Inference: 0.2140 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:04:52
[09/22 13:08:41] d2.evaluation.evaluator INFO: Inference done 3756/5000. Dataloading: 0.0012 s/iter. Inference: 0.2140 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:04:47
[09/22 13:08:46] d2.evaluation.evaluator INFO: Inference done 3778/5000. Dataloading: 0.0012 s/iter. Inference: 0.2140 s/iter. Eval: 0.0159 s/iter. Total: 0.2311 s/iter. ETA=0:04:42
[09/22 13:08:51] d2.evaluation.evaluator INFO: Inference done 3800/5000. Dataloading: 0.0012 s/iter. Inference: 0.2140 s/iter. Eval: 0.0159 s/iter. Total: 0.2312 s/iter. ETA=0:04:37
[09/22 13:10:23] d2.evaluation.evaluator INFO: Inference done 3811/5000. Dataloading: 0.0012 s/iter. Inference: 0.2376 s/iter. Eval: 0.0159 s/iter. Total: 0.2547 s/iter. ETA=0:05:02
[09/22 13:10:28] d2.evaluation.evaluator INFO: Inference done 3834/5000. Dataloading: 0.0012 s/iter. Inference: 0.2374 s/iter. Eval: 0.0159 s/iter. Total: 0.2545 s/iter. ETA=0:04:56
[09/22 13:10:33] d2.evaluation.evaluator INFO: Inference done 3857/5000. Dataloading: 0.0012 s/iter. Inference: 0.2372 s/iter. Eval: 0.0159 s/iter. Total: 0.2543 s/iter. ETA=0:04:50
[09/22 13:10:38] d2.evaluation.evaluator INFO: Inference done 3880/5000. Dataloading: 0.0012 s/iter. Inference: 0.2370 s/iter. Eval: 0.0159 s/iter. Total: 0.2541 s/iter. ETA=0:04:44
[09/22 13:10:44] d2.evaluation.evaluator INFO: Inference done 3904/5000. Dataloading: 0.0012 s/iter. Inference: 0.2367 s/iter. Eval: 0.0158 s/iter. Total: 0.2538 s/iter. ETA=0:04:38
[09/22 13:10:49] d2.evaluation.evaluator INFO: Inference done 3927/5000. Dataloading: 0.0012 s/iter. Inference: 0.2365 s/iter. Eval: 0.0158 s/iter. Total: 0.2536 s/iter. ETA=0:04:32
[09/22 13:10:54] d2.evaluation.evaluator INFO: Inference done 3951/5000. Dataloading: 0.0012 s/iter. Inference: 0.2363 s/iter. Eval: 0.0158 s/iter. Total: 0.2534 s/iter. ETA=0:04:25
[09/22 13:10:59] d2.evaluation.evaluator INFO: Inference done 3974/5000. Dataloading: 0.0012 s/iter. Inference: 0.2361 s/iter. Eval: 0.0158 s/iter. Total: 0.2532 s/iter. ETA=0:04:19
[09/22 13:11:04] d2.evaluation.evaluator INFO: Inference done 3998/5000. Dataloading: 0.0012 s/iter. Inference: 0.2359 s/iter. Eval: 0.0158 s/iter. Total: 0.2530 s/iter. ETA=0:04:13
[09/22 13:11:09] d2.evaluation.evaluator INFO: Inference done 4021/5000. Dataloading: 0.0012 s/iter. Inference: 0.2357 s/iter. Eval: 0.0159 s/iter. Total: 0.2528 s/iter. ETA=0:04:07
[09/22 13:11:14] d2.evaluation.evaluator INFO: Inference done 4043/5000. Dataloading: 0.0012 s/iter. Inference: 0.2356 s/iter. Eval: 0.0159 s/iter. Total: 0.2527 s/iter. ETA=0:04:01
[09/22 13:11:19] d2.evaluation.evaluator INFO: Inference done 4066/5000. Dataloading: 0.0012 s/iter. Inference: 0.2354 s/iter. Eval: 0.0159 s/iter. Total: 0.2526 s/iter. ETA=0:03:55
[09/22 13:11:25] d2.evaluation.evaluator INFO: Inference done 4088/5000. Dataloading: 0.0012 s/iter. Inference: 0.2353 s/iter. Eval: 0.0159 s/iter. Total: 0.2525 s/iter. ETA=0:03:50
[09/22 13:11:30] d2.evaluation.evaluator INFO: Inference done 4110/5000. Dataloading: 0.0012 s/iter. Inference: 0.2352 s/iter. Eval: 0.0159 s/iter. Total: 0.2523 s/iter. ETA=0:03:44
[09/22 13:11:35] d2.evaluation.evaluator INFO: Inference done 4132/5000. Dataloading: 0.0012 s/iter. Inference: 0.2351 s/iter. Eval: 0.0159 s/iter. Total: 0.2522 s/iter. ETA=0:03:38
[09/22 13:11:40] d2.evaluation.evaluator INFO: Inference done 4155/5000. Dataloading: 0.0012 s/iter. Inference: 0.2349 s/iter. Eval: 0.0159 s/iter. Total: 0.2521 s/iter. ETA=0:03:33
[09/22 13:11:45] d2.evaluation.evaluator INFO: Inference done 4177/5000. Dataloading: 0.0012 s/iter. Inference: 0.2348 s/iter. Eval: 0.0159 s/iter. Total: 0.2520 s/iter. ETA=0:03:27
[09/22 13:11:50] d2.evaluation.evaluator INFO: Inference done 4200/5000. Dataloading: 0.0012 s/iter. Inference: 0.2347 s/iter. Eval: 0.0159 s/iter. Total: 0.2518 s/iter. ETA=0:03:21
[09/22 13:11:55] d2.evaluation.evaluator INFO: Inference done 4223/5000. Dataloading: 0.0012 s/iter. Inference: 0.2345 s/iter. Eval: 0.0159 s/iter. Total: 0.2517 s/iter. ETA=0:03:15
[09/22 13:12:00] d2.evaluation.evaluator INFO: Inference done 4246/5000. Dataloading: 0.0012 s/iter. Inference: 0.2343 s/iter. Eval: 0.0159 s/iter. Total: 0.2515 s/iter. ETA=0:03:09
[09/22 13:12:05] d2.evaluation.evaluator INFO: Inference done 4268/5000. Dataloading: 0.0012 s/iter. Inference: 0.2342 s/iter. Eval: 0.0159 s/iter. Total: 0.2514 s/iter. ETA=0:03:04
[09/22 13:12:10] d2.evaluation.evaluator INFO: Inference done 4290/5000. Dataloading: 0.0012 s/iter. Inference: 0.2340 s/iter. Eval: 0.0159 s/iter. Total: 0.2512 s/iter. ETA=0:02:58
[09/22 13:12:15] d2.evaluation.evaluator INFO: Inference done 4312/5000. Dataloading: 0.0012 s/iter. Inference: 0.2339 s/iter. Eval: 0.0159 s/iter. Total: 0.2511 s/iter. ETA=0:02:52
[09/22 13:12:21] d2.evaluation.evaluator INFO: Inference done 4335/5000. Dataloading: 0.0012 s/iter. Inference: 0.2338 s/iter. Eval: 0.0159 s/iter. Total: 0.2510 s/iter. ETA=0:02:46
[09/22 13:12:26] d2.evaluation.evaluator INFO: Inference done 4359/5000. Dataloading: 0.0012 s/iter. Inference: 0.2336 s/iter. Eval: 0.0159 s/iter. Total: 0.2508 s/iter. ETA=0:02:40
[09/22 13:12:31] d2.evaluation.evaluator INFO: Inference done 4382/5000. Dataloading: 0.0012 s/iter. Inference: 0.2335 s/iter. Eval: 0.0159 s/iter. Total: 0.2507 s/iter. ETA=0:02:34
[09/22 13:12:36] d2.evaluation.evaluator INFO: Inference done 4404/5000. Dataloading: 0.0012 s/iter. Inference: 0.2334 s/iter. Eval: 0.0159 s/iter. Total: 0.2506 s/iter. ETA=0:02:29
[09/22 13:12:41] d2.evaluation.evaluator INFO: Inference done 4427/5000. Dataloading: 0.0012 s/iter. Inference: 0.2333 s/iter. Eval: 0.0159 s/iter. Total: 0.2504 s/iter. ETA=0:02:23
[09/22 13:12:46] d2.evaluation.evaluator INFO: Inference done 4449/5000. Dataloading: 0.0012 s/iter. Inference: 0.2332 s/iter. Eval: 0.0159 s/iter. Total: 0.2503 s/iter. ETA=0:02:17
[09/22 13:12:51] d2.evaluation.evaluator INFO: Inference done 4472/5000. Dataloading: 0.0012 s/iter. Inference: 0.2331 s/iter. Eval: 0.0159 s/iter. Total: 0.2502 s/iter. ETA=0:02:12
[09/22 13:12:57] d2.evaluation.evaluator INFO: Inference done 4495/5000. Dataloading: 0.0012 s/iter. Inference: 0.2329 s/iter. Eval: 0.0159 s/iter. Total: 0.2501 s/iter. ETA=0:02:06
[09/22 13:13:02] d2.evaluation.evaluator INFO: Inference done 4517/5000. Dataloading: 0.0012 s/iter. Inference: 0.2328 s/iter. Eval: 0.0159 s/iter. Total: 0.2500 s/iter. ETA=0:02:00
[09/22 13:13:07] d2.evaluation.evaluator INFO: Inference done 4540/5000. Dataloading: 0.0012 s/iter. Inference: 0.2327 s/iter. Eval: 0.0159 s/iter. Total: 0.2498 s/iter. ETA=0:01:54
[09/22 13:13:12] d2.evaluation.evaluator INFO: Inference done 4562/5000. Dataloading: 0.0012 s/iter. Inference: 0.2326 s/iter. Eval: 0.0159 s/iter. Total: 0.2498 s/iter. ETA=0:01:49
[09/22 13:13:17] d2.evaluation.evaluator INFO: Inference done 4584/5000. Dataloading: 0.0012 s/iter. Inference: 0.2325 s/iter. Eval: 0.0159 s/iter. Total: 0.2497 s/iter. ETA=0:01:43
[09/22 13:13:22] d2.evaluation.evaluator INFO: Inference done 4607/5000. Dataloading: 0.0012 s/iter. Inference: 0.2324 s/iter. Eval: 0.0159 s/iter. Total: 0.2496 s/iter. ETA=0:01:38
[09/22 13:13:28] d2.evaluation.evaluator INFO: Inference done 4630/5000. Dataloading: 0.0012 s/iter. Inference: 0.2323 s/iter. Eval: 0.0159 s/iter. Total: 0.2495 s/iter. ETA=0:01:32
[09/22 13:13:33] d2.evaluation.evaluator INFO: Inference done 4652/5000. Dataloading: 0.0012 s/iter. Inference: 0.2322 s/iter. Eval: 0.0159 s/iter. Total: 0.2494 s/iter. ETA=0:01:26
[09/22 13:13:38] d2.evaluation.evaluator INFO: Inference done 4675/5000. Dataloading: 0.0012 s/iter. Inference: 0.2321 s/iter. Eval: 0.0159 s/iter. Total: 0.2493 s/iter. ETA=0:01:21
[09/22 13:13:43] d2.evaluation.evaluator INFO: Inference done 4697/5000. Dataloading: 0.0012 s/iter. Inference: 0.2320 s/iter. Eval: 0.0159 s/iter. Total: 0.2492 s/iter. ETA=0:01:15
[09/22 13:13:48] d2.evaluation.evaluator INFO: Inference done 4719/5000. Dataloading: 0.0012 s/iter. Inference: 0.2319 s/iter. Eval: 0.0159 s/iter. Total: 0.2491 s/iter. ETA=0:01:09
[09/22 13:13:53] d2.evaluation.evaluator INFO: Inference done 4741/5000. Dataloading: 0.0012 s/iter. Inference: 0.2318 s/iter. Eval: 0.0159 s/iter. Total: 0.2490 s/iter. ETA=0:01:04
[09/22 13:13:58] d2.evaluation.evaluator INFO: Inference done 4763/5000. Dataloading: 0.0012 s/iter. Inference: 0.2317 s/iter. Eval: 0.0159 s/iter. Total: 0.2489 s/iter. ETA=0:00:58
[09/22 13:14:03] d2.evaluation.evaluator INFO: Inference done 4786/5000. Dataloading: 0.0012 s/iter. Inference: 0.2316 s/iter. Eval: 0.0159 s/iter. Total: 0.2488 s/iter. ETA=0:00:53
[09/22 13:14:08] d2.evaluation.evaluator INFO: Inference done 4808/5000. Dataloading: 0.0012 s/iter. Inference: 0.2315 s/iter. Eval: 0.0159 s/iter. Total: 0.2487 s/iter. ETA=0:00:47
[09/22 13:14:13] d2.evaluation.evaluator INFO: Inference done 4832/5000. Dataloading: 0.0012 s/iter. Inference: 0.2313 s/iter. Eval: 0.0159 s/iter. Total: 0.2485 s/iter. ETA=0:00:41
[09/22 13:14:18] d2.evaluation.evaluator INFO: Inference done 4854/5000. Dataloading: 0.0012 s/iter. Inference: 0.2313 s/iter. Eval: 0.0159 s/iter. Total: 0.2484 s/iter. ETA=0:00:36
[09/22 13:14:23] d2.evaluation.evaluator INFO: Inference done 4876/5000. Dataloading: 0.0012 s/iter. Inference: 0.2312 s/iter. Eval: 0.0159 s/iter. Total: 0.2483 s/iter. ETA=0:00:30
[09/22 13:14:29] d2.evaluation.evaluator INFO: Inference done 4898/5000. Dataloading: 0.0012 s/iter. Inference: 0.2311 s/iter. Eval: 0.0159 s/iter. Total: 0.2483 s/iter. ETA=0:00:25
[09/22 13:14:34] d2.evaluation.evaluator INFO: Inference done 4919/5000. Dataloading: 0.0012 s/iter. Inference: 0.2311 s/iter. Eval: 0.0159 s/iter. Total: 0.2482 s/iter. ETA=0:00:20
[09/22 13:14:39] d2.evaluation.evaluator INFO: Inference done 4942/5000. Dataloading: 0.0012 s/iter. Inference: 0.2310 s/iter. Eval: 0.0159 s/iter. Total: 0.2481 s/iter. ETA=0:00:14
[09/22 13:14:44] d2.evaluation.evaluator INFO: Inference done 4964/5000. Dataloading: 0.0012 s/iter. Inference: 0.2309 s/iter. Eval: 0.0159 s/iter. Total: 0.2480 s/iter. ETA=0:00:08
[09/22 13:14:49] d2.evaluation.evaluator INFO: Inference done 4987/5000. Dataloading: 0.0012 s/iter. Inference: 0.2308 s/iter. Eval: 0.0159 s/iter. Total: 0.2480 s/iter. ETA=0:00:03
[09/22 13:14:52] d2.evaluation.evaluator INFO: Total inference time: 0:20:38.218578 (0.247892 s / iter per device, on 1 devices)
[09/22 13:14:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:19:12 (0.230760 s / iter per device, on 1 devices)
[09/22 13:14:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[09/22 13:14:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[09/22 13:15:14] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 35.450 | 56.689 | 38.368 | 20.757 | 37.962 | 48.074 |
[09/22 13:15:14] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 49.864 | bicycle      | 25.043 | car            | 37.223 |
| motorcycle    | 37.124 | airplane     | 61.119 | bus            | 58.081 |
| train         | 56.202 | truck        | 28.630 | boat           | 21.117 |
| traffic light | 24.347 | fire hydrant | 62.804 | stop sign      | 60.631 |
| parking meter | 38.694 | bench        | 19.632 | bird           | 29.671 |
| cat           | 58.210 | dog          | 56.809 | horse          | 51.071 |
| sheep         | 43.321 | cow          | 48.340 | elephant       | 55.116 |
| bear          | 62.820 | zebra        | 61.982 | giraffe        | 61.751 |
| backpack      | 13.003 | umbrella     | 32.293 | handbag        | 9.988  |
| tie           | 27.100 | suitcase     | 31.691 | frisbee        | 57.464 |
| skis          | 19.966 | snowboard    | 30.928 | sports ball    | 45.113 |
| kite          | 38.572 | baseball bat | 23.654 | baseball glove | 34.620 |
| skateboard    | 45.659 | surfboard    | 32.863 | tennis racket  | 39.270 |
| bottle        | 32.343 | wine glass   | 28.212 | cup            | 34.669 |
| fork          | 25.742 | knife        | 12.847 | spoon          | 7.798  |
| bowl          | 31.327 | banana       | 19.891 | apple          | 16.241 |
| sandwich      | 29.937 | orange       | 25.424 | broccoli       | 19.624 |
| carrot        | 16.328 | hot dog      | 28.338 | pizza          | 48.660 |
| donut         | 42.331 | cake         | 33.368 | chair          | 22.942 |
| couch         | 34.281 | potted plant | 22.759 | bed            | 39.416 |
| dining table  | 22.310 | toilet       | 55.919 | tv             | 49.567 |
| laptop        | 53.684 | mouse        | 51.846 | remote         | 25.083 |
| keyboard      | 41.933 | cell phone   | 28.162 | microwave      | 49.947 |
| oven          | 26.933 | toaster      | 20.217 | sink           | 30.175 |
| refrigerator  | 46.403 | book         | 10.407 | clock          | 41.935 |
| vase          | 32.623 | scissors     | 22.660 | teddy bear     | 42.901 |
| hair drier    | 0.601  | toothbrush   | 18.430 |                |        |
[09/22 13:15:44] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 33.710 | 54.236 | 36.171 | 16.547 | 35.172 | 50.534 |
[09/22 13:15:44] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 44.886 | bicycle      | 14.302 | car            | 35.851 |
| motorcycle    | 29.779 | airplane     | 49.861 | bus            | 58.589 |
| train         | 57.499 | truck        | 28.496 | boat           | 17.880 |
| traffic light | 24.549 | fire hydrant | 59.780 | stop sign      | 63.054 |
| parking meter | 40.362 | bench        | 14.464 | bird           | 26.580 |
| cat           | 63.392 | dog          | 57.043 | horse          | 38.085 |
| sheep         | 39.655 | cow          | 42.979 | elephant       | 52.548 |
| bear          | 62.056 | zebra        | 54.282 | giraffe        | 49.924 |
| backpack      | 12.583 | umbrella     | 40.825 | handbag        | 11.220 |
| tie           | 27.034 | suitcase     | 33.383 | frisbee        | 60.673 |
| skis          | 3.598  | snowboard    | 23.365 | sports ball    | 46.240 |
| kite          | 29.289 | baseball bat | 22.388 | baseball glove | 38.500 |
| skateboard    | 25.824 | surfboard    | 29.822 | tennis racket  | 50.933 |
| bottle        | 32.615 | wine glass   | 26.565 | cup            | 36.468 |
| fork          | 11.461 | knife        | 10.012 | spoon          | 7.358  |
| bowl          | 30.283 | banana       | 17.657 | apple          | 16.008 |
| sandwich      | 33.630 | orange       | 25.949 | broccoli       | 18.159 |
| carrot        | 15.275 | hot dog      | 26.661 | pizza          | 50.397 |
| donut         | 45.145 | cake         | 35.632 | chair          | 15.130 |
| couch         | 29.855 | potted plant | 20.969 | bed            | 29.743 |
| dining table  | 12.636 | toilet       | 57.554 | tv             | 53.262 |
| laptop        | 55.807 | mouse        | 56.915 | remote         | 25.416 |
| keyboard      | 43.639 | cell phone   | 30.613 | microwave      | 51.750 |
| oven          | 24.998 | toaster      | 27.359 | sink           | 30.740 |
| refrigerator  | 49.853 | book         | 7.247  | clock          | 44.406 |
| vase          | 33.352 | scissors     | 16.707 | teddy bear     | 43.698 |
| hair drier    | 0.616  | toothbrush   | 13.695 |                |        |
[09/22 13:15:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[09/22 13:15:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 13:15:45] d2.evaluation.testing INFO: copypaste: 35.4500,56.6885,38.3684,20.7573,37.9621,48.0738
[09/22 13:15:45] d2.evaluation.testing INFO: copypaste: Task: segm
[09/22 13:15:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 13:15:45] d2.evaluation.testing INFO: copypaste: 33.7101,54.2360,36.1708,16.5473,35.1716,50.5344
[09/22 14:12:51] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 14:12:51] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 14:12:51] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 14:12:51] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=128,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 14:12:51] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 14:12:51] d2.utils.env INFO: Using a generated random seed 53548924
[09/22 14:12:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 14:12:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.fpn_lateral2.weight' to the model due to incompatible shapes: (256, 96, 1, 1) in the checkpoint but (256, 128, 1, 1) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.fpn_lateral3.weight' to the model due to incompatible shapes: (256, 192, 1, 1) in the checkpoint but (256, 256, 1, 1) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.fpn_lateral4.weight' to the model due to incompatible shapes: (256, 384, 1, 1) in the checkpoint but (256, 512, 1, 1) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.fpn_lateral5.weight' to the model due to incompatible shapes: (256, 768, 1, 1) in the checkpoint but (256, 1024, 1, 1) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.pos_embed' to the model due to incompatible shapes: (1, 96, 14, 14) in the checkpoint but (1, 128, 14, 14) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.pos_embed_window' to the model due to incompatible shapes: (1, 96, 8, 8) in the checkpoint but (1, 128, 8, 8) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.patch_embed.proj.weight' to the model due to incompatible shapes: (96, 3, 7, 7) in the checkpoint but (128, 3, 7, 7) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.patch_embed.proj.bias' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.norm1.weight' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.norm1.bias' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.attn.qkv.weight' to the model due to incompatible shapes: (288, 96) in the checkpoint but (384, 128) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.attn.qkv.bias' to the model due to incompatible shapes: (288,) in the checkpoint but (384,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.attn.proj.weight' to the model due to incompatible shapes: (96, 96) in the checkpoint but (128, 128) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.attn.proj.bias' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.norm2.weight' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.norm2.bias' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.mlp.fc1.weight' to the model due to incompatible shapes: (384, 96) in the checkpoint but (512, 128) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.mlp.fc1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.mlp.fc2.weight' to the model due to incompatible shapes: (96, 384) in the checkpoint but (128, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.0.mlp.fc2.bias' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.norm1.weight' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.norm1.bias' to the model due to incompatible shapes: (96,) in the checkpoint but (128,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.attn.qkv.weight' to the model due to incompatible shapes: (576, 96) in the checkpoint but (768, 128) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.attn.qkv.bias' to the model due to incompatible shapes: (576,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.attn.proj.weight' to the model due to incompatible shapes: (192, 192) in the checkpoint but (256, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.attn.proj.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.norm2.weight' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.norm2.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.mlp.fc1.weight' to the model due to incompatible shapes: (768, 192) in the checkpoint but (1024, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.mlp.fc1.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.mlp.fc2.weight' to the model due to incompatible shapes: (192, 768) in the checkpoint but (256, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.mlp.fc2.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.proj.weight' to the model due to incompatible shapes: (192, 96) in the checkpoint but (256, 128) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.1.proj.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.norm1.weight' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.norm1.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.attn.qkv.weight' to the model due to incompatible shapes: (576, 192) in the checkpoint but (768, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.attn.qkv.bias' to the model due to incompatible shapes: (576,) in the checkpoint but (768,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.attn.proj.weight' to the model due to incompatible shapes: (192, 192) in the checkpoint but (256, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.attn.proj.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.norm2.weight' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.norm2.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.mlp.fc1.weight' to the model due to incompatible shapes: (768, 192) in the checkpoint but (1024, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.mlp.fc1.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.mlp.fc2.weight' to the model due to incompatible shapes: (192, 768) in the checkpoint but (256, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.2.mlp.fc2.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.norm1.weight' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.norm1.bias' to the model due to incompatible shapes: (192,) in the checkpoint but (256,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.attn.qkv.weight' to the model due to incompatible shapes: (1152, 192) in the checkpoint but (1536, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.proj.weight' to the model due to incompatible shapes: (384, 192) in the checkpoint but (512, 256) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.3.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.attn.qkv.weight' to the model due to incompatible shapes: (1152, 384) in the checkpoint but (1536, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.4.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.attn.qkv.weight' to the model due to incompatible shapes: (1152, 384) in the checkpoint but (1536, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.5.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.attn.qkv.weight' to the model due to incompatible shapes: (1152, 384) in the checkpoint but (1536, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.6.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.attn.qkv.weight' to the model due to incompatible shapes: (1152, 384) in the checkpoint but (1536, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.7.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.attn.qkv.weight' to the model due to incompatible shapes: (1152, 384) in the checkpoint but (1536, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.8.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.attn.qkv.weight' to the model due to incompatible shapes: (1152, 384) in the checkpoint but (1536, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.attn.qkv.bias' to the model due to incompatible shapes: (1152,) in the checkpoint but (1536,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.attn.proj.weight' to the model due to incompatible shapes: (384, 384) in the checkpoint but (512, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.attn.proj.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.norm2.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.norm2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.mlp.fc1.weight' to the model due to incompatible shapes: (1536, 384) in the checkpoint but (2048, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.mlp.fc1.bias' to the model due to incompatible shapes: (1536,) in the checkpoint but (2048,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.mlp.fc2.weight' to the model due to incompatible shapes: (384, 1536) in the checkpoint but (512, 2048) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.9.mlp.fc2.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.norm1.weight' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.norm1.bias' to the model due to incompatible shapes: (384,) in the checkpoint but (512,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.attn.qkv.weight' to the model due to incompatible shapes: (2304, 384) in the checkpoint but (3072, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.attn.qkv.bias' to the model due to incompatible shapes: (2304,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.attn.proj.weight' to the model due to incompatible shapes: (768, 768) in the checkpoint but (1024, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.attn.proj.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.norm2.weight' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.norm2.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.mlp.fc1.weight' to the model due to incompatible shapes: (3072, 768) in the checkpoint but (4096, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.mlp.fc1.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (4096,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.mlp.fc2.weight' to the model due to incompatible shapes: (768, 3072) in the checkpoint but (1024, 4096) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.mlp.fc2.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.proj.weight' to the model due to incompatible shapes: (768, 384) in the checkpoint but (1024, 512) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.10.proj.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.norm1.weight' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.norm1.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.attn.qkv.weight' to the model due to incompatible shapes: (2304, 768) in the checkpoint but (3072, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.attn.qkv.bias' to the model due to incompatible shapes: (2304,) in the checkpoint but (3072,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.attn.proj.weight' to the model due to incompatible shapes: (768, 768) in the checkpoint but (1024, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.attn.proj.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.norm2.weight' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.norm2.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.mlp.fc1.weight' to the model due to incompatible shapes: (3072, 768) in the checkpoint but (4096, 1024) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.mlp.fc1.bias' to the model due to incompatible shapes: (3072,) in the checkpoint but (4096,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.mlp.fc2.weight' to the model due to incompatible shapes: (768, 3072) in the checkpoint but (1024, 4096) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Skip loading parameter 'backbone.bottom_up.blocks.11.mlp.fc2.bias' to the model due to incompatible shapes: (768,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.
[09/22 14:12:53] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.attn.proj.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.attn.qkv.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.norm1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.norm2.{bias, weight}[0m
[34mbackbone.bottom_up.patch_embed.proj.{bias, weight}[0m
[34mbackbone.bottom_up.{pos_embed, pos_embed_window}[0m
[34mbackbone.fpn_lateral2.weight[0m
[34mbackbone.fpn_lateral3.weight[0m
[34mbackbone.fpn_lateral4.weight[0m
[34mbackbone.fpn_lateral5.weight[0m
[09/22 14:12:53] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 14:12:54] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 14:12:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 14:12:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 14:12:54] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 14:12:54] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 14:12:54] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 14:12:54] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 14:12:57] d2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0008 s/iter. Inference: 0.2086 s/iter. Eval: 0.0001 s/iter. Total: 0.2095 s/iter. ETA=0:17:24
[09/22 14:13:02] d2.evaluation.evaluator INFO: Inference done 35/5000. Dataloading: 0.0011 s/iter. Inference: 0.2109 s/iter. Eval: 0.0017 s/iter. Total: 0.2138 s/iter. ETA=0:17:41
[09/22 14:13:07] d2.evaluation.evaluator INFO: Inference done 59/5000. Dataloading: 0.0011 s/iter. Inference: 0.2121 s/iter. Eval: 0.0014 s/iter. Total: 0.2146 s/iter. ETA=0:17:40
[09/22 14:13:12] d2.evaluation.evaluator INFO: Inference done 83/5000. Dataloading: 0.0011 s/iter. Inference: 0.2127 s/iter. Eval: 0.0010 s/iter. Total: 0.2148 s/iter. ETA=0:17:36
[09/22 14:13:17] d2.evaluation.evaluator INFO: Inference done 108/5000. Dataloading: 0.0011 s/iter. Inference: 0.2097 s/iter. Eval: 0.0011 s/iter. Total: 0.2120 s/iter. ETA=0:17:17
[09/22 14:13:23] d2.evaluation.evaluator INFO: Inference done 132/5000. Dataloading: 0.0011 s/iter. Inference: 0.2104 s/iter. Eval: 0.0010 s/iter. Total: 0.2126 s/iter. ETA=0:17:15
[09/22 14:13:28] d2.evaluation.evaluator INFO: Inference done 155/5000. Dataloading: 0.0012 s/iter. Inference: 0.2121 s/iter. Eval: 0.0015 s/iter. Total: 0.2148 s/iter. ETA=0:17:20
[09/22 14:13:33] d2.evaluation.evaluator INFO: Inference done 178/5000. Dataloading: 0.0012 s/iter. Inference: 0.2115 s/iter. Eval: 0.0027 s/iter. Total: 0.2154 s/iter. ETA=0:17:18
[09/22 14:13:38] d2.evaluation.evaluator INFO: Inference done 202/5000. Dataloading: 0.0011 s/iter. Inference: 0.2117 s/iter. Eval: 0.0026 s/iter. Total: 0.2155 s/iter. ETA=0:17:13
[09/22 14:13:43] d2.evaluation.evaluator INFO: Inference done 226/5000. Dataloading: 0.0012 s/iter. Inference: 0.2111 s/iter. Eval: 0.0024 s/iter. Total: 0.2147 s/iter. ETA=0:17:05
[09/22 14:13:48] d2.evaluation.evaluator INFO: Inference done 249/5000. Dataloading: 0.0012 s/iter. Inference: 0.2118 s/iter. Eval: 0.0023 s/iter. Total: 0.2153 s/iter. ETA=0:17:02
[09/22 14:13:53] d2.evaluation.evaluator INFO: Inference done 273/5000. Dataloading: 0.0012 s/iter. Inference: 0.2113 s/iter. Eval: 0.0022 s/iter. Total: 0.2147 s/iter. ETA=0:16:54
[09/22 14:13:58] d2.evaluation.evaluator INFO: Inference done 296/5000. Dataloading: 0.0012 s/iter. Inference: 0.2118 s/iter. Eval: 0.0022 s/iter. Total: 0.2152 s/iter. ETA=0:16:52
[09/22 14:14:03] d2.evaluation.evaluator INFO: Inference done 320/5000. Dataloading: 0.0012 s/iter. Inference: 0.2118 s/iter. Eval: 0.0021 s/iter. Total: 0.2151 s/iter. ETA=0:16:46
[09/22 14:14:09] d2.evaluation.evaluator INFO: Inference done 343/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0023 s/iter. Total: 0.2158 s/iter. ETA=0:16:45
[09/22 14:14:14] d2.evaluation.evaluator INFO: Inference done 366/5000. Dataloading: 0.0012 s/iter. Inference: 0.2126 s/iter. Eval: 0.0022 s/iter. Total: 0.2160 s/iter. ETA=0:16:41
[09/22 14:14:19] d2.evaluation.evaluator INFO: Inference done 390/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0022 s/iter. Total: 0.2157 s/iter. ETA=0:16:34
[09/22 14:14:24] d2.evaluation.evaluator INFO: Inference done 413/5000. Dataloading: 0.0012 s/iter. Inference: 0.2124 s/iter. Eval: 0.0022 s/iter. Total: 0.2158 s/iter. ETA=0:16:30
[09/22 14:14:29] d2.evaluation.evaluator INFO: Inference done 437/5000. Dataloading: 0.0012 s/iter. Inference: 0.2125 s/iter. Eval: 0.0021 s/iter. Total: 0.2158 s/iter. ETA=0:16:24
[09/22 14:14:34] d2.evaluation.evaluator INFO: Inference done 461/5000. Dataloading: 0.0012 s/iter. Inference: 0.2126 s/iter. Eval: 0.0020 s/iter. Total: 0.2158 s/iter. ETA=0:16:19
[09/22 14:14:39] d2.evaluation.evaluator INFO: Inference done 484/5000. Dataloading: 0.0012 s/iter. Inference: 0.2129 s/iter. Eval: 0.0019 s/iter. Total: 0.2160 s/iter. ETA=0:16:15
[09/22 14:14:44] d2.evaluation.evaluator INFO: Inference done 508/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0019 s/iter. Total: 0.2160 s/iter. ETA=0:16:10
[09/22 14:14:50] d2.evaluation.evaluator INFO: Inference done 532/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0020 s/iter. Total: 0.2160 s/iter. ETA=0:16:05
[09/22 14:14:55] d2.evaluation.evaluator INFO: Inference done 556/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0020 s/iter. Total: 0.2161 s/iter. ETA=0:16:00
[09/22 14:15:00] d2.evaluation.evaluator INFO: Inference done 579/5000. Dataloading: 0.0012 s/iter. Inference: 0.2129 s/iter. Eval: 0.0020 s/iter. Total: 0.2161 s/iter. ETA=0:15:55
[09/22 14:15:05] d2.evaluation.evaluator INFO: Inference done 603/5000. Dataloading: 0.0012 s/iter. Inference: 0.2128 s/iter. Eval: 0.0020 s/iter. Total: 0.2160 s/iter. ETA=0:15:49
[09/22 14:15:10] d2.evaluation.evaluator INFO: Inference done 626/5000. Dataloading: 0.0012 s/iter. Inference: 0.2132 s/iter. Eval: 0.0020 s/iter. Total: 0.2164 s/iter. ETA=0:15:46
[09/22 14:15:15] d2.evaluation.evaluator INFO: Inference done 650/5000. Dataloading: 0.0012 s/iter. Inference: 0.2133 s/iter. Eval: 0.0019 s/iter. Total: 0.2164 s/iter. ETA=0:15:41
[09/22 14:15:20] d2.evaluation.evaluator INFO: Inference done 673/5000. Dataloading: 0.0012 s/iter. Inference: 0.2136 s/iter. Eval: 0.0019 s/iter. Total: 0.2168 s/iter. ETA=0:15:37
[09/22 14:15:25] d2.evaluation.evaluator INFO: Inference done 695/5000. Dataloading: 0.0012 s/iter. Inference: 0.2139 s/iter. Eval: 0.0019 s/iter. Total: 0.2171 s/iter. ETA=0:15:34
[09/22 14:15:31] d2.evaluation.evaluator INFO: Inference done 717/5000. Dataloading: 0.0012 s/iter. Inference: 0.2144 s/iter. Eval: 0.0019 s/iter. Total: 0.2175 s/iter. ETA=0:15:31
[09/22 14:15:36] d2.evaluation.evaluator INFO: Inference done 740/5000. Dataloading: 0.0012 s/iter. Inference: 0.2146 s/iter. Eval: 0.0019 s/iter. Total: 0.2177 s/iter. ETA=0:15:27
[09/22 14:15:41] d2.evaluation.evaluator INFO: Inference done 763/5000. Dataloading: 0.0012 s/iter. Inference: 0.2148 s/iter. Eval: 0.0019 s/iter. Total: 0.2179 s/iter. ETA=0:15:23
[09/22 14:15:46] d2.evaluation.evaluator INFO: Inference done 785/5000. Dataloading: 0.0012 s/iter. Inference: 0.2151 s/iter. Eval: 0.0019 s/iter. Total: 0.2183 s/iter. ETA=0:15:20
[09/22 14:15:51] d2.evaluation.evaluator INFO: Inference done 808/5000. Dataloading: 0.0012 s/iter. Inference: 0.2154 s/iter. Eval: 0.0020 s/iter. Total: 0.2186 s/iter. ETA=0:15:16
[09/22 14:15:56] d2.evaluation.evaluator INFO: Inference done 831/5000. Dataloading: 0.0012 s/iter. Inference: 0.2154 s/iter. Eval: 0.0019 s/iter. Total: 0.2186 s/iter. ETA=0:15:11
[09/22 14:16:01] d2.evaluation.evaluator INFO: Inference done 854/5000. Dataloading: 0.0012 s/iter. Inference: 0.2156 s/iter. Eval: 0.0019 s/iter. Total: 0.2188 s/iter. ETA=0:15:06
[09/22 14:16:06] d2.evaluation.evaluator INFO: Inference done 876/5000. Dataloading: 0.0012 s/iter. Inference: 0.2159 s/iter. Eval: 0.0019 s/iter. Total: 0.2190 s/iter. ETA=0:15:03
[09/22 14:16:12] d2.evaluation.evaluator INFO: Inference done 899/5000. Dataloading: 0.0012 s/iter. Inference: 0.2160 s/iter. Eval: 0.0019 s/iter. Total: 0.2192 s/iter. ETA=0:14:58
[09/22 14:16:17] d2.evaluation.evaluator INFO: Inference done 922/5000. Dataloading: 0.0012 s/iter. Inference: 0.2160 s/iter. Eval: 0.0019 s/iter. Total: 0.2191 s/iter. ETA=0:14:53
[09/22 14:16:22] d2.evaluation.evaluator INFO: Inference done 944/5000. Dataloading: 0.0012 s/iter. Inference: 0.2162 s/iter. Eval: 0.0019 s/iter. Total: 0.2194 s/iter. ETA=0:14:49
[09/22 14:16:27] d2.evaluation.evaluator INFO: Inference done 967/5000. Dataloading: 0.0012 s/iter. Inference: 0.2164 s/iter. Eval: 0.0019 s/iter. Total: 0.2195 s/iter. ETA=0:14:45
[09/22 14:16:32] d2.evaluation.evaluator INFO: Inference done 990/5000. Dataloading: 0.0012 s/iter. Inference: 0.2164 s/iter. Eval: 0.0018 s/iter. Total: 0.2195 s/iter. ETA=0:14:40
[09/22 14:16:37] d2.evaluation.evaluator INFO: Inference done 1013/5000. Dataloading: 0.0012 s/iter. Inference: 0.2165 s/iter. Eval: 0.0018 s/iter. Total: 0.2195 s/iter. ETA=0:14:35
[09/22 14:16:42] d2.evaluation.evaluator INFO: Inference done 1036/5000. Dataloading: 0.0012 s/iter. Inference: 0.2165 s/iter. Eval: 0.0018 s/iter. Total: 0.2196 s/iter. ETA=0:14:30
[09/22 14:16:47] d2.evaluation.evaluator INFO: Inference done 1059/5000. Dataloading: 0.0012 s/iter. Inference: 0.2167 s/iter. Eval: 0.0018 s/iter. Total: 0.2197 s/iter. ETA=0:14:26
[09/22 14:16:52] d2.evaluation.evaluator INFO: Inference done 1081/5000. Dataloading: 0.0012 s/iter. Inference: 0.2169 s/iter. Eval: 0.0018 s/iter. Total: 0.2200 s/iter. ETA=0:14:22
[09/22 14:16:58] d2.evaluation.evaluator INFO: Inference done 1104/5000. Dataloading: 0.0012 s/iter. Inference: 0.2171 s/iter. Eval: 0.0018 s/iter. Total: 0.2201 s/iter. ETA=0:14:17
[09/22 14:17:03] d2.evaluation.evaluator INFO: Inference done 1127/5000. Dataloading: 0.0012 s/iter. Inference: 0.2172 s/iter. Eval: 0.0018 s/iter. Total: 0.2202 s/iter. ETA=0:14:12
[09/22 14:17:08] d2.evaluation.evaluator INFO: Inference done 1149/5000. Dataloading: 0.0012 s/iter. Inference: 0.2173 s/iter. Eval: 0.0018 s/iter. Total: 0.2204 s/iter. ETA=0:14:08
[09/22 14:17:13] d2.evaluation.evaluator INFO: Inference done 1171/5000. Dataloading: 0.0012 s/iter. Inference: 0.2176 s/iter. Eval: 0.0017 s/iter. Total: 0.2206 s/iter. ETA=0:14:04
[09/22 14:17:18] d2.evaluation.evaluator INFO: Inference done 1193/5000. Dataloading: 0.0012 s/iter. Inference: 0.2177 s/iter. Eval: 0.0018 s/iter. Total: 0.2207 s/iter. ETA=0:14:00
[09/22 14:17:23] d2.evaluation.evaluator INFO: Inference done 1216/5000. Dataloading: 0.0012 s/iter. Inference: 0.2178 s/iter. Eval: 0.0018 s/iter. Total: 0.2208 s/iter. ETA=0:13:55
[09/22 14:17:28] d2.evaluation.evaluator INFO: Inference done 1239/5000. Dataloading: 0.0012 s/iter. Inference: 0.2179 s/iter. Eval: 0.0018 s/iter. Total: 0.2209 s/iter. ETA=0:13:50
[09/22 14:17:33] d2.evaluation.evaluator INFO: Inference done 1262/5000. Dataloading: 0.0012 s/iter. Inference: 0.2179 s/iter. Eval: 0.0017 s/iter. Total: 0.2209 s/iter. ETA=0:13:45
[09/22 14:17:38] d2.evaluation.evaluator INFO: Inference done 1285/5000. Dataloading: 0.0012 s/iter. Inference: 0.2180 s/iter. Eval: 0.0017 s/iter. Total: 0.2209 s/iter. ETA=0:13:40
[09/22 14:17:44] d2.evaluation.evaluator INFO: Inference done 1308/5000. Dataloading: 0.0012 s/iter. Inference: 0.2180 s/iter. Eval: 0.0017 s/iter. Total: 0.2209 s/iter. ETA=0:13:35
[09/22 14:17:49] d2.evaluation.evaluator INFO: Inference done 1331/5000. Dataloading: 0.0012 s/iter. Inference: 0.2179 s/iter. Eval: 0.0017 s/iter. Total: 0.2209 s/iter. ETA=0:13:30
[09/22 14:17:54] d2.evaluation.evaluator INFO: Inference done 1354/5000. Dataloading: 0.0012 s/iter. Inference: 0.2180 s/iter. Eval: 0.0017 s/iter. Total: 0.2210 s/iter. ETA=0:13:25
[09/22 14:17:59] d2.evaluation.evaluator INFO: Inference done 1377/5000. Dataloading: 0.0012 s/iter. Inference: 0.2181 s/iter. Eval: 0.0017 s/iter. Total: 0.2210 s/iter. ETA=0:13:20
[09/22 14:18:04] d2.evaluation.evaluator INFO: Inference done 1400/5000. Dataloading: 0.0012 s/iter. Inference: 0.2181 s/iter. Eval: 0.0017 s/iter. Total: 0.2211 s/iter. ETA=0:13:15
[09/22 14:18:09] d2.evaluation.evaluator INFO: Inference done 1424/5000. Dataloading: 0.0012 s/iter. Inference: 0.2180 s/iter. Eval: 0.0017 s/iter. Total: 0.2210 s/iter. ETA=0:13:10
[09/22 14:18:14] d2.evaluation.evaluator INFO: Inference done 1447/5000. Dataloading: 0.0012 s/iter. Inference: 0.2181 s/iter. Eval: 0.0017 s/iter. Total: 0.2210 s/iter. ETA=0:13:05
[09/22 14:18:19] d2.evaluation.evaluator INFO: Inference done 1471/5000. Dataloading: 0.0012 s/iter. Inference: 0.2179 s/iter. Eval: 0.0017 s/iter. Total: 0.2208 s/iter. ETA=0:12:59
[09/22 14:18:25] d2.evaluation.evaluator INFO: Inference done 1494/5000. Dataloading: 0.0012 s/iter. Inference: 0.2180 s/iter. Eval: 0.0017 s/iter. Total: 0.2209 s/iter. ETA=0:12:54
[09/22 14:18:30] d2.evaluation.evaluator INFO: Inference done 1518/5000. Dataloading: 0.0012 s/iter. Inference: 0.2178 s/iter. Eval: 0.0017 s/iter. Total: 0.2207 s/iter. ETA=0:12:48
[09/22 14:18:35] d2.evaluation.evaluator INFO: Inference done 1541/5000. Dataloading: 0.0012 s/iter. Inference: 0.2179 s/iter. Eval: 0.0017 s/iter. Total: 0.2208 s/iter. ETA=0:12:43
[09/22 14:18:40] d2.evaluation.evaluator INFO: Inference done 1563/5000. Dataloading: 0.0012 s/iter. Inference: 0.2180 s/iter. Eval: 0.0017 s/iter. Total: 0.2209 s/iter. ETA=0:12:39
[09/22 14:18:45] d2.evaluation.evaluator INFO: Inference done 1585/5000. Dataloading: 0.0012 s/iter. Inference: 0.2181 s/iter. Eval: 0.0017 s/iter. Total: 0.2211 s/iter. ETA=0:12:34
[09/22 14:18:50] d2.evaluation.evaluator INFO: Inference done 1608/5000. Dataloading: 0.0012 s/iter. Inference: 0.2182 s/iter. Eval: 0.0017 s/iter. Total: 0.2211 s/iter. ETA=0:12:29
[09/22 14:18:55] d2.evaluation.evaluator INFO: Inference done 1631/5000. Dataloading: 0.0012 s/iter. Inference: 0.2182 s/iter. Eval: 0.0017 s/iter. Total: 0.2211 s/iter. ETA=0:12:24
[09/22 14:19:00] d2.evaluation.evaluator INFO: Inference done 1654/5000. Dataloading: 0.0012 s/iter. Inference: 0.2182 s/iter. Eval: 0.0017 s/iter. Total: 0.2211 s/iter. ETA=0:12:19
[09/22 14:19:05] d2.evaluation.evaluator INFO: Inference done 1677/5000. Dataloading: 0.0012 s/iter. Inference: 0.2182 s/iter. Eval: 0.0016 s/iter. Total: 0.2211 s/iter. ETA=0:12:14
[09/22 14:19:11] d2.evaluation.evaluator INFO: Inference done 1700/5000. Dataloading: 0.0012 s/iter. Inference: 0.2183 s/iter. Eval: 0.0016 s/iter. Total: 0.2212 s/iter. ETA=0:12:09
[09/22 14:19:16] d2.evaluation.evaluator INFO: Inference done 1723/5000. Dataloading: 0.0012 s/iter. Inference: 0.2183 s/iter. Eval: 0.0017 s/iter. Total: 0.2212 s/iter. ETA=0:12:04
[09/22 14:19:21] d2.evaluation.evaluator INFO: Inference done 1746/5000. Dataloading: 0.0012 s/iter. Inference: 0.2184 s/iter. Eval: 0.0017 s/iter. Total: 0.2213 s/iter. ETA=0:12:00
[09/22 14:19:26] d2.evaluation.evaluator INFO: Inference done 1769/5000. Dataloading: 0.0012 s/iter. Inference: 0.2184 s/iter. Eval: 0.0016 s/iter. Total: 0.2213 s/iter. ETA=0:11:54
[09/22 14:19:31] d2.evaluation.evaluator INFO: Inference done 1793/5000. Dataloading: 0.0012 s/iter. Inference: 0.2183 s/iter. Eval: 0.0016 s/iter. Total: 0.2212 s/iter. ETA=0:11:49
[09/22 14:19:36] d2.evaluation.evaluator INFO: Inference done 1816/5000. Dataloading: 0.0012 s/iter. Inference: 0.2184 s/iter. Eval: 0.0016 s/iter. Total: 0.2213 s/iter. ETA=0:11:44
[09/22 14:19:41] d2.evaluation.evaluator INFO: Inference done 1839/5000. Dataloading: 0.0012 s/iter. Inference: 0.2184 s/iter. Eval: 0.0016 s/iter. Total: 0.2213 s/iter. ETA=0:11:39
[09/22 14:19:47] d2.evaluation.evaluator INFO: Inference done 1862/5000. Dataloading: 0.0012 s/iter. Inference: 0.2184 s/iter. Eval: 0.0016 s/iter. Total: 0.2213 s/iter. ETA=0:11:34
[09/22 14:19:52] d2.evaluation.evaluator INFO: Inference done 1884/5000. Dataloading: 0.0012 s/iter. Inference: 0.2185 s/iter. Eval: 0.0016 s/iter. Total: 0.2213 s/iter. ETA=0:11:29
[09/22 14:19:57] d2.evaluation.evaluator INFO: Inference done 1907/5000. Dataloading: 0.0012 s/iter. Inference: 0.2185 s/iter. Eval: 0.0016 s/iter. Total: 0.2214 s/iter. ETA=0:11:24
[09/22 14:20:02] d2.evaluation.evaluator INFO: Inference done 1930/5000. Dataloading: 0.0012 s/iter. Inference: 0.2186 s/iter. Eval: 0.0016 s/iter. Total: 0.2214 s/iter. ETA=0:11:19
[09/22 14:20:07] d2.evaluation.evaluator INFO: Inference done 1953/5000. Dataloading: 0.0012 s/iter. Inference: 0.2186 s/iter. Eval: 0.0016 s/iter. Total: 0.2214 s/iter. ETA=0:11:14
[09/22 14:20:12] d2.evaluation.evaluator INFO: Inference done 1976/5000. Dataloading: 0.0012 s/iter. Inference: 0.2186 s/iter. Eval: 0.0016 s/iter. Total: 0.2215 s/iter. ETA=0:11:09
[09/22 14:20:17] d2.evaluation.evaluator INFO: Inference done 1999/5000. Dataloading: 0.0012 s/iter. Inference: 0.2186 s/iter. Eval: 0.0016 s/iter. Total: 0.2215 s/iter. ETA=0:11:04
[09/22 14:20:22] d2.evaluation.evaluator INFO: Inference done 2021/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:11:00
[09/22 14:20:28] d2.evaluation.evaluator INFO: Inference done 2045/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:54
[09/22 14:20:33] d2.evaluation.evaluator INFO: Inference done 2068/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:49
[09/22 14:20:38] d2.evaluation.evaluator INFO: Inference done 2091/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:44
[09/22 14:20:43] d2.evaluation.evaluator INFO: Inference done 2114/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:39
[09/22 14:20:48] d2.evaluation.evaluator INFO: Inference done 2137/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:34
[09/22 14:20:53] d2.evaluation.evaluator INFO: Inference done 2160/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:29
[09/22 14:20:58] d2.evaluation.evaluator INFO: Inference done 2184/5000. Dataloading: 0.0012 s/iter. Inference: 0.2186 s/iter. Eval: 0.0016 s/iter. Total: 0.2215 s/iter. ETA=0:10:23
[09/22 14:21:03] d2.evaluation.evaluator INFO: Inference done 2206/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2216 s/iter. ETA=0:10:19
[09/22 14:21:08] d2.evaluation.evaluator INFO: Inference done 2229/5000. Dataloading: 0.0012 s/iter. Inference: 0.2187 s/iter. Eval: 0.0016 s/iter. Total: 0.2215 s/iter. ETA=0:10:13
[09/22 14:21:14] d2.evaluation.evaluator INFO: Inference done 2251/5000. Dataloading: 0.0012 s/iter. Inference: 0.2188 s/iter. Eval: 0.0016 s/iter. Total: 0.2217 s/iter. ETA=0:10:09
[09/22 14:21:19] d2.evaluation.evaluator INFO: Inference done 2274/5000. Dataloading: 0.0012 s/iter. Inference: 0.2188 s/iter. Eval: 0.0016 s/iter. Total: 0.2217 s/iter. ETA=0:10:04
[09/22 14:21:24] d2.evaluation.evaluator INFO: Inference done 2297/5000. Dataloading: 0.0012 s/iter. Inference: 0.2188 s/iter. Eval: 0.0016 s/iter. Total: 0.2217 s/iter. ETA=0:09:59
[09/22 14:21:29] d2.evaluation.evaluator INFO: Inference done 2319/5000. Dataloading: 0.0012 s/iter. Inference: 0.2189 s/iter. Eval: 0.0016 s/iter. Total: 0.2217 s/iter. ETA=0:09:54
[09/22 14:21:34] d2.evaluation.evaluator INFO: Inference done 2342/5000. Dataloading: 0.0012 s/iter. Inference: 0.2189 s/iter. Eval: 0.0016 s/iter. Total: 0.2218 s/iter. ETA=0:09:49
[09/22 14:21:39] d2.evaluation.evaluator INFO: Inference done 2364/5000. Dataloading: 0.0012 s/iter. Inference: 0.2190 s/iter. Eval: 0.0016 s/iter. Total: 0.2218 s/iter. ETA=0:09:44
[09/22 14:21:44] d2.evaluation.evaluator INFO: Inference done 2387/5000. Dataloading: 0.0012 s/iter. Inference: 0.2190 s/iter. Eval: 0.0016 s/iter. Total: 0.2218 s/iter. ETA=0:09:39
[09/22 14:21:49] d2.evaluation.evaluator INFO: Inference done 2410/5000. Dataloading: 0.0012 s/iter. Inference: 0.2190 s/iter. Eval: 0.0016 s/iter. Total: 0.2219 s/iter. ETA=0:09:34
[09/22 14:21:54] d2.evaluation.evaluator INFO: Inference done 2433/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2219 s/iter. ETA=0:09:29
[09/22 14:22:00] d2.evaluation.evaluator INFO: Inference done 2455/5000. Dataloading: 0.0012 s/iter. Inference: 0.2192 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:09:24
[09/22 14:22:05] d2.evaluation.evaluator INFO: Inference done 2479/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:09:19
[09/22 14:22:10] d2.evaluation.evaluator INFO: Inference done 2502/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:09:14
[09/22 14:22:15] d2.evaluation.evaluator INFO: Inference done 2525/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:09:09
[09/22 14:22:20] d2.evaluation.evaluator INFO: Inference done 2548/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:09:04
[09/22 14:22:25] d2.evaluation.evaluator INFO: Inference done 2571/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:08:59
[09/22 14:22:30] d2.evaluation.evaluator INFO: Inference done 2595/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2219 s/iter. ETA=0:08:53
[09/22 14:22:35] d2.evaluation.evaluator INFO: Inference done 2617/5000. Dataloading: 0.0012 s/iter. Inference: 0.2191 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:08:48
[09/22 14:22:41] d2.evaluation.evaluator INFO: Inference done 2640/5000. Dataloading: 0.0012 s/iter. Inference: 0.2192 s/iter. Eval: 0.0016 s/iter. Total: 0.2220 s/iter. ETA=0:08:43
[09/22 14:22:46] d2.evaluation.evaluator INFO: Inference done 2663/5000. Dataloading: 0.0012 s/iter. Inference: 0.2192 s/iter. Eval: 0.0016 s/iter. Total: 0.2221 s/iter. ETA=0:08:38
[09/22 14:22:51] d2.evaluation.evaluator INFO: Inference done 2685/5000. Dataloading: 0.0012 s/iter. Inference: 0.2193 s/iter. Eval: 0.0016 s/iter. Total: 0.2221 s/iter. ETA=0:08:34
[09/22 14:22:56] d2.evaluation.evaluator INFO: Inference done 2708/5000. Dataloading: 0.0012 s/iter. Inference: 0.2193 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:08:29
[09/22 14:23:01] d2.evaluation.evaluator INFO: Inference done 2731/5000. Dataloading: 0.0012 s/iter. Inference: 0.2194 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:08:24
[09/22 14:23:07] d2.evaluation.evaluator INFO: Inference done 2755/5000. Dataloading: 0.0012 s/iter. Inference: 0.2193 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:08:18
[09/22 14:23:12] d2.evaluation.evaluator INFO: Inference done 2778/5000. Dataloading: 0.0012 s/iter. Inference: 0.2193 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:08:13
[09/22 14:23:17] d2.evaluation.evaluator INFO: Inference done 2801/5000. Dataloading: 0.0012 s/iter. Inference: 0.2193 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:08:08
[09/22 14:23:22] d2.evaluation.evaluator INFO: Inference done 2824/5000. Dataloading: 0.0012 s/iter. Inference: 0.2193 s/iter. Eval: 0.0016 s/iter. Total: 0.2221 s/iter. ETA=0:08:03
[09/22 14:23:27] d2.evaluation.evaluator INFO: Inference done 2846/5000. Dataloading: 0.0012 s/iter. Inference: 0.2194 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:07:58
[09/22 14:23:32] d2.evaluation.evaluator INFO: Inference done 2869/5000. Dataloading: 0.0012 s/iter. Inference: 0.2194 s/iter. Eval: 0.0016 s/iter. Total: 0.2222 s/iter. ETA=0:07:53
[09/22 14:23:37] d2.evaluation.evaluator INFO: Inference done 2891/5000. Dataloading: 0.0012 s/iter. Inference: 0.2195 s/iter. Eval: 0.0016 s/iter. Total: 0.2223 s/iter. ETA=0:07:48
[09/22 14:23:42] d2.evaluation.evaluator INFO: Inference done 2914/5000. Dataloading: 0.0012 s/iter. Inference: 0.2194 s/iter. Eval: 0.0016 s/iter. Total: 0.2223 s/iter. ETA=0:07:43
[09/22 14:23:47] d2.evaluation.evaluator INFO: Inference done 2937/5000. Dataloading: 0.0012 s/iter. Inference: 0.2195 s/iter. Eval: 0.0016 s/iter. Total: 0.2223 s/iter. ETA=0:07:38
[09/22 14:23:53] d2.evaluation.evaluator INFO: Inference done 2961/5000. Dataloading: 0.0012 s/iter. Inference: 0.2194 s/iter. Eval: 0.0016 s/iter. Total: 0.2223 s/iter. ETA=0:07:33
[09/22 14:23:58] d2.evaluation.evaluator INFO: Inference done 2984/5000. Dataloading: 0.0012 s/iter. Inference: 0.2195 s/iter. Eval: 0.0016 s/iter. Total: 0.2223 s/iter. ETA=0:07:28
[09/22 14:24:03] d2.evaluation.evaluator INFO: Inference done 3007/5000. Dataloading: 0.0012 s/iter. Inference: 0.2195 s/iter. Eval: 0.0016 s/iter. Total: 0.2223 s/iter. ETA=0:07:23
[09/22 14:24:58] d2.evaluation.evaluator INFO: Inference done 3011/5000. Dataloading: 0.0012 s/iter. Inference: 0.2374 s/iter. Eval: 0.0016 s/iter. Total: 0.2403 s/iter. ETA=0:07:57
[09/22 14:25:03] d2.evaluation.evaluator INFO: Inference done 3035/5000. Dataloading: 0.0012 s/iter. Inference: 0.2372 s/iter. Eval: 0.0016 s/iter. Total: 0.2401 s/iter. ETA=0:07:51
[09/22 14:25:08] d2.evaluation.evaluator INFO: Inference done 3058/5000. Dataloading: 0.0012 s/iter. Inference: 0.2371 s/iter. Eval: 0.0016 s/iter. Total: 0.2400 s/iter. ETA=0:07:45
[09/22 14:25:13] d2.evaluation.evaluator INFO: Inference done 3081/5000. Dataloading: 0.0012 s/iter. Inference: 0.2370 s/iter. Eval: 0.0016 s/iter. Total: 0.2398 s/iter. ETA=0:07:40
[09/22 14:25:18] d2.evaluation.evaluator INFO: Inference done 3104/5000. Dataloading: 0.0012 s/iter. Inference: 0.2368 s/iter. Eval: 0.0016 s/iter. Total: 0.2396 s/iter. ETA=0:07:34
[09/22 14:25:23] d2.evaluation.evaluator INFO: Inference done 3128/5000. Dataloading: 0.0012 s/iter. Inference: 0.2366 s/iter. Eval: 0.0016 s/iter. Total: 0.2394 s/iter. ETA=0:07:28
[09/22 14:25:29] d2.evaluation.evaluator INFO: Inference done 3152/5000. Dataloading: 0.0012 s/iter. Inference: 0.2364 s/iter. Eval: 0.0016 s/iter. Total: 0.2393 s/iter. ETA=0:07:22
[09/22 14:25:34] d2.evaluation.evaluator INFO: Inference done 3176/5000. Dataloading: 0.0012 s/iter. Inference: 0.2363 s/iter. Eval: 0.0016 s/iter. Total: 0.2391 s/iter. ETA=0:07:16
[09/22 14:25:39] d2.evaluation.evaluator INFO: Inference done 3199/5000. Dataloading: 0.0012 s/iter. Inference: 0.2361 s/iter. Eval: 0.0015 s/iter. Total: 0.2389 s/iter. ETA=0:07:10
[09/22 14:25:44] d2.evaluation.evaluator INFO: Inference done 3222/5000. Dataloading: 0.0012 s/iter. Inference: 0.2360 s/iter. Eval: 0.0016 s/iter. Total: 0.2388 s/iter. ETA=0:07:04
[09/22 14:25:49] d2.evaluation.evaluator INFO: Inference done 3245/5000. Dataloading: 0.0012 s/iter. Inference: 0.2359 s/iter. Eval: 0.0015 s/iter. Total: 0.2387 s/iter. ETA=0:06:58
[09/22 14:25:54] d2.evaluation.evaluator INFO: Inference done 3269/5000. Dataloading: 0.0012 s/iter. Inference: 0.2358 s/iter. Eval: 0.0015 s/iter. Total: 0.2386 s/iter. ETA=0:06:52
[09/22 14:25:59] d2.evaluation.evaluator INFO: Inference done 3291/5000. Dataloading: 0.0012 s/iter. Inference: 0.2357 s/iter. Eval: 0.0015 s/iter. Total: 0.2385 s/iter. ETA=0:06:47
[09/22 14:26:04] d2.evaluation.evaluator INFO: Inference done 3314/5000. Dataloading: 0.0012 s/iter. Inference: 0.2356 s/iter. Eval: 0.0015 s/iter. Total: 0.2384 s/iter. ETA=0:06:41
[09/22 14:26:10] d2.evaluation.evaluator INFO: Inference done 3337/5000. Dataloading: 0.0012 s/iter. Inference: 0.2355 s/iter. Eval: 0.0015 s/iter. Total: 0.2383 s/iter. ETA=0:06:36
[09/22 14:26:15] d2.evaluation.evaluator INFO: Inference done 3360/5000. Dataloading: 0.0012 s/iter. Inference: 0.2354 s/iter. Eval: 0.0015 s/iter. Total: 0.2381 s/iter. ETA=0:06:30
[09/22 14:26:20] d2.evaluation.evaluator INFO: Inference done 3383/5000. Dataloading: 0.0012 s/iter. Inference: 0.2353 s/iter. Eval: 0.0015 s/iter. Total: 0.2381 s/iter. ETA=0:06:24
[09/22 14:26:25] d2.evaluation.evaluator INFO: Inference done 3407/5000. Dataloading: 0.0012 s/iter. Inference: 0.2351 s/iter. Eval: 0.0015 s/iter. Total: 0.2379 s/iter. ETA=0:06:18
[09/22 14:26:30] d2.evaluation.evaluator INFO: Inference done 3429/5000. Dataloading: 0.0012 s/iter. Inference: 0.2351 s/iter. Eval: 0.0015 s/iter. Total: 0.2378 s/iter. ETA=0:06:13
[09/22 14:26:35] d2.evaluation.evaluator INFO: Inference done 3452/5000. Dataloading: 0.0012 s/iter. Inference: 0.2349 s/iter. Eval: 0.0015 s/iter. Total: 0.2377 s/iter. ETA=0:06:07
[09/22 14:26:40] d2.evaluation.evaluator INFO: Inference done 3474/5000. Dataloading: 0.0012 s/iter. Inference: 0.2349 s/iter. Eval: 0.0015 s/iter. Total: 0.2377 s/iter. ETA=0:06:02
[09/22 14:26:45] d2.evaluation.evaluator INFO: Inference done 3498/5000. Dataloading: 0.0012 s/iter. Inference: 0.2348 s/iter. Eval: 0.0015 s/iter. Total: 0.2375 s/iter. ETA=0:05:56
[09/22 14:26:50] d2.evaluation.evaluator INFO: Inference done 3521/5000. Dataloading: 0.0012 s/iter. Inference: 0.2347 s/iter. Eval: 0.0015 s/iter. Total: 0.2374 s/iter. ETA=0:05:51
[09/22 14:26:56] d2.evaluation.evaluator INFO: Inference done 3545/5000. Dataloading: 0.0012 s/iter. Inference: 0.2345 s/iter. Eval: 0.0015 s/iter. Total: 0.2373 s/iter. ETA=0:05:45
[09/22 14:27:01] d2.evaluation.evaluator INFO: Inference done 3568/5000. Dataloading: 0.0012 s/iter. Inference: 0.2344 s/iter. Eval: 0.0015 s/iter. Total: 0.2372 s/iter. ETA=0:05:39
[09/22 14:27:06] d2.evaluation.evaluator INFO: Inference done 3591/5000. Dataloading: 0.0012 s/iter. Inference: 0.2343 s/iter. Eval: 0.0015 s/iter. Total: 0.2371 s/iter. ETA=0:05:34
[09/22 14:27:11] d2.evaluation.evaluator INFO: Inference done 3614/5000. Dataloading: 0.0012 s/iter. Inference: 0.2342 s/iter. Eval: 0.0015 s/iter. Total: 0.2370 s/iter. ETA=0:05:28
[09/22 14:27:16] d2.evaluation.evaluator INFO: Inference done 3636/5000. Dataloading: 0.0012 s/iter. Inference: 0.2342 s/iter. Eval: 0.0015 s/iter. Total: 0.2370 s/iter. ETA=0:05:23
[09/22 14:27:21] d2.evaluation.evaluator INFO: Inference done 3659/5000. Dataloading: 0.0012 s/iter. Inference: 0.2341 s/iter. Eval: 0.0015 s/iter. Total: 0.2369 s/iter. ETA=0:05:17
[09/22 14:27:26] d2.evaluation.evaluator INFO: Inference done 3682/5000. Dataloading: 0.0012 s/iter. Inference: 0.2340 s/iter. Eval: 0.0015 s/iter. Total: 0.2368 s/iter. ETA=0:05:12
[09/22 14:27:32] d2.evaluation.evaluator INFO: Inference done 3705/5000. Dataloading: 0.0012 s/iter. Inference: 0.2339 s/iter. Eval: 0.0015 s/iter. Total: 0.2367 s/iter. ETA=0:05:06
[09/22 14:27:37] d2.evaluation.evaluator INFO: Inference done 3728/5000. Dataloading: 0.0012 s/iter. Inference: 0.2339 s/iter. Eval: 0.0015 s/iter. Total: 0.2367 s/iter. ETA=0:05:01
[09/22 14:27:42] d2.evaluation.evaluator INFO: Inference done 3751/5000. Dataloading: 0.0012 s/iter. Inference: 0.2338 s/iter. Eval: 0.0015 s/iter. Total: 0.2366 s/iter. ETA=0:04:55
[09/22 14:27:47] d2.evaluation.evaluator INFO: Inference done 3774/5000. Dataloading: 0.0012 s/iter. Inference: 0.2337 s/iter. Eval: 0.0015 s/iter. Total: 0.2365 s/iter. ETA=0:04:49
[09/22 14:27:52] d2.evaluation.evaluator INFO: Inference done 3796/5000. Dataloading: 0.0012 s/iter. Inference: 0.2336 s/iter. Eval: 0.0015 s/iter. Total: 0.2364 s/iter. ETA=0:04:44
[09/22 14:27:57] d2.evaluation.evaluator INFO: Inference done 3818/5000. Dataloading: 0.0012 s/iter. Inference: 0.2336 s/iter. Eval: 0.0015 s/iter. Total: 0.2364 s/iter. ETA=0:04:39
[09/22 14:28:02] d2.evaluation.evaluator INFO: Inference done 3840/5000. Dataloading: 0.0012 s/iter. Inference: 0.2335 s/iter. Eval: 0.0015 s/iter. Total: 0.2363 s/iter. ETA=0:04:34
[09/22 14:28:07] d2.evaluation.evaluator INFO: Inference done 3862/5000. Dataloading: 0.0012 s/iter. Inference: 0.2335 s/iter. Eval: 0.0015 s/iter. Total: 0.2363 s/iter. ETA=0:04:28
[09/22 14:28:12] d2.evaluation.evaluator INFO: Inference done 3885/5000. Dataloading: 0.0012 s/iter. Inference: 0.2334 s/iter. Eval: 0.0015 s/iter. Total: 0.2362 s/iter. ETA=0:04:23
[09/22 14:28:17] d2.evaluation.evaluator INFO: Inference done 3908/5000. Dataloading: 0.0012 s/iter. Inference: 0.2333 s/iter. Eval: 0.0015 s/iter. Total: 0.2361 s/iter. ETA=0:04:17
[09/22 14:28:22] d2.evaluation.evaluator INFO: Inference done 3931/5000. Dataloading: 0.0012 s/iter. Inference: 0.2332 s/iter. Eval: 0.0015 s/iter. Total: 0.2360 s/iter. ETA=0:04:12
[09/22 14:28:27] d2.evaluation.evaluator INFO: Inference done 3954/5000. Dataloading: 0.0012 s/iter. Inference: 0.2331 s/iter. Eval: 0.0015 s/iter. Total: 0.2359 s/iter. ETA=0:04:06
[09/22 14:28:32] d2.evaluation.evaluator INFO: Inference done 3977/5000. Dataloading: 0.0012 s/iter. Inference: 0.2330 s/iter. Eval: 0.0015 s/iter. Total: 0.2358 s/iter. ETA=0:04:01
[09/22 14:28:37] d2.evaluation.evaluator INFO: Inference done 4000/5000. Dataloading: 0.0012 s/iter. Inference: 0.2329 s/iter. Eval: 0.0015 s/iter. Total: 0.2357 s/iter. ETA=0:03:55
[09/22 14:28:43] d2.evaluation.evaluator INFO: Inference done 4024/5000. Dataloading: 0.0012 s/iter. Inference: 0.2328 s/iter. Eval: 0.0015 s/iter. Total: 0.2356 s/iter. ETA=0:03:49
[09/22 14:28:48] d2.evaluation.evaluator INFO: Inference done 4046/5000. Dataloading: 0.0012 s/iter. Inference: 0.2328 s/iter. Eval: 0.0015 s/iter. Total: 0.2356 s/iter. ETA=0:03:44
[09/22 14:28:53] d2.evaluation.evaluator INFO: Inference done 4069/5000. Dataloading: 0.0012 s/iter. Inference: 0.2327 s/iter. Eval: 0.0015 s/iter. Total: 0.2355 s/iter. ETA=0:03:39
[09/22 14:28:58] d2.evaluation.evaluator INFO: Inference done 4092/5000. Dataloading: 0.0012 s/iter. Inference: 0.2326 s/iter. Eval: 0.0015 s/iter. Total: 0.2354 s/iter. ETA=0:03:33
[09/22 14:29:03] d2.evaluation.evaluator INFO: Inference done 4114/5000. Dataloading: 0.0012 s/iter. Inference: 0.2326 s/iter. Eval: 0.0015 s/iter. Total: 0.2354 s/iter. ETA=0:03:28
[09/22 14:29:08] d2.evaluation.evaluator INFO: Inference done 4136/5000. Dataloading: 0.0012 s/iter. Inference: 0.2326 s/iter. Eval: 0.0015 s/iter. Total: 0.2354 s/iter. ETA=0:03:23
[09/22 14:29:13] d2.evaluation.evaluator INFO: Inference done 4159/5000. Dataloading: 0.0012 s/iter. Inference: 0.2325 s/iter. Eval: 0.0015 s/iter. Total: 0.2353 s/iter. ETA=0:03:17
[09/22 14:29:18] d2.evaluation.evaluator INFO: Inference done 4183/5000. Dataloading: 0.0012 s/iter. Inference: 0.2324 s/iter. Eval: 0.0015 s/iter. Total: 0.2352 s/iter. ETA=0:03:12
[09/22 14:29:23] d2.evaluation.evaluator INFO: Inference done 4206/5000. Dataloading: 0.0012 s/iter. Inference: 0.2323 s/iter. Eval: 0.0015 s/iter. Total: 0.2351 s/iter. ETA=0:03:06
[09/22 14:29:28] d2.evaluation.evaluator INFO: Inference done 4229/5000. Dataloading: 0.0012 s/iter. Inference: 0.2322 s/iter. Eval: 0.0015 s/iter. Total: 0.2350 s/iter. ETA=0:03:01
[09/22 14:29:33] d2.evaluation.evaluator INFO: Inference done 4253/5000. Dataloading: 0.0012 s/iter. Inference: 0.2321 s/iter. Eval: 0.0015 s/iter. Total: 0.2349 s/iter. ETA=0:02:55
[09/22 14:29:39] d2.evaluation.evaluator INFO: Inference done 4276/5000. Dataloading: 0.0012 s/iter. Inference: 0.2320 s/iter. Eval: 0.0015 s/iter. Total: 0.2348 s/iter. ETA=0:02:50
[09/22 14:29:44] d2.evaluation.evaluator INFO: Inference done 4300/5000. Dataloading: 0.0012 s/iter. Inference: 0.2319 s/iter. Eval: 0.0015 s/iter. Total: 0.2347 s/iter. ETA=0:02:44
[09/22 14:29:49] d2.evaluation.evaluator INFO: Inference done 4323/5000. Dataloading: 0.0012 s/iter. Inference: 0.2319 s/iter. Eval: 0.0015 s/iter. Total: 0.2346 s/iter. ETA=0:02:38
[09/22 14:29:54] d2.evaluation.evaluator INFO: Inference done 4346/5000. Dataloading: 0.0012 s/iter. Inference: 0.2318 s/iter. Eval: 0.0015 s/iter. Total: 0.2346 s/iter. ETA=0:02:33
[09/22 14:29:59] d2.evaluation.evaluator INFO: Inference done 4369/5000. Dataloading: 0.0012 s/iter. Inference: 0.2317 s/iter. Eval: 0.0015 s/iter. Total: 0.2345 s/iter. ETA=0:02:27
[09/22 14:30:04] d2.evaluation.evaluator INFO: Inference done 4393/5000. Dataloading: 0.0012 s/iter. Inference: 0.2316 s/iter. Eval: 0.0015 s/iter. Total: 0.2344 s/iter. ETA=0:02:22
[09/22 14:30:09] d2.evaluation.evaluator INFO: Inference done 4416/5000. Dataloading: 0.0012 s/iter. Inference: 0.2316 s/iter. Eval: 0.0015 s/iter. Total: 0.2344 s/iter. ETA=0:02:16
[09/22 14:30:14] d2.evaluation.evaluator INFO: Inference done 4439/5000. Dataloading: 0.0012 s/iter. Inference: 0.2315 s/iter. Eval: 0.0015 s/iter. Total: 0.2343 s/iter. ETA=0:02:11
[09/22 14:30:20] d2.evaluation.evaluator INFO: Inference done 4461/5000. Dataloading: 0.0012 s/iter. Inference: 0.2315 s/iter. Eval: 0.0015 s/iter. Total: 0.2343 s/iter. ETA=0:02:06
[09/22 14:30:25] d2.evaluation.evaluator INFO: Inference done 4484/5000. Dataloading: 0.0012 s/iter. Inference: 0.2314 s/iter. Eval: 0.0015 s/iter. Total: 0.2342 s/iter. ETA=0:02:00
[09/22 14:30:30] d2.evaluation.evaluator INFO: Inference done 4507/5000. Dataloading: 0.0012 s/iter. Inference: 0.2314 s/iter. Eval: 0.0015 s/iter. Total: 0.2341 s/iter. ETA=0:01:55
[09/22 14:30:35] d2.evaluation.evaluator INFO: Inference done 4530/5000. Dataloading: 0.0012 s/iter. Inference: 0.2313 s/iter. Eval: 0.0015 s/iter. Total: 0.2341 s/iter. ETA=0:01:50
[09/22 14:30:40] d2.evaluation.evaluator INFO: Inference done 4554/5000. Dataloading: 0.0012 s/iter. Inference: 0.2312 s/iter. Eval: 0.0015 s/iter. Total: 0.2340 s/iter. ETA=0:01:44
[09/22 14:30:45] d2.evaluation.evaluator INFO: Inference done 4577/5000. Dataloading: 0.0012 s/iter. Inference: 0.2312 s/iter. Eval: 0.0015 s/iter. Total: 0.2339 s/iter. ETA=0:01:38
[09/22 14:30:50] d2.evaluation.evaluator INFO: Inference done 4600/5000. Dataloading: 0.0012 s/iter. Inference: 0.2311 s/iter. Eval: 0.0015 s/iter. Total: 0.2339 s/iter. ETA=0:01:33
[09/22 14:30:55] d2.evaluation.evaluator INFO: Inference done 4623/5000. Dataloading: 0.0012 s/iter. Inference: 0.2311 s/iter. Eval: 0.0015 s/iter. Total: 0.2338 s/iter. ETA=0:01:28
[09/22 14:31:01] d2.evaluation.evaluator INFO: Inference done 4646/5000. Dataloading: 0.0012 s/iter. Inference: 0.2310 s/iter. Eval: 0.0015 s/iter. Total: 0.2338 s/iter. ETA=0:01:22
[09/22 14:31:06] d2.evaluation.evaluator INFO: Inference done 4669/5000. Dataloading: 0.0012 s/iter. Inference: 0.2310 s/iter. Eval: 0.0015 s/iter. Total: 0.2337 s/iter. ETA=0:01:17
[09/22 14:31:11] d2.evaluation.evaluator INFO: Inference done 4692/5000. Dataloading: 0.0012 s/iter. Inference: 0.2309 s/iter. Eval: 0.0015 s/iter. Total: 0.2336 s/iter. ETA=0:01:11
[09/22 14:31:16] d2.evaluation.evaluator INFO: Inference done 4715/5000. Dataloading: 0.0012 s/iter. Inference: 0.2308 s/iter. Eval: 0.0015 s/iter. Total: 0.2336 s/iter. ETA=0:01:06
[09/22 14:31:21] d2.evaluation.evaluator INFO: Inference done 4738/5000. Dataloading: 0.0012 s/iter. Inference: 0.2308 s/iter. Eval: 0.0015 s/iter. Total: 0.2335 s/iter. ETA=0:01:01
[09/22 14:31:26] d2.evaluation.evaluator INFO: Inference done 4760/5000. Dataloading: 0.0012 s/iter. Inference: 0.2308 s/iter. Eval: 0.0015 s/iter. Total: 0.2335 s/iter. ETA=0:00:56
[09/22 14:31:31] d2.evaluation.evaluator INFO: Inference done 4783/5000. Dataloading: 0.0012 s/iter. Inference: 0.2307 s/iter. Eval: 0.0015 s/iter. Total: 0.2335 s/iter. ETA=0:00:50
[09/22 14:31:36] d2.evaluation.evaluator INFO: Inference done 4806/5000. Dataloading: 0.0012 s/iter. Inference: 0.2307 s/iter. Eval: 0.0015 s/iter. Total: 0.2334 s/iter. ETA=0:00:45
[09/22 14:31:41] d2.evaluation.evaluator INFO: Inference done 4830/5000. Dataloading: 0.0012 s/iter. Inference: 0.2306 s/iter. Eval: 0.0015 s/iter. Total: 0.2333 s/iter. ETA=0:00:39
[09/22 14:31:47] d2.evaluation.evaluator INFO: Inference done 4853/5000. Dataloading: 0.0012 s/iter. Inference: 0.2305 s/iter. Eval: 0.0015 s/iter. Total: 0.2333 s/iter. ETA=0:00:34
[09/22 14:31:52] d2.evaluation.evaluator INFO: Inference done 4875/5000. Dataloading: 0.0012 s/iter. Inference: 0.2305 s/iter. Eval: 0.0015 s/iter. Total: 0.2333 s/iter. ETA=0:00:29
[09/22 14:31:57] d2.evaluation.evaluator INFO: Inference done 4897/5000. Dataloading: 0.0012 s/iter. Inference: 0.2305 s/iter. Eval: 0.0015 s/iter. Total: 0.2333 s/iter. ETA=0:00:24
[09/22 14:32:02] d2.evaluation.evaluator INFO: Inference done 4920/5000. Dataloading: 0.0012 s/iter. Inference: 0.2305 s/iter. Eval: 0.0015 s/iter. Total: 0.2332 s/iter. ETA=0:00:18
[09/22 14:32:07] d2.evaluation.evaluator INFO: Inference done 4943/5000. Dataloading: 0.0012 s/iter. Inference: 0.2304 s/iter. Eval: 0.0015 s/iter. Total: 0.2332 s/iter. ETA=0:00:13
[09/22 14:32:12] d2.evaluation.evaluator INFO: Inference done 4965/5000. Dataloading: 0.0012 s/iter. Inference: 0.2304 s/iter. Eval: 0.0015 s/iter. Total: 0.2332 s/iter. ETA=0:00:08
[09/22 14:32:17] d2.evaluation.evaluator INFO: Inference done 4988/5000. Dataloading: 0.0012 s/iter. Inference: 0.2303 s/iter. Eval: 0.0015 s/iter. Total: 0.2331 s/iter. ETA=0:00:02
[09/22 14:32:20] d2.evaluation.evaluator INFO: Total inference time: 0:19:24.190658 (0.233071 s / iter per device, on 1 devices)
[09/22 14:32:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:19:10 (0.230313 s / iter per device, on 1 devices)
[09/22 14:32:20] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[09/22 14:32:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[09/22 14:32:26] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.007  | 0.000  | 0.000 | 0.002 | 0.001 |
[09/22 14:32:26] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.049 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.003 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.033 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[09/22 14:32:35] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[09/22 14:32:35] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.005 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.001 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[09/22 14:32:35] d2.evaluation.testing INFO: copypaste: Task: bbox
[09/22 14:32:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 14:32:35] d2.evaluation.testing INFO: copypaste: 0.0011,0.0070,0.0001,0.0000,0.0025,0.0013
[09/22 14:32:35] d2.evaluation.testing INFO: copypaste: Task: segm
[09/22 14:32:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 14:32:35] d2.evaluation.testing INFO: copypaste: 0.0001,0.0004,0.0000,0.0000,0.0000,0.0001
[09/22 14:33:24] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 14:33:25] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 14:33:25] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 14:33:25] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=2,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 14:33:25] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 14:33:25] d2.utils.env INFO: Using a generated random seed 27125322
[09/22 14:33:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 14:33:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 14:33:26] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 14:33:27] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 14:33:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 14:33:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 14:33:27] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 14:33:27] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 14:33:27] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 14:33:27] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 14:33:31] d2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0008 s/iter. Inference: 0.2588 s/iter. Eval: 0.0186 s/iter. Total: 0.2782 s/iter. ETA=0:23:07
[09/22 14:33:36] d2.evaluation.evaluator INFO: Inference done 29/5000. Dataloading: 0.0011 s/iter. Inference: 0.2662 s/iter. Eval: 0.0139 s/iter. Total: 0.2813 s/iter. ETA=0:23:18
[09/22 14:33:41] d2.evaluation.evaluator INFO: Inference done 48/5000. Dataloading: 0.0012 s/iter. Inference: 0.2581 s/iter. Eval: 0.0142 s/iter. Total: 0.2735 s/iter. ETA=0:22:34
[09/22 14:33:46] d2.evaluation.evaluator INFO: Inference done 66/5000. Dataloading: 0.0012 s/iter. Inference: 0.2609 s/iter. Eval: 0.0135 s/iter. Total: 0.2757 s/iter. ETA=0:22:40
[09/22 14:33:51] d2.evaluation.evaluator INFO: Inference done 85/5000. Dataloading: 0.0012 s/iter. Inference: 0.2603 s/iter. Eval: 0.0138 s/iter. Total: 0.2754 s/iter. ETA=0:22:33
[09/22 14:33:56] d2.evaluation.evaluator INFO: Inference done 104/5000. Dataloading: 0.0012 s/iter. Inference: 0.2571 s/iter. Eval: 0.0148 s/iter. Total: 0.2731 s/iter. ETA=0:22:17
[09/22 14:34:01] d2.evaluation.evaluator INFO: Inference done 123/5000. Dataloading: 0.0012 s/iter. Inference: 0.2565 s/iter. Eval: 0.0149 s/iter. Total: 0.2726 s/iter. ETA=0:22:09
[09/22 14:34:07] d2.evaluation.evaluator INFO: Inference done 141/5000. Dataloading: 0.0012 s/iter. Inference: 0.2585 s/iter. Eval: 0.0154 s/iter. Total: 0.2751 s/iter. ETA=0:22:16
[09/22 14:34:12] d2.evaluation.evaluator INFO: Inference done 159/5000. Dataloading: 0.0012 s/iter. Inference: 0.2594 s/iter. Eval: 0.0153 s/iter. Total: 0.2760 s/iter. ETA=0:22:16
[09/22 14:34:17] d2.evaluation.evaluator INFO: Inference done 178/5000. Dataloading: 0.0012 s/iter. Inference: 0.2588 s/iter. Eval: 0.0155 s/iter. Total: 0.2755 s/iter. ETA=0:22:08
[09/22 14:34:22] d2.evaluation.evaluator INFO: Inference done 196/5000. Dataloading: 0.0012 s/iter. Inference: 0.2595 s/iter. Eval: 0.0155 s/iter. Total: 0.2763 s/iter. ETA=0:22:07
[09/22 14:34:27] d2.evaluation.evaluator INFO: Inference done 215/5000. Dataloading: 0.0012 s/iter. Inference: 0.2592 s/iter. Eval: 0.0150 s/iter. Total: 0.2754 s/iter. ETA=0:21:57
[09/22 14:34:32] d2.evaluation.evaluator INFO: Inference done 234/5000. Dataloading: 0.0012 s/iter. Inference: 0.2595 s/iter. Eval: 0.0147 s/iter. Total: 0.2754 s/iter. ETA=0:21:52
[09/22 14:34:37] d2.evaluation.evaluator INFO: Inference done 252/5000. Dataloading: 0.0012 s/iter. Inference: 0.2598 s/iter. Eval: 0.0148 s/iter. Total: 0.2758 s/iter. ETA=0:21:49
[09/22 14:34:42] d2.evaluation.evaluator INFO: Inference done 270/5000. Dataloading: 0.0012 s/iter. Inference: 0.2602 s/iter. Eval: 0.0148 s/iter. Total: 0.2762 s/iter. ETA=0:21:46
[09/22 14:34:47] d2.evaluation.evaluator INFO: Inference done 288/5000. Dataloading: 0.0012 s/iter. Inference: 0.2605 s/iter. Eval: 0.0149 s/iter. Total: 0.2766 s/iter. ETA=0:21:43
[09/22 14:34:53] d2.evaluation.evaluator INFO: Inference done 306/5000. Dataloading: 0.0012 s/iter. Inference: 0.2610 s/iter. Eval: 0.0149 s/iter. Total: 0.2772 s/iter. ETA=0:21:40
[09/22 14:34:58] d2.evaluation.evaluator INFO: Inference done 324/5000. Dataloading: 0.0012 s/iter. Inference: 0.2612 s/iter. Eval: 0.0150 s/iter. Total: 0.2774 s/iter. ETA=0:21:37
[09/22 14:35:03] d2.evaluation.evaluator INFO: Inference done 342/5000. Dataloading: 0.0012 s/iter. Inference: 0.2617 s/iter. Eval: 0.0152 s/iter. Total: 0.2781 s/iter. ETA=0:21:35
[09/22 14:35:08] d2.evaluation.evaluator INFO: Inference done 359/5000. Dataloading: 0.0012 s/iter. Inference: 0.2626 s/iter. Eval: 0.0153 s/iter. Total: 0.2792 s/iter. ETA=0:21:35
[09/22 14:35:13] d2.evaluation.evaluator INFO: Inference done 377/5000. Dataloading: 0.0012 s/iter. Inference: 0.2627 s/iter. Eval: 0.0152 s/iter. Total: 0.2791 s/iter. ETA=0:21:30
[09/22 14:35:18] d2.evaluation.evaluator INFO: Inference done 397/5000. Dataloading: 0.0012 s/iter. Inference: 0.2619 s/iter. Eval: 0.0148 s/iter. Total: 0.2779 s/iter. ETA=0:21:19
[09/22 14:35:23] d2.evaluation.evaluator INFO: Inference done 416/5000. Dataloading: 0.0012 s/iter. Inference: 0.2619 s/iter. Eval: 0.0147 s/iter. Total: 0.2778 s/iter. ETA=0:21:13
[09/22 14:35:29] d2.evaluation.evaluator INFO: Inference done 435/5000. Dataloading: 0.0012 s/iter. Inference: 0.2619 s/iter. Eval: 0.0145 s/iter. Total: 0.2777 s/iter. ETA=0:21:07
[09/22 14:35:34] d2.evaluation.evaluator INFO: Inference done 454/5000. Dataloading: 0.0012 s/iter. Inference: 0.2617 s/iter. Eval: 0.0144 s/iter. Total: 0.2773 s/iter. ETA=0:21:00
[09/22 14:35:39] d2.evaluation.evaluator INFO: Inference done 472/5000. Dataloading: 0.0012 s/iter. Inference: 0.2623 s/iter. Eval: 0.0142 s/iter. Total: 0.2777 s/iter. ETA=0:20:57
[09/22 14:35:44] d2.evaluation.evaluator INFO: Inference done 490/5000. Dataloading: 0.0012 s/iter. Inference: 0.2626 s/iter. Eval: 0.0143 s/iter. Total: 0.2781 s/iter. ETA=0:20:54
[09/22 14:35:49] d2.evaluation.evaluator INFO: Inference done 509/5000. Dataloading: 0.0012 s/iter. Inference: 0.2624 s/iter. Eval: 0.0144 s/iter. Total: 0.2780 s/iter. ETA=0:20:48
[09/22 14:35:54] d2.evaluation.evaluator INFO: Inference done 528/5000. Dataloading: 0.0012 s/iter. Inference: 0.2622 s/iter. Eval: 0.0143 s/iter. Total: 0.2778 s/iter. ETA=0:20:42
[09/22 14:36:00] d2.evaluation.evaluator INFO: Inference done 546/5000. Dataloading: 0.0012 s/iter. Inference: 0.2623 s/iter. Eval: 0.0145 s/iter. Total: 0.2780 s/iter. ETA=0:20:38
[09/22 14:36:05] d2.evaluation.evaluator INFO: Inference done 565/5000. Dataloading: 0.0012 s/iter. Inference: 0.2623 s/iter. Eval: 0.0144 s/iter. Total: 0.2780 s/iter. ETA=0:20:32
[09/22 14:36:10] d2.evaluation.evaluator INFO: Inference done 583/5000. Dataloading: 0.0012 s/iter. Inference: 0.2626 s/iter. Eval: 0.0145 s/iter. Total: 0.2784 s/iter. ETA=0:20:29
[09/22 14:36:15] d2.evaluation.evaluator INFO: Inference done 602/5000. Dataloading: 0.0012 s/iter. Inference: 0.2621 s/iter. Eval: 0.0145 s/iter. Total: 0.2779 s/iter. ETA=0:20:22
[09/22 14:36:20] d2.evaluation.evaluator INFO: Inference done 620/5000. Dataloading: 0.0012 s/iter. Inference: 0.2624 s/iter. Eval: 0.0145 s/iter. Total: 0.2782 s/iter. ETA=0:20:18
[09/22 14:36:25] d2.evaluation.evaluator INFO: Inference done 638/5000. Dataloading: 0.0012 s/iter. Inference: 0.2625 s/iter. Eval: 0.0146 s/iter. Total: 0.2783 s/iter. ETA=0:20:14
[09/22 14:36:30] d2.evaluation.evaluator INFO: Inference done 656/5000. Dataloading: 0.0012 s/iter. Inference: 0.2624 s/iter. Eval: 0.0147 s/iter. Total: 0.2784 s/iter. ETA=0:20:09
[09/22 14:36:36] d2.evaluation.evaluator INFO: Inference done 675/5000. Dataloading: 0.0012 s/iter. Inference: 0.2625 s/iter. Eval: 0.0146 s/iter. Total: 0.2784 s/iter. ETA=0:20:03
[09/22 14:36:41] d2.evaluation.evaluator INFO: Inference done 693/5000. Dataloading: 0.0012 s/iter. Inference: 0.2626 s/iter. Eval: 0.0146 s/iter. Total: 0.2785 s/iter. ETA=0:19:59
[09/22 14:36:46] d2.evaluation.evaluator INFO: Inference done 711/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:19:55
[09/22 14:36:51] d2.evaluation.evaluator INFO: Inference done 728/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0147 s/iter. Total: 0.2790 s/iter. ETA=0:19:52
[09/22 14:36:56] d2.evaluation.evaluator INFO: Inference done 747/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0147 s/iter. Total: 0.2789 s/iter. ETA=0:19:46
[09/22 14:37:01] d2.evaluation.evaluator INFO: Inference done 766/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:19:40
[09/22 14:37:06] d2.evaluation.evaluator INFO: Inference done 784/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0146 s/iter. Total: 0.2789 s/iter. ETA=0:19:36
[09/22 14:37:12] d2.evaluation.evaluator INFO: Inference done 802/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0146 s/iter. Total: 0.2790 s/iter. ETA=0:19:31
[09/22 14:37:17] d2.evaluation.evaluator INFO: Inference done 820/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:19:26
[09/22 14:37:22] d2.evaluation.evaluator INFO: Inference done 839/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:19:20
[09/22 14:37:27] d2.evaluation.evaluator INFO: Inference done 857/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:19:16
[09/22 14:37:32] d2.evaluation.evaluator INFO: Inference done 876/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:19:10
[09/22 14:37:37] d2.evaluation.evaluator INFO: Inference done 894/5000. Dataloading: 0.0012 s/iter. Inference: 0.2634 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:19:05
[09/22 14:37:42] d2.evaluation.evaluator INFO: Inference done 913/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:18:59
[09/22 14:37:47] d2.evaluation.evaluator INFO: Inference done 931/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:18:54
[09/22 14:37:52] d2.evaluation.evaluator INFO: Inference done 949/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0143 s/iter. Total: 0.2787 s/iter. ETA=0:18:49
[09/22 14:37:57] d2.evaluation.evaluator INFO: Inference done 967/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0143 s/iter. Total: 0.2788 s/iter. ETA=0:18:44
[09/22 14:38:03] d2.evaluation.evaluator INFO: Inference done 985/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0146 s/iter. Total: 0.2791 s/iter. ETA=0:18:40
[09/22 14:38:08] d2.evaluation.evaluator INFO: Inference done 1004/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:18:34
[09/22 14:38:13] d2.evaluation.evaluator INFO: Inference done 1023/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:18:28
[09/22 14:38:18] d2.evaluation.evaluator INFO: Inference done 1041/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:18:23
[09/22 14:38:23] d2.evaluation.evaluator INFO: Inference done 1059/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0146 s/iter. Total: 0.2790 s/iter. ETA=0:18:19
[09/22 14:38:28] d2.evaluation.evaluator INFO: Inference done 1077/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0146 s/iter. Total: 0.2791 s/iter. ETA=0:18:14
[09/22 14:38:33] d2.evaluation.evaluator INFO: Inference done 1095/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0146 s/iter. Total: 0.2791 s/iter. ETA=0:18:09
[09/22 14:38:39] d2.evaluation.evaluator INFO: Inference done 1113/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0146 s/iter. Total: 0.2792 s/iter. ETA=0:18:05
[09/22 14:38:44] d2.evaluation.evaluator INFO: Inference done 1131/5000. Dataloading: 0.0012 s/iter. Inference: 0.2634 s/iter. Eval: 0.0145 s/iter. Total: 0.2792 s/iter. ETA=0:18:00
[09/22 14:38:49] d2.evaluation.evaluator INFO: Inference done 1150/5000. Dataloading: 0.0012 s/iter. Inference: 0.2634 s/iter. Eval: 0.0145 s/iter. Total: 0.2792 s/iter. ETA=0:17:54
[09/22 14:38:54] d2.evaluation.evaluator INFO: Inference done 1167/5000. Dataloading: 0.0012 s/iter. Inference: 0.2636 s/iter. Eval: 0.0145 s/iter. Total: 0.2794 s/iter. ETA=0:17:51
[09/22 14:38:59] d2.evaluation.evaluator INFO: Inference done 1185/5000. Dataloading: 0.0012 s/iter. Inference: 0.2637 s/iter. Eval: 0.0145 s/iter. Total: 0.2795 s/iter. ETA=0:17:46
[09/22 14:39:04] d2.evaluation.evaluator INFO: Inference done 1203/5000. Dataloading: 0.0012 s/iter. Inference: 0.2638 s/iter. Eval: 0.0145 s/iter. Total: 0.2796 s/iter. ETA=0:17:41
[09/22 14:39:09] d2.evaluation.evaluator INFO: Inference done 1221/5000. Dataloading: 0.0012 s/iter. Inference: 0.2638 s/iter. Eval: 0.0146 s/iter. Total: 0.2797 s/iter. ETA=0:17:36
[09/22 14:39:14] d2.evaluation.evaluator INFO: Inference done 1239/5000. Dataloading: 0.0012 s/iter. Inference: 0.2639 s/iter. Eval: 0.0147 s/iter. Total: 0.2798 s/iter. ETA=0:17:32
[09/22 14:39:20] d2.evaluation.evaluator INFO: Inference done 1257/5000. Dataloading: 0.0012 s/iter. Inference: 0.2638 s/iter. Eval: 0.0147 s/iter. Total: 0.2798 s/iter. ETA=0:17:27
[09/22 14:39:25] d2.evaluation.evaluator INFO: Inference done 1276/5000. Dataloading: 0.0012 s/iter. Inference: 0.2637 s/iter. Eval: 0.0147 s/iter. Total: 0.2797 s/iter. ETA=0:17:21
[09/22 14:39:30] d2.evaluation.evaluator INFO: Inference done 1295/5000. Dataloading: 0.0012 s/iter. Inference: 0.2637 s/iter. Eval: 0.0147 s/iter. Total: 0.2796 s/iter. ETA=0:17:16
[09/22 14:39:35] d2.evaluation.evaluator INFO: Inference done 1314/5000. Dataloading: 0.0012 s/iter. Inference: 0.2636 s/iter. Eval: 0.0147 s/iter. Total: 0.2796 s/iter. ETA=0:17:10
[09/22 14:39:40] d2.evaluation.evaluator INFO: Inference done 1333/5000. Dataloading: 0.0012 s/iter. Inference: 0.2635 s/iter. Eval: 0.0147 s/iter. Total: 0.2795 s/iter. ETA=0:17:04
[09/22 14:39:45] d2.evaluation.evaluator INFO: Inference done 1351/5000. Dataloading: 0.0012 s/iter. Inference: 0.2636 s/iter. Eval: 0.0147 s/iter. Total: 0.2796 s/iter. ETA=0:17:00
[09/22 14:39:51] d2.evaluation.evaluator INFO: Inference done 1369/5000. Dataloading: 0.0012 s/iter. Inference: 0.2636 s/iter. Eval: 0.0147 s/iter. Total: 0.2796 s/iter. ETA=0:16:55
[09/22 14:39:56] d2.evaluation.evaluator INFO: Inference done 1388/5000. Dataloading: 0.0012 s/iter. Inference: 0.2634 s/iter. Eval: 0.0147 s/iter. Total: 0.2794 s/iter. ETA=0:16:49
[09/22 14:40:01] d2.evaluation.evaluator INFO: Inference done 1406/5000. Dataloading: 0.0012 s/iter. Inference: 0.2635 s/iter. Eval: 0.0147 s/iter. Total: 0.2794 s/iter. ETA=0:16:44
[09/22 14:40:06] d2.evaluation.evaluator INFO: Inference done 1426/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0146 s/iter. Total: 0.2791 s/iter. ETA=0:16:37
[09/22 14:40:11] d2.evaluation.evaluator INFO: Inference done 1444/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0146 s/iter. Total: 0.2792 s/iter. ETA=0:16:32
[09/22 14:40:16] d2.evaluation.evaluator INFO: Inference done 1463/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0146 s/iter. Total: 0.2791 s/iter. ETA=0:16:27
[09/22 14:40:21] d2.evaluation.evaluator INFO: Inference done 1482/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0146 s/iter. Total: 0.2790 s/iter. ETA=0:16:21
[09/22 14:40:26] d2.evaluation.evaluator INFO: Inference done 1500/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0146 s/iter. Total: 0.2790 s/iter. ETA=0:16:16
[09/22 14:40:31] d2.evaluation.evaluator INFO: Inference done 1520/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:16:10
[09/22 14:40:37] d2.evaluation.evaluator INFO: Inference done 1539/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:16:04
[09/22 14:40:42] d2.evaluation.evaluator INFO: Inference done 1556/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0147 s/iter. Total: 0.2790 s/iter. ETA=0:16:00
[09/22 14:40:47] d2.evaluation.evaluator INFO: Inference done 1575/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0147 s/iter. Total: 0.2789 s/iter. ETA=0:15:55
[09/22 14:40:52] d2.evaluation.evaluator INFO: Inference done 1592/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0148 s/iter. Total: 0.2791 s/iter. ETA=0:15:51
[09/22 14:40:57] d2.evaluation.evaluator INFO: Inference done 1610/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0148 s/iter. Total: 0.2791 s/iter. ETA=0:15:46
[09/22 14:41:02] d2.evaluation.evaluator INFO: Inference done 1629/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0148 s/iter. Total: 0.2791 s/iter. ETA=0:15:40
[09/22 14:41:08] d2.evaluation.evaluator INFO: Inference done 1648/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0148 s/iter. Total: 0.2790 s/iter. ETA=0:15:35
[09/22 14:41:13] d2.evaluation.evaluator INFO: Inference done 1666/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0148 s/iter. Total: 0.2790 s/iter. ETA=0:15:30
[09/22 14:41:18] d2.evaluation.evaluator INFO: Inference done 1685/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0148 s/iter. Total: 0.2790 s/iter. ETA=0:15:24
[09/22 14:41:23] d2.evaluation.evaluator INFO: Inference done 1703/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0148 s/iter. Total: 0.2791 s/iter. ETA=0:15:20
[09/22 14:41:28] d2.evaluation.evaluator INFO: Inference done 1721/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0148 s/iter. Total: 0.2791 s/iter. ETA=0:15:15
[09/22 14:41:33] d2.evaluation.evaluator INFO: Inference done 1740/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0148 s/iter. Total: 0.2790 s/iter. ETA=0:15:09
[09/22 14:41:38] d2.evaluation.evaluator INFO: Inference done 1758/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0147 s/iter. Total: 0.2790 s/iter. ETA=0:15:04
[09/22 14:41:44] d2.evaluation.evaluator INFO: Inference done 1778/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:58
[09/22 14:41:49] d2.evaluation.evaluator INFO: Inference done 1797/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:52
[09/22 14:41:54] d2.evaluation.evaluator INFO: Inference done 1815/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:47
[09/22 14:41:59] d2.evaluation.evaluator INFO: Inference done 1833/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:43
[09/22 14:42:04] d2.evaluation.evaluator INFO: Inference done 1852/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2787 s/iter. ETA=0:14:37
[09/22 14:42:09] d2.evaluation.evaluator INFO: Inference done 1870/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:32
[09/22 14:42:14] d2.evaluation.evaluator INFO: Inference done 1888/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:27
[09/22 14:42:20] d2.evaluation.evaluator INFO: Inference done 1907/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:14:22
[09/22 14:42:25] d2.evaluation.evaluator INFO: Inference done 1925/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:14:17
[09/22 14:42:30] d2.evaluation.evaluator INFO: Inference done 1944/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:14:11
[09/22 14:42:35] d2.evaluation.evaluator INFO: Inference done 1963/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:14:06
[09/22 14:42:40] d2.evaluation.evaluator INFO: Inference done 1981/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:14:01
[09/22 14:42:45] d2.evaluation.evaluator INFO: Inference done 1999/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:13:56
[09/22 14:42:50] d2.evaluation.evaluator INFO: Inference done 2017/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2789 s/iter. ETA=0:13:51
[09/22 14:42:55] d2.evaluation.evaluator INFO: Inference done 2036/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:13:46
[09/22 14:43:01] d2.evaluation.evaluator INFO: Inference done 2055/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2787 s/iter. ETA=0:13:40
[09/22 14:43:06] d2.evaluation.evaluator INFO: Inference done 2074/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:13:35
[09/22 14:43:11] d2.evaluation.evaluator INFO: Inference done 2093/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:13:30
[09/22 14:43:16] d2.evaluation.evaluator INFO: Inference done 2111/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0147 s/iter. Total: 0.2788 s/iter. ETA=0:13:25
[09/22 14:43:21] d2.evaluation.evaluator INFO: Inference done 2130/5000. Dataloading: 0.0012 s/iter. Inference: 0.2627 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:13:19
[09/22 14:43:26] d2.evaluation.evaluator INFO: Inference done 2148/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:13:14
[09/22 14:43:31] d2.evaluation.evaluator INFO: Inference done 2166/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:13:09
[09/22 14:43:36] d2.evaluation.evaluator INFO: Inference done 2185/5000. Dataloading: 0.0012 s/iter. Inference: 0.2627 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:13:04
[09/22 14:43:42] d2.evaluation.evaluator INFO: Inference done 2203/5000. Dataloading: 0.0012 s/iter. Inference: 0.2627 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:12:59
[09/22 14:43:47] d2.evaluation.evaluator INFO: Inference done 2222/5000. Dataloading: 0.0012 s/iter. Inference: 0.2627 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:12:53
[09/22 14:43:52] d2.evaluation.evaluator INFO: Inference done 2240/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:12:49
[09/22 14:43:57] d2.evaluation.evaluator INFO: Inference done 2257/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:12:44
[09/22 14:44:02] d2.evaluation.evaluator INFO: Inference done 2276/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:12:39
[09/22 14:44:07] d2.evaluation.evaluator INFO: Inference done 2295/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2786 s/iter. ETA=0:12:33
[09/22 14:44:13] d2.evaluation.evaluator INFO: Inference done 2314/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:12:28
[09/22 14:44:18] d2.evaluation.evaluator INFO: Inference done 2333/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2786 s/iter. ETA=0:12:23
[09/22 14:44:23] d2.evaluation.evaluator INFO: Inference done 2351/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2786 s/iter. ETA=0:12:17
[09/22 14:44:28] d2.evaluation.evaluator INFO: Inference done 2370/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2785 s/iter. ETA=0:12:12
[09/22 14:44:33] d2.evaluation.evaluator INFO: Inference done 2388/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2786 s/iter. ETA=0:12:07
[09/22 14:44:38] d2.evaluation.evaluator INFO: Inference done 2406/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2786 s/iter. ETA=0:12:02
[09/22 14:44:43] d2.evaluation.evaluator INFO: Inference done 2424/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:11:58
[09/22 14:44:49] d2.evaluation.evaluator INFO: Inference done 2442/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2788 s/iter. ETA=0:11:53
[09/22 14:44:54] d2.evaluation.evaluator INFO: Inference done 2460/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2788 s/iter. ETA=0:11:48
[09/22 14:44:59] d2.evaluation.evaluator INFO: Inference done 2479/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:11:42
[09/22 14:45:04] d2.evaluation.evaluator INFO: Inference done 2498/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:11:37
[09/22 14:45:09] d2.evaluation.evaluator INFO: Inference done 2516/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:11:32
[09/22 14:45:14] d2.evaluation.evaluator INFO: Inference done 2535/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:11:26
[09/22 14:45:19] d2.evaluation.evaluator INFO: Inference done 2553/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:11:21
[09/22 14:45:24] d2.evaluation.evaluator INFO: Inference done 2571/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:11:16
[09/22 14:45:29] d2.evaluation.evaluator INFO: Inference done 2590/5000. Dataloading: 0.0012 s/iter. Inference: 0.2627 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:11:11
[09/22 14:45:34] d2.evaluation.evaluator INFO: Inference done 2608/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2786 s/iter. ETA=0:11:06
[09/22 14:45:40] d2.evaluation.evaluator INFO: Inference done 2626/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:11:01
[09/22 14:45:45] d2.evaluation.evaluator INFO: Inference done 2643/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:10:57
[09/22 14:45:50] d2.evaluation.evaluator INFO: Inference done 2661/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:10:52
[09/22 14:45:55] d2.evaluation.evaluator INFO: Inference done 2679/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0146 s/iter. Total: 0.2789 s/iter. ETA=0:10:47
[09/22 14:46:00] d2.evaluation.evaluator INFO: Inference done 2697/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0146 s/iter. Total: 0.2789 s/iter. ETA=0:10:42
[09/22 14:46:05] d2.evaluation.evaluator INFO: Inference done 2716/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2788 s/iter. ETA=0:10:36
[09/22 14:46:10] d2.evaluation.evaluator INFO: Inference done 2734/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:10:31
[09/22 14:46:15] d2.evaluation.evaluator INFO: Inference done 2753/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:10:26
[09/22 14:46:20] d2.evaluation.evaluator INFO: Inference done 2771/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:10:21
[09/22 14:46:25] d2.evaluation.evaluator INFO: Inference done 2789/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:10:16
[09/22 14:46:30] d2.evaluation.evaluator INFO: Inference done 2808/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:10:10
[09/22 14:46:36] d2.evaluation.evaluator INFO: Inference done 2827/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:10:05
[09/22 14:46:41] d2.evaluation.evaluator INFO: Inference done 2845/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:10:00
[09/22 14:46:46] d2.evaluation.evaluator INFO: Inference done 2864/5000. Dataloading: 0.0012 s/iter. Inference: 0.2628 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:09:55
[09/22 14:46:51] d2.evaluation.evaluator INFO: Inference done 2882/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:09:50
[09/22 14:46:56] d2.evaluation.evaluator INFO: Inference done 2900/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2788 s/iter. ETA=0:09:45
[09/22 14:47:01] d2.evaluation.evaluator INFO: Inference done 2918/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:09:40
[09/22 14:47:07] d2.evaluation.evaluator INFO: Inference done 2937/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2788 s/iter. ETA=0:09:35
[09/22 14:47:12] d2.evaluation.evaluator INFO: Inference done 2956/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0146 s/iter. Total: 0.2787 s/iter. ETA=0:09:29
[09/22 14:47:17] d2.evaluation.evaluator INFO: Inference done 2975/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:09:24
[09/22 14:47:22] d2.evaluation.evaluator INFO: Inference done 2993/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:09:19
[09/22 14:47:27] d2.evaluation.evaluator INFO: Inference done 3012/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2786 s/iter. ETA=0:09:13
[09/22 14:47:32] d2.evaluation.evaluator INFO: Inference done 3030/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:09:08
[09/22 14:47:37] d2.evaluation.evaluator INFO: Inference done 3049/5000. Dataloading: 0.0012 s/iter. Inference: 0.2629 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:09:03
[09/22 14:47:43] d2.evaluation.evaluator INFO: Inference done 3067/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:58
[09/22 14:47:48] d2.evaluation.evaluator INFO: Inference done 3085/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:53
[09/22 14:47:53] d2.evaluation.evaluator INFO: Inference done 3104/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:48
[09/22 14:47:58] d2.evaluation.evaluator INFO: Inference done 3122/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:43
[09/22 14:48:03] d2.evaluation.evaluator INFO: Inference done 3140/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2788 s/iter. ETA=0:08:38
[09/22 14:48:08] d2.evaluation.evaluator INFO: Inference done 3159/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:33
[09/22 14:48:13] d2.evaluation.evaluator INFO: Inference done 3177/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:28
[09/22 14:48:19] d2.evaluation.evaluator INFO: Inference done 3196/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:22
[09/22 14:48:24] d2.evaluation.evaluator INFO: Inference done 3214/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:08:17
[09/22 14:48:29] d2.evaluation.evaluator INFO: Inference done 3233/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:08:12
[09/22 14:48:34] d2.evaluation.evaluator INFO: Inference done 3252/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:08:07
[09/22 14:48:39] d2.evaluation.evaluator INFO: Inference done 3270/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2787 s/iter. ETA=0:08:02
[09/22 14:48:44] d2.evaluation.evaluator INFO: Inference done 3287/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2788 s/iter. ETA=0:07:57
[09/22 14:48:49] d2.evaluation.evaluator INFO: Inference done 3305/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:52
[09/22 14:48:55] d2.evaluation.evaluator INFO: Inference done 3323/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:47
[09/22 14:49:00] d2.evaluation.evaluator INFO: Inference done 3342/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:42
[09/22 14:49:05] d2.evaluation.evaluator INFO: Inference done 3360/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:37
[09/22 14:49:10] d2.evaluation.evaluator INFO: Inference done 3378/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:32
[09/22 14:49:15] d2.evaluation.evaluator INFO: Inference done 3397/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:27
[09/22 14:49:20] d2.evaluation.evaluator INFO: Inference done 3416/5000. Dataloading: 0.0012 s/iter. Inference: 0.2630 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:21
[09/22 14:49:26] d2.evaluation.evaluator INFO: Inference done 3434/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:16
[09/22 14:49:31] d2.evaluation.evaluator INFO: Inference done 3452/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:11
[09/22 14:49:36] d2.evaluation.evaluator INFO: Inference done 3470/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:07:06
[09/22 14:49:41] d2.evaluation.evaluator INFO: Inference done 3489/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:07:01
[09/22 14:49:46] d2.evaluation.evaluator INFO: Inference done 3507/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:56
[09/22 14:49:51] d2.evaluation.evaluator INFO: Inference done 3526/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:51
[09/22 14:49:56] d2.evaluation.evaluator INFO: Inference done 3545/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:45
[09/22 14:50:01] d2.evaluation.evaluator INFO: Inference done 3563/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:40
[09/22 14:50:07] d2.evaluation.evaluator INFO: Inference done 3581/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:35
[09/22 14:50:12] d2.evaluation.evaluator INFO: Inference done 3599/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:30
[09/22 14:50:17] d2.evaluation.evaluator INFO: Inference done 3618/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:25
[09/22 14:50:22] d2.evaluation.evaluator INFO: Inference done 3636/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:20
[09/22 14:50:27] d2.evaluation.evaluator INFO: Inference done 3654/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:15
[09/22 14:50:32] d2.evaluation.evaluator INFO: Inference done 3672/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:06:10
[09/22 14:50:37] d2.evaluation.evaluator INFO: Inference done 3691/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:06:05
[09/22 14:50:43] d2.evaluation.evaluator INFO: Inference done 3709/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:06:00
[09/22 14:50:48] d2.evaluation.evaluator INFO: Inference done 3727/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:05:55
[09/22 14:50:53] d2.evaluation.evaluator INFO: Inference done 3745/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:05:50
[09/22 14:50:58] d2.evaluation.evaluator INFO: Inference done 3764/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:05:44
[09/22 14:51:03] d2.evaluation.evaluator INFO: Inference done 3782/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:05:39
[09/22 14:51:08] d2.evaluation.evaluator INFO: Inference done 3800/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:05:34
[09/22 14:51:13] d2.evaluation.evaluator INFO: Inference done 3819/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:05:29
[09/22 14:51:18] d2.evaluation.evaluator INFO: Inference done 3837/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:05:24
[09/22 14:51:24] d2.evaluation.evaluator INFO: Inference done 3855/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2791 s/iter. ETA=0:05:19
[09/22 14:51:29] d2.evaluation.evaluator INFO: Inference done 3873/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2791 s/iter. ETA=0:05:14
[09/22 14:51:34] d2.evaluation.evaluator INFO: Inference done 3891/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2791 s/iter. ETA=0:05:09
[09/22 14:51:39] d2.evaluation.evaluator INFO: Inference done 3910/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:05:04
[09/22 14:51:44] d2.evaluation.evaluator INFO: Inference done 3929/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:04:58
[09/22 14:51:49] d2.evaluation.evaluator INFO: Inference done 3948/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:04:53
[09/22 14:51:54] d2.evaluation.evaluator INFO: Inference done 3966/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:04:48
[09/22 14:51:59] d2.evaluation.evaluator INFO: Inference done 3985/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:04:43
[09/22 14:52:04] d2.evaluation.evaluator INFO: Inference done 4003/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:04:38
[09/22 14:52:09] d2.evaluation.evaluator INFO: Inference done 4021/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:04:33
[09/22 14:52:14] d2.evaluation.evaluator INFO: Inference done 4039/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:04:28
[09/22 14:52:20] d2.evaluation.evaluator INFO: Inference done 4057/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:04:23
[09/22 14:52:25] d2.evaluation.evaluator INFO: Inference done 4075/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2790 s/iter. ETA=0:04:18
[09/22 14:52:30] d2.evaluation.evaluator INFO: Inference done 4093/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:04:13
[09/22 14:52:35] d2.evaluation.evaluator INFO: Inference done 4112/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:04:07
[09/22 14:52:40] d2.evaluation.evaluator INFO: Inference done 4130/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:04:02
[09/22 14:52:45] d2.evaluation.evaluator INFO: Inference done 4149/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:03:57
[09/22 14:52:51] d2.evaluation.evaluator INFO: Inference done 4167/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:03:52
[09/22 14:52:56] d2.evaluation.evaluator INFO: Inference done 4185/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:03:47
[09/22 14:53:01] d2.evaluation.evaluator INFO: Inference done 4203/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:03:42
[09/22 14:53:06] d2.evaluation.evaluator INFO: Inference done 4222/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2790 s/iter. ETA=0:03:37
[09/22 14:53:11] d2.evaluation.evaluator INFO: Inference done 4242/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:03:31
[09/22 14:53:16] d2.evaluation.evaluator INFO: Inference done 4260/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:03:26
[09/22 14:53:21] d2.evaluation.evaluator INFO: Inference done 4279/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:03:21
[09/22 14:53:26] d2.evaluation.evaluator INFO: Inference done 4297/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0145 s/iter. Total: 0.2789 s/iter. ETA=0:03:16
[09/22 14:53:31] d2.evaluation.evaluator INFO: Inference done 4315/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:03:11
[09/22 14:53:37] d2.evaluation.evaluator INFO: Inference done 4334/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:03:05
[09/22 14:53:42] d2.evaluation.evaluator INFO: Inference done 4353/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:03:00
[09/22 14:53:47] d2.evaluation.evaluator INFO: Inference done 4372/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:55
[09/22 14:53:52] d2.evaluation.evaluator INFO: Inference done 4391/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:49
[09/22 14:53:57] d2.evaluation.evaluator INFO: Inference done 4409/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:44
[09/22 14:54:02] d2.evaluation.evaluator INFO: Inference done 4428/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:39
[09/22 14:54:07] d2.evaluation.evaluator INFO: Inference done 4446/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:34
[09/22 14:54:13] d2.evaluation.evaluator INFO: Inference done 4464/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:29
[09/22 14:54:18] d2.evaluation.evaluator INFO: Inference done 4484/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:23
[09/22 14:54:23] d2.evaluation.evaluator INFO: Inference done 4502/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:18
[09/22 14:54:28] d2.evaluation.evaluator INFO: Inference done 4521/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:13
[09/22 14:54:33] d2.evaluation.evaluator INFO: Inference done 4540/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:08
[09/22 14:54:38] d2.evaluation.evaluator INFO: Inference done 4558/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:02:03
[09/22 14:54:44] d2.evaluation.evaluator INFO: Inference done 4576/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:58
[09/22 14:54:49] d2.evaluation.evaluator INFO: Inference done 4594/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:53
[09/22 14:54:54] d2.evaluation.evaluator INFO: Inference done 4612/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:48
[09/22 14:54:59] d2.evaluation.evaluator INFO: Inference done 4631/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:42
[09/22 14:55:04] d2.evaluation.evaluator INFO: Inference done 4649/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:37
[09/22 14:55:09] d2.evaluation.evaluator INFO: Inference done 4667/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:32
[09/22 14:55:14] d2.evaluation.evaluator INFO: Inference done 4686/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:27
[09/22 14:55:19] d2.evaluation.evaluator INFO: Inference done 4704/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:22
[09/22 14:55:24] d2.evaluation.evaluator INFO: Inference done 4722/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:17
[09/22 14:55:30] d2.evaluation.evaluator INFO: Inference done 4741/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:12
[09/22 14:55:35] d2.evaluation.evaluator INFO: Inference done 4759/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:07
[09/22 14:55:40] d2.evaluation.evaluator INFO: Inference done 4778/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:01:01
[09/22 14:55:45] d2.evaluation.evaluator INFO: Inference done 4796/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:00:56
[09/22 14:55:50] d2.evaluation.evaluator INFO: Inference done 4814/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:00:51
[09/22 14:55:55] d2.evaluation.evaluator INFO: Inference done 4834/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2787 s/iter. ETA=0:00:46
[09/22 14:56:00] d2.evaluation.evaluator INFO: Inference done 4852/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:00:41
[09/22 14:56:05] d2.evaluation.evaluator INFO: Inference done 4870/5000. Dataloading: 0.0012 s/iter. Inference: 0.2631 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:00:36
[09/22 14:56:11] d2.evaluation.evaluator INFO: Inference done 4888/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:00:31
[09/22 14:56:16] d2.evaluation.evaluator INFO: Inference done 4907/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2788 s/iter. ETA=0:00:25
[09/22 14:56:21] d2.evaluation.evaluator INFO: Inference done 4925/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:00:20
[09/22 14:56:26] d2.evaluation.evaluator INFO: Inference done 4943/5000. Dataloading: 0.0012 s/iter. Inference: 0.2632 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:00:15
[09/22 14:56:31] d2.evaluation.evaluator INFO: Inference done 4961/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0143 s/iter. Total: 0.2789 s/iter. ETA=0:00:10
[09/22 14:56:36] d2.evaluation.evaluator INFO: Inference done 4979/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0144 s/iter. Total: 0.2789 s/iter. ETA=0:00:05
[09/22 14:56:41] d2.evaluation.evaluator INFO: Inference done 4997/5000. Dataloading: 0.0012 s/iter. Inference: 0.2633 s/iter. Eval: 0.0143 s/iter. Total: 0.2789 s/iter. ETA=0:00:00
[09/22 14:56:42] d2.evaluation.evaluator INFO: Total inference time: 0:23:13.091592 (0.278897 s / iter per device, on 1 devices)
[09/22 14:56:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:21:54 (0.263252 s / iter per device, on 1 devices)
[09/22 14:56:42] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[09/22 14:56:42] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[09/22 14:57:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.424 | 48.327 | 30.054 | 15.481 | 29.402 | 40.779 |
[09/22 14:57:04] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 42.560 | bicycle      | 18.783 | car            | 32.133 |
| motorcycle    | 29.166 | airplane     | 49.442 | bus            | 49.033 |
| train         | 51.177 | truck        | 22.423 | boat           | 14.938 |
| traffic light | 20.556 | fire hydrant | 51.656 | stop sign      | 55.655 |
| parking meter | 33.138 | bench        | 15.120 | bird           | 24.864 |
| cat           | 48.723 | dog          | 44.963 | horse          | 38.864 |
| sheep         | 36.704 | cow          | 35.771 | elephant       | 45.057 |
| bear          | 55.637 | zebra        | 54.610 | giraffe        | 50.908 |
| backpack      | 8.787  | umbrella     | 25.535 | handbag        | 6.534  |
| tie           | 21.714 | suitcase     | 23.965 | frisbee        | 55.225 |
| skis          | 15.515 | snowboard    | 22.329 | sports ball    | 39.909 |
| kite          | 31.156 | baseball bat | 13.411 | baseball glove | 28.518 |
| skateboard    | 33.830 | surfboard    | 25.784 | tennis racket  | 30.923 |
| bottle        | 23.761 | wine glass   | 19.414 | cup            | 25.892 |
| fork          | 15.626 | knife        | 9.117  | spoon          | 5.167  |
| bowl          | 23.803 | banana       | 16.182 | apple          | 9.448  |
| sandwich      | 20.037 | orange       | 22.625 | broccoli       | 14.258 |
| carrot        | 13.151 | hot dog      | 20.418 | pizza          | 41.360 |
| donut         | 31.391 | cake         | 20.493 | chair          | 14.449 |
| couch         | 24.622 | potted plant | 15.056 | bed            | 30.804 |
| dining table  | 20.583 | toilet       | 50.170 | tv             | 39.660 |
| laptop        | 41.957 | mouse        | 47.095 | remote         | 16.484 |
| keyboard      | 36.674 | cell phone   | 23.768 | microwave      | 36.892 |
| oven          | 20.787 | toaster      | 19.386 | sink           | 25.811 |
| refrigerator  | 34.999 | book         | 9.160  | clock          | 37.566 |
| vase          | 23.004 | scissors     | 17.976 | teddy bear     | 30.640 |
| hair drier    | 4.653  | toothbrush   | 14.532 |                |        |
[09/22 14:57:33] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.015 | 46.054 | 29.648 | 12.685 | 28.160 | 44.050 |
[09/22 14:57:33] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 39.985 | bicycle      | 10.946 | car            | 31.935 |
| motorcycle    | 24.033 | airplane     | 44.151 | bus            | 51.235 |
| train         | 52.309 | truck        | 23.613 | boat           | 13.101 |
| traffic light | 21.056 | fire hydrant | 52.640 | stop sign      | 60.140 |
| parking meter | 33.664 | bench        | 11.811 | bird           | 22.940 |
| cat           | 57.010 | dog          | 47.772 | horse          | 30.969 |
| sheep         | 33.356 | cow          | 34.981 | elephant       | 43.505 |
| bear          | 59.886 | zebra        | 49.248 | giraffe        | 42.818 |
| backpack      | 8.878  | umbrella     | 35.329 | handbag        | 8.417  |
| tie           | 22.929 | suitcase     | 25.041 | frisbee        | 58.582 |
| skis          | 2.584  | snowboard    | 15.452 | sports ball    | 41.067 |
| kite          | 27.374 | baseball bat | 16.609 | baseball glove | 33.077 |
| skateboard    | 19.719 | surfboard    | 24.154 | tennis racket  | 44.068 |
| bottle        | 25.015 | wine glass   | 18.182 | cup            | 27.963 |
| fork          | 7.438  | knife        | 6.662  | spoon          | 4.817  |
| bowl          | 23.494 | banana       | 13.869 | apple          | 9.662  |
| sandwich      | 23.027 | orange       | 23.552 | broccoli       | 13.968 |
| carrot        | 12.299 | hot dog      | 18.299 | pizza          | 42.591 |
| donut         | 34.491 | cake         | 22.428 | chair          | 9.373  |
| couch         | 23.752 | potted plant | 13.968 | bed            | 23.675 |
| dining table  | 11.313 | toilet       | 53.007 | tv             | 43.568 |
| laptop        | 47.581 | mouse        | 52.795 | remote         | 19.151 |
| keyboard      | 40.507 | cell phone   | 25.431 | microwave      | 39.848 |
| oven          | 20.406 | toaster      | 23.761 | sink           | 27.992 |
| refrigerator  | 37.010 | book         | 5.895  | clock          | 39.588 |
| vase          | 24.208 | scissors     | 11.407 | teddy bear     | 32.196 |
| hair drier    | 0.557  | toothbrush   | 10.032 |                |        |
[09/22 14:57:34] d2.evaluation.testing INFO: copypaste: Task: bbox
[09/22 14:57:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 14:57:34] d2.evaluation.testing INFO: copypaste: 28.4236,48.3268,30.0537,15.4808,29.4019,40.7787
[09/22 14:57:34] d2.evaluation.testing INFO: copypaste: Task: segm
[09/22 14:57:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 14:57:34] d2.evaluation.testing INFO: copypaste: 28.0146,46.0536,29.6480,12.6848,28.1597,44.0502
[09/22 15:22:25] detectron2 INFO: Rank of current process: 0. World size: 1
[09/22 15:22:25] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/22 15:22:25] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/22 15:22:25] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/22 15:22:25] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/22 15:22:25] d2.utils.env INFO: Using a generated random seed 27387457
[09/22 15:22:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 15:22:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/22 15:22:27] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/22 15:22:27] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/22 15:22:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/22 15:22:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/22 15:22:27] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/22 15:22:27] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/22 15:22:27] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/22 15:22:28] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/22 15:22:31] d2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0009 s/iter. Inference: 0.2095 s/iter. Eval: 0.0181 s/iter. Total: 0.2285 s/iter. ETA=0:19:00
[09/22 15:22:36] d2.evaluation.evaluator INFO: Inference done 33/5000. Dataloading: 0.0011 s/iter. Inference: 0.2149 s/iter. Eval: 0.0134 s/iter. Total: 0.2294 s/iter. ETA=0:18:59
[09/22 15:22:41] d2.evaluation.evaluator INFO: Inference done 56/5000. Dataloading: 0.0011 s/iter. Inference: 0.2125 s/iter. Eval: 0.0152 s/iter. Total: 0.2289 s/iter. ETA=0:18:51
[09/22 15:22:46] d2.evaluation.evaluator INFO: Inference done 79/5000. Dataloading: 0.0012 s/iter. Inference: 0.2122 s/iter. Eval: 0.0145 s/iter. Total: 0.2279 s/iter. ETA=0:18:41
[09/22 15:22:51] d2.evaluation.evaluator INFO: Inference done 102/5000. Dataloading: 0.0012 s/iter. Inference: 0.2097 s/iter. Eval: 0.0161 s/iter. Total: 0.2270 s/iter. ETA=0:18:32
[09/22 15:22:56] d2.evaluation.evaluator INFO: Inference done 125/5000. Dataloading: 0.0012 s/iter. Inference: 0.2085 s/iter. Eval: 0.0161 s/iter. Total: 0.2259 s/iter. ETA=0:18:21
[09/22 15:23:02] d2.evaluation.evaluator INFO: Inference done 147/5000. Dataloading: 0.0012 s/iter. Inference: 0.2100 s/iter. Eval: 0.0164 s/iter. Total: 0.2276 s/iter. ETA=0:18:24
[09/22 15:23:07] d2.evaluation.evaluator INFO: Inference done 170/5000. Dataloading: 0.0012 s/iter. Inference: 0.2095 s/iter. Eval: 0.0164 s/iter. Total: 0.2272 s/iter. ETA=0:18:17
[09/22 15:23:12] d2.evaluation.evaluator INFO: Inference done 192/5000. Dataloading: 0.0012 s/iter. Inference: 0.2098 s/iter. Eval: 0.0167 s/iter. Total: 0.2277 s/iter. ETA=0:18:14
[09/22 15:23:17] d2.evaluation.evaluator INFO: Inference done 216/5000. Dataloading: 0.0012 s/iter. Inference: 0.2087 s/iter. Eval: 0.0162 s/iter. Total: 0.2261 s/iter. ETA=0:18:01
[09/22 15:23:22] d2.evaluation.evaluator INFO: Inference done 239/5000. Dataloading: 0.0012 s/iter. Inference: 0.2086 s/iter. Eval: 0.0161 s/iter. Total: 0.2259 s/iter. ETA=0:17:55
[09/22 15:23:27] d2.evaluation.evaluator INFO: Inference done 261/5000. Dataloading: 0.0012 s/iter. Inference: 0.2094 s/iter. Eval: 0.0162 s/iter. Total: 0.2268 s/iter. ETA=0:17:55
[09/22 15:23:32] d2.evaluation.evaluator INFO: Inference done 285/5000. Dataloading: 0.0012 s/iter. Inference: 0.2086 s/iter. Eval: 0.0160 s/iter. Total: 0.2258 s/iter. ETA=0:17:44
[09/22 15:23:38] d2.evaluation.evaluator INFO: Inference done 307/5000. Dataloading: 0.0012 s/iter. Inference: 0.2089 s/iter. Eval: 0.0160 s/iter. Total: 0.2262 s/iter. ETA=0:17:41
[09/22 15:23:43] d2.evaluation.evaluator INFO: Inference done 329/5000. Dataloading: 0.0012 s/iter. Inference: 0.2091 s/iter. Eval: 0.0161 s/iter. Total: 0.2264 s/iter. ETA=0:17:37
[09/22 15:23:48] d2.evaluation.evaluator INFO: Inference done 351/5000. Dataloading: 0.0012 s/iter. Inference: 0.2095 s/iter. Eval: 0.0162 s/iter. Total: 0.2269 s/iter. ETA=0:17:35
[09/22 15:23:53] d2.evaluation.evaluator INFO: Inference done 373/5000. Dataloading: 0.0012 s/iter. Inference: 0.2099 s/iter. Eval: 0.0163 s/iter. Total: 0.2275 s/iter. ETA=0:17:32
[09/22 15:23:58] d2.evaluation.evaluator INFO: Inference done 397/5000. Dataloading: 0.0012 s/iter. Inference: 0.2092 s/iter. Eval: 0.0160 s/iter. Total: 0.2265 s/iter. ETA=0:17:22
[09/22 15:24:03] d2.evaluation.evaluator INFO: Inference done 420/5000. Dataloading: 0.0012 s/iter. Inference: 0.2090 s/iter. Eval: 0.0159 s/iter. Total: 0.2261 s/iter. ETA=0:17:15
[09/22 15:24:08] d2.evaluation.evaluator INFO: Inference done 443/5000. Dataloading: 0.0012 s/iter. Inference: 0.2090 s/iter. Eval: 0.0157 s/iter. Total: 0.2260 s/iter. ETA=0:17:09
[09/22 15:24:13] d2.evaluation.evaluator INFO: Inference done 466/5000. Dataloading: 0.0012 s/iter. Inference: 0.2090 s/iter. Eval: 0.0155 s/iter. Total: 0.2257 s/iter. ETA=0:17:03
[09/22 15:24:18] d2.evaluation.evaluator INFO: Inference done 488/5000. Dataloading: 0.0012 s/iter. Inference: 0.2094 s/iter. Eval: 0.0155 s/iter. Total: 0.2262 s/iter. ETA=0:17:00
[09/22 15:24:24] d2.evaluation.evaluator INFO: Inference done 510/5000. Dataloading: 0.0012 s/iter. Inference: 0.2093 s/iter. Eval: 0.0157 s/iter. Total: 0.2263 s/iter. ETA=0:16:56
[09/22 15:24:29] d2.evaluation.evaluator INFO: Inference done 533/5000. Dataloading: 0.0012 s/iter. Inference: 0.2092 s/iter. Eval: 0.0158 s/iter. Total: 0.2262 s/iter. ETA=0:16:50
[09/22 15:24:34] d2.evaluation.evaluator INFO: Inference done 555/5000. Dataloading: 0.0012 s/iter. Inference: 0.2093 s/iter. Eval: 0.0159 s/iter. Total: 0.2264 s/iter. ETA=0:16:46
[09/22 15:24:39] d2.evaluation.evaluator INFO: Inference done 577/5000. Dataloading: 0.0012 s/iter. Inference: 0.2096 s/iter. Eval: 0.0159 s/iter. Total: 0.2268 s/iter. ETA=0:16:43
[09/22 15:24:44] d2.evaluation.evaluator INFO: Inference done 600/5000. Dataloading: 0.0012 s/iter. Inference: 0.2094 s/iter. Eval: 0.0159 s/iter. Total: 0.2266 s/iter. ETA=0:16:37
[09/22 15:24:49] d2.evaluation.evaluator INFO: Inference done 622/5000. Dataloading: 0.0012 s/iter. Inference: 0.2097 s/iter. Eval: 0.0159 s/iter. Total: 0.2269 s/iter. ETA=0:16:33
[09/22 15:24:54] d2.evaluation.evaluator INFO: Inference done 644/5000. Dataloading: 0.0012 s/iter. Inference: 0.2098 s/iter. Eval: 0.0160 s/iter. Total: 0.2271 s/iter. ETA=0:16:29
[09/22 15:25:00] d2.evaluation.evaluator INFO: Inference done 666/5000. Dataloading: 0.0012 s/iter. Inference: 0.2100 s/iter. Eval: 0.0162 s/iter. Total: 0.2274 s/iter. ETA=0:16:25
[09/22 15:25:05] d2.evaluation.evaluator INFO: Inference done 689/5000. Dataloading: 0.0012 s/iter. Inference: 0.2101 s/iter. Eval: 0.0160 s/iter. Total: 0.2274 s/iter. ETA=0:16:20
[09/22 15:25:10] d2.evaluation.evaluator INFO: Inference done 711/5000. Dataloading: 0.0012 s/iter. Inference: 0.2102 s/iter. Eval: 0.0160 s/iter. Total: 0.2275 s/iter. ETA=0:16:15
[09/22 15:25:15] d2.evaluation.evaluator INFO: Inference done 732/5000. Dataloading: 0.0012 s/iter. Inference: 0.2105 s/iter. Eval: 0.0161 s/iter. Total: 0.2279 s/iter. ETA=0:16:12
[09/22 15:25:20] d2.evaluation.evaluator INFO: Inference done 754/5000. Dataloading: 0.0012 s/iter. Inference: 0.2107 s/iter. Eval: 0.0160 s/iter. Total: 0.2280 s/iter. ETA=0:16:07
[09/22 15:25:25] d2.evaluation.evaluator INFO: Inference done 776/5000. Dataloading: 0.0012 s/iter. Inference: 0.2108 s/iter. Eval: 0.0160 s/iter. Total: 0.2281 s/iter. ETA=0:16:03
[09/22 15:25:30] d2.evaluation.evaluator INFO: Inference done 798/5000. Dataloading: 0.0012 s/iter. Inference: 0.2110 s/iter. Eval: 0.0161 s/iter. Total: 0.2283 s/iter. ETA=0:15:59
[09/22 15:25:35] d2.evaluation.evaluator INFO: Inference done 818/5000. Dataloading: 0.0012 s/iter. Inference: 0.2117 s/iter. Eval: 0.0160 s/iter. Total: 0.2289 s/iter. ETA=0:15:57
[09/22 15:25:41] d2.evaluation.evaluator INFO: Inference done 840/5000. Dataloading: 0.0012 s/iter. Inference: 0.2119 s/iter. Eval: 0.0160 s/iter. Total: 0.2291 s/iter. ETA=0:15:53
[09/22 15:25:46] d2.evaluation.evaluator INFO: Inference done 861/5000. Dataloading: 0.0012 s/iter. Inference: 0.2123 s/iter. Eval: 0.0161 s/iter. Total: 0.2297 s/iter. ETA=0:15:50
[09/22 15:25:51] d2.evaluation.evaluator INFO: Inference done 883/5000. Dataloading: 0.0012 s/iter. Inference: 0.2125 s/iter. Eval: 0.0160 s/iter. Total: 0.2298 s/iter. ETA=0:15:46
[09/22 15:25:56] d2.evaluation.evaluator INFO: Inference done 902/5000. Dataloading: 0.0012 s/iter. Inference: 0.2129 s/iter. Eval: 0.0164 s/iter. Total: 0.2306 s/iter. ETA=0:15:44
[09/22 15:26:01] d2.evaluation.evaluator INFO: Inference done 924/5000. Dataloading: 0.0013 s/iter. Inference: 0.2130 s/iter. Eval: 0.0164 s/iter. Total: 0.2307 s/iter. ETA=0:15:40
[09/22 15:26:06] d2.evaluation.evaluator INFO: Inference done 945/5000. Dataloading: 0.0013 s/iter. Inference: 0.2133 s/iter. Eval: 0.0163 s/iter. Total: 0.2309 s/iter. ETA=0:15:36
[09/22 15:26:11] d2.evaluation.evaluator INFO: Inference done 966/5000. Dataloading: 0.0013 s/iter. Inference: 0.2136 s/iter. Eval: 0.0164 s/iter. Total: 0.2313 s/iter. ETA=0:15:33
[09/22 15:26:17] d2.evaluation.evaluator INFO: Inference done 986/5000. Dataloading: 0.0013 s/iter. Inference: 0.2138 s/iter. Eval: 0.0166 s/iter. Total: 0.2317 s/iter. ETA=0:15:29
[09/22 15:26:22] d2.evaluation.evaluator INFO: Inference done 1007/5000. Dataloading: 0.0013 s/iter. Inference: 0.2140 s/iter. Eval: 0.0165 s/iter. Total: 0.2318 s/iter. ETA=0:15:25
[09/22 15:26:27] d2.evaluation.evaluator INFO: Inference done 1027/5000. Dataloading: 0.0013 s/iter. Inference: 0.2141 s/iter. Eval: 0.0167 s/iter. Total: 0.2322 s/iter. ETA=0:15:22
[09/22 15:26:32] d2.evaluation.evaluator INFO: Inference done 1048/5000. Dataloading: 0.0013 s/iter. Inference: 0.2143 s/iter. Eval: 0.0168 s/iter. Total: 0.2325 s/iter. ETA=0:15:18
[09/22 15:26:37] d2.evaluation.evaluator INFO: Inference done 1068/5000. Dataloading: 0.0013 s/iter. Inference: 0.2146 s/iter. Eval: 0.0168 s/iter. Total: 0.2328 s/iter. ETA=0:15:15
[09/22 15:26:42] d2.evaluation.evaluator INFO: Inference done 1088/5000. Dataloading: 0.0013 s/iter. Inference: 0.2150 s/iter. Eval: 0.0168 s/iter. Total: 0.2332 s/iter. ETA=0:15:12
[09/22 15:26:47] d2.evaluation.evaluator INFO: Inference done 1109/5000. Dataloading: 0.0013 s/iter. Inference: 0.2152 s/iter. Eval: 0.0168 s/iter. Total: 0.2334 s/iter. ETA=0:15:08
[09/22 15:26:52] d2.evaluation.evaluator INFO: Inference done 1131/5000. Dataloading: 0.0013 s/iter. Inference: 0.2152 s/iter. Eval: 0.0168 s/iter. Total: 0.2334 s/iter. ETA=0:15:02
[09/22 15:26:57] d2.evaluation.evaluator INFO: Inference done 1153/5000. Dataloading: 0.0013 s/iter. Inference: 0.2152 s/iter. Eval: 0.0168 s/iter. Total: 0.2334 s/iter. ETA=0:14:57
[09/22 15:27:02] d2.evaluation.evaluator INFO: Inference done 1174/5000. Dataloading: 0.0013 s/iter. Inference: 0.2155 s/iter. Eval: 0.0168 s/iter. Total: 0.2336 s/iter. ETA=0:14:53
[09/22 15:27:07] d2.evaluation.evaluator INFO: Inference done 1194/5000. Dataloading: 0.0013 s/iter. Inference: 0.2158 s/iter. Eval: 0.0167 s/iter. Total: 0.2339 s/iter. ETA=0:14:50
[09/22 15:27:13] d2.evaluation.evaluator INFO: Inference done 1214/5000. Dataloading: 0.0013 s/iter. Inference: 0.2161 s/iter. Eval: 0.0169 s/iter. Total: 0.2343 s/iter. ETA=0:14:47
[09/22 15:27:18] d2.evaluation.evaluator INFO: Inference done 1234/5000. Dataloading: 0.0013 s/iter. Inference: 0.2163 s/iter. Eval: 0.0169 s/iter. Total: 0.2346 s/iter. ETA=0:14:43
[09/22 15:27:23] d2.evaluation.evaluator INFO: Inference done 1254/5000. Dataloading: 0.0014 s/iter. Inference: 0.2165 s/iter. Eval: 0.0171 s/iter. Total: 0.2350 s/iter. ETA=0:14:40
[09/22 15:27:28] d2.evaluation.evaluator INFO: Inference done 1276/5000. Dataloading: 0.0014 s/iter. Inference: 0.2165 s/iter. Eval: 0.0171 s/iter. Total: 0.2351 s/iter. ETA=0:14:35
[09/22 15:27:33] d2.evaluation.evaluator INFO: Inference done 1297/5000. Dataloading: 0.0014 s/iter. Inference: 0.2167 s/iter. Eval: 0.0171 s/iter. Total: 0.2352 s/iter. ETA=0:14:30
[09/22 15:27:38] d2.evaluation.evaluator INFO: Inference done 1318/5000. Dataloading: 0.0014 s/iter. Inference: 0.2168 s/iter. Eval: 0.0171 s/iter. Total: 0.2353 s/iter. ETA=0:14:26
[09/22 15:27:43] d2.evaluation.evaluator INFO: Inference done 1338/5000. Dataloading: 0.0014 s/iter. Inference: 0.2170 s/iter. Eval: 0.0172 s/iter. Total: 0.2356 s/iter. ETA=0:14:22
[09/22 15:27:48] d2.evaluation.evaluator INFO: Inference done 1359/5000. Dataloading: 0.0014 s/iter. Inference: 0.2171 s/iter. Eval: 0.0172 s/iter. Total: 0.2358 s/iter. ETA=0:14:18
[09/22 15:27:54] d2.evaluation.evaluator INFO: Inference done 1380/5000. Dataloading: 0.0014 s/iter. Inference: 0.2172 s/iter. Eval: 0.0172 s/iter. Total: 0.2359 s/iter. ETA=0:14:13
[09/22 15:27:59] d2.evaluation.evaluator INFO: Inference done 1401/5000. Dataloading: 0.0014 s/iter. Inference: 0.2173 s/iter. Eval: 0.0173 s/iter. Total: 0.2360 s/iter. ETA=0:14:09
[09/22 15:28:04] d2.evaluation.evaluator INFO: Inference done 1423/5000. Dataloading: 0.0014 s/iter. Inference: 0.2173 s/iter. Eval: 0.0173 s/iter. Total: 0.2360 s/iter. ETA=0:14:04
[09/22 15:28:09] d2.evaluation.evaluator INFO: Inference done 1444/5000. Dataloading: 0.0014 s/iter. Inference: 0.2174 s/iter. Eval: 0.0172 s/iter. Total: 0.2361 s/iter. ETA=0:13:59
[09/22 15:28:14] d2.evaluation.evaluator INFO: Inference done 1467/5000. Dataloading: 0.0014 s/iter. Inference: 0.2172 s/iter. Eval: 0.0172 s/iter. Total: 0.2358 s/iter. ETA=0:13:53
[09/22 15:28:19] d2.evaluation.evaluator INFO: Inference done 1489/5000. Dataloading: 0.0014 s/iter. Inference: 0.2172 s/iter. Eval: 0.0172 s/iter. Total: 0.2358 s/iter. ETA=0:13:47
[09/22 15:28:24] d2.evaluation.evaluator INFO: Inference done 1512/5000. Dataloading: 0.0014 s/iter. Inference: 0.2169 s/iter. Eval: 0.0172 s/iter. Total: 0.2355 s/iter. ETA=0:13:41
[09/22 15:28:29] d2.evaluation.evaluator INFO: Inference done 1533/5000. Dataloading: 0.0014 s/iter. Inference: 0.2171 s/iter. Eval: 0.0172 s/iter. Total: 0.2357 s/iter. ETA=0:13:37
[09/22 15:28:35] d2.evaluation.evaluator INFO: Inference done 1553/5000. Dataloading: 0.0014 s/iter. Inference: 0.2173 s/iter. Eval: 0.0173 s/iter. Total: 0.2360 s/iter. ETA=0:13:33
[09/22 15:28:40] d2.evaluation.evaluator INFO: Inference done 1574/5000. Dataloading: 0.0014 s/iter. Inference: 0.2174 s/iter. Eval: 0.0173 s/iter. Total: 0.2361 s/iter. ETA=0:13:28
[09/22 15:28:45] d2.evaluation.evaluator INFO: Inference done 1593/5000. Dataloading: 0.0014 s/iter. Inference: 0.2176 s/iter. Eval: 0.0174 s/iter. Total: 0.2365 s/iter. ETA=0:13:25
[09/22 15:28:50] d2.evaluation.evaluator INFO: Inference done 1614/5000. Dataloading: 0.0014 s/iter. Inference: 0.2177 s/iter. Eval: 0.0174 s/iter. Total: 0.2366 s/iter. ETA=0:13:21
[09/22 15:28:55] d2.evaluation.evaluator INFO: Inference done 1635/5000. Dataloading: 0.0014 s/iter. Inference: 0.2178 s/iter. Eval: 0.0175 s/iter. Total: 0.2367 s/iter. ETA=0:13:16
[09/22 15:29:00] d2.evaluation.evaluator INFO: Inference done 1657/5000. Dataloading: 0.0014 s/iter. Inference: 0.2179 s/iter. Eval: 0.0174 s/iter. Total: 0.2367 s/iter. ETA=0:13:11
[09/22 15:29:05] d2.evaluation.evaluator INFO: Inference done 1677/5000. Dataloading: 0.0014 s/iter. Inference: 0.2180 s/iter. Eval: 0.0175 s/iter. Total: 0.2369 s/iter. ETA=0:13:07
[09/22 15:29:10] d2.evaluation.evaluator INFO: Inference done 1698/5000. Dataloading: 0.0014 s/iter. Inference: 0.2181 s/iter. Eval: 0.0175 s/iter. Total: 0.2370 s/iter. ETA=0:13:02
[09/22 15:29:16] d2.evaluation.evaluator INFO: Inference done 1719/5000. Dataloading: 0.0014 s/iter. Inference: 0.2182 s/iter. Eval: 0.0175 s/iter. Total: 0.2372 s/iter. ETA=0:12:58
[09/22 15:29:21] d2.evaluation.evaluator INFO: Inference done 1740/5000. Dataloading: 0.0014 s/iter. Inference: 0.2183 s/iter. Eval: 0.0175 s/iter. Total: 0.2372 s/iter. ETA=0:12:53
[09/22 15:29:26] d2.evaluation.evaluator INFO: Inference done 1761/5000. Dataloading: 0.0014 s/iter. Inference: 0.2184 s/iter. Eval: 0.0175 s/iter. Total: 0.2373 s/iter. ETA=0:12:48
[09/22 15:29:31] d2.evaluation.evaluator INFO: Inference done 1783/5000. Dataloading: 0.0014 s/iter. Inference: 0.2183 s/iter. Eval: 0.0175 s/iter. Total: 0.2372 s/iter. ETA=0:12:43
[09/22 15:29:36] d2.evaluation.evaluator INFO: Inference done 1805/5000. Dataloading: 0.0014 s/iter. Inference: 0.2183 s/iter. Eval: 0.0174 s/iter. Total: 0.2371 s/iter. ETA=0:12:37
[09/22 15:29:41] d2.evaluation.evaluator INFO: Inference done 1826/5000. Dataloading: 0.0014 s/iter. Inference: 0.2183 s/iter. Eval: 0.0174 s/iter. Total: 0.2372 s/iter. ETA=0:12:32
[09/22 15:29:46] d2.evaluation.evaluator INFO: Inference done 1848/5000. Dataloading: 0.0014 s/iter. Inference: 0.2182 s/iter. Eval: 0.0174 s/iter. Total: 0.2371 s/iter. ETA=0:12:27
[09/22 15:29:51] d2.evaluation.evaluator INFO: Inference done 1869/5000. Dataloading: 0.0014 s/iter. Inference: 0.2183 s/iter. Eval: 0.0174 s/iter. Total: 0.2372 s/iter. ETA=0:12:22
[09/22 15:29:56] d2.evaluation.evaluator INFO: Inference done 1889/5000. Dataloading: 0.0014 s/iter. Inference: 0.2185 s/iter. Eval: 0.0174 s/iter. Total: 0.2374 s/iter. ETA=0:12:18
[09/22 15:30:02] d2.evaluation.evaluator INFO: Inference done 1910/5000. Dataloading: 0.0014 s/iter. Inference: 0.2185 s/iter. Eval: 0.0174 s/iter. Total: 0.2374 s/iter. ETA=0:12:13
[09/22 15:30:07] d2.evaluation.evaluator INFO: Inference done 1931/5000. Dataloading: 0.0014 s/iter. Inference: 0.2187 s/iter. Eval: 0.0174 s/iter. Total: 0.2376 s/iter. ETA=0:12:09
[09/22 15:30:12] d2.evaluation.evaluator INFO: Inference done 1953/5000. Dataloading: 0.0014 s/iter. Inference: 0.2187 s/iter. Eval: 0.0174 s/iter. Total: 0.2376 s/iter. ETA=0:12:03
[09/22 15:30:17] d2.evaluation.evaluator INFO: Inference done 1973/5000. Dataloading: 0.0014 s/iter. Inference: 0.2188 s/iter. Eval: 0.0175 s/iter. Total: 0.2377 s/iter. ETA=0:11:59
[09/22 15:30:22] d2.evaluation.evaluator INFO: Inference done 1993/5000. Dataloading: 0.0014 s/iter. Inference: 0.2189 s/iter. Eval: 0.0175 s/iter. Total: 0.2379 s/iter. ETA=0:11:55
[09/22 15:30:27] d2.evaluation.evaluator INFO: Inference done 2013/5000. Dataloading: 0.0014 s/iter. Inference: 0.2190 s/iter. Eval: 0.0175 s/iter. Total: 0.2380 s/iter. ETA=0:11:50
[09/22 15:30:32] d2.evaluation.evaluator INFO: Inference done 2033/5000. Dataloading: 0.0014 s/iter. Inference: 0.2191 s/iter. Eval: 0.0176 s/iter. Total: 0.2382 s/iter. ETA=0:11:46
[09/22 15:30:37] d2.evaluation.evaluator INFO: Inference done 2054/5000. Dataloading: 0.0014 s/iter. Inference: 0.2191 s/iter. Eval: 0.0176 s/iter. Total: 0.2382 s/iter. ETA=0:11:41
[09/22 15:30:42] d2.evaluation.evaluator INFO: Inference done 2075/5000. Dataloading: 0.0014 s/iter. Inference: 0.2192 s/iter. Eval: 0.0176 s/iter. Total: 0.2382 s/iter. ETA=0:11:36
[09/22 15:30:47] d2.evaluation.evaluator INFO: Inference done 2096/5000. Dataloading: 0.0014 s/iter. Inference: 0.2192 s/iter. Eval: 0.0176 s/iter. Total: 0.2383 s/iter. ETA=0:11:31
[09/22 15:30:53] d2.evaluation.evaluator INFO: Inference done 2117/5000. Dataloading: 0.0014 s/iter. Inference: 0.2193 s/iter. Eval: 0.0176 s/iter. Total: 0.2384 s/iter. ETA=0:11:27
[09/22 15:30:58] d2.evaluation.evaluator INFO: Inference done 2138/5000. Dataloading: 0.0015 s/iter. Inference: 0.2193 s/iter. Eval: 0.0176 s/iter. Total: 0.2384 s/iter. ETA=0:11:22
[09/22 15:31:03] d2.evaluation.evaluator INFO: Inference done 2159/5000. Dataloading: 0.0014 s/iter. Inference: 0.2193 s/iter. Eval: 0.0176 s/iter. Total: 0.2384 s/iter. ETA=0:11:17
[09/22 15:31:08] d2.evaluation.evaluator INFO: Inference done 2181/5000. Dataloading: 0.0014 s/iter. Inference: 0.2193 s/iter. Eval: 0.0176 s/iter. Total: 0.2384 s/iter. ETA=0:11:12
[09/22 15:31:13] d2.evaluation.evaluator INFO: Inference done 2201/5000. Dataloading: 0.0014 s/iter. Inference: 0.2195 s/iter. Eval: 0.0175 s/iter. Total: 0.2385 s/iter. ETA=0:11:07
[09/22 15:31:18] d2.evaluation.evaluator INFO: Inference done 2221/5000. Dataloading: 0.0014 s/iter. Inference: 0.2196 s/iter. Eval: 0.0176 s/iter. Total: 0.2387 s/iter. ETA=0:11:03
[09/22 15:31:23] d2.evaluation.evaluator INFO: Inference done 2241/5000. Dataloading: 0.0014 s/iter. Inference: 0.2197 s/iter. Eval: 0.0176 s/iter. Total: 0.2388 s/iter. ETA=0:10:58
[09/22 15:31:28] d2.evaluation.evaluator INFO: Inference done 2259/5000. Dataloading: 0.0015 s/iter. Inference: 0.2200 s/iter. Eval: 0.0176 s/iter. Total: 0.2391 s/iter. ETA=0:10:55
[09/22 15:31:33] d2.evaluation.evaluator INFO: Inference done 2280/5000. Dataloading: 0.0015 s/iter. Inference: 0.2201 s/iter. Eval: 0.0176 s/iter. Total: 0.2392 s/iter. ETA=0:10:50
[09/22 15:31:38] d2.evaluation.evaluator INFO: Inference done 2301/5000. Dataloading: 0.0015 s/iter. Inference: 0.2201 s/iter. Eval: 0.0176 s/iter. Total: 0.2392 s/iter. ETA=0:10:45
[09/22 15:31:44] d2.evaluation.evaluator INFO: Inference done 2320/5000. Dataloading: 0.0015 s/iter. Inference: 0.2203 s/iter. Eval: 0.0176 s/iter. Total: 0.2394 s/iter. ETA=0:10:41
[09/22 15:31:49] d2.evaluation.evaluator INFO: Inference done 2342/5000. Dataloading: 0.0015 s/iter. Inference: 0.2203 s/iter. Eval: 0.0175 s/iter. Total: 0.2394 s/iter. ETA=0:10:36
[09/22 15:31:54] d2.evaluation.evaluator INFO: Inference done 2363/5000. Dataloading: 0.0015 s/iter. Inference: 0.2204 s/iter. Eval: 0.0175 s/iter. Total: 0.2394 s/iter. ETA=0:10:31
[09/22 15:31:59] d2.evaluation.evaluator INFO: Inference done 2384/5000. Dataloading: 0.0015 s/iter. Inference: 0.2204 s/iter. Eval: 0.0175 s/iter. Total: 0.2395 s/iter. ETA=0:10:26
[09/22 15:32:04] d2.evaluation.evaluator INFO: Inference done 2405/5000. Dataloading: 0.0015 s/iter. Inference: 0.2205 s/iter. Eval: 0.0175 s/iter. Total: 0.2395 s/iter. ETA=0:10:21
[09/22 15:32:09] d2.evaluation.evaluator INFO: Inference done 2424/5000. Dataloading: 0.0015 s/iter. Inference: 0.2206 s/iter. Eval: 0.0176 s/iter. Total: 0.2397 s/iter. ETA=0:10:17
[09/22 15:32:14] d2.evaluation.evaluator INFO: Inference done 2444/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0176 s/iter. Total: 0.2398 s/iter. ETA=0:10:13
[09/22 15:32:19] d2.evaluation.evaluator INFO: Inference done 2464/5000. Dataloading: 0.0015 s/iter. Inference: 0.2208 s/iter. Eval: 0.0176 s/iter. Total: 0.2399 s/iter. ETA=0:10:08
[09/22 15:32:24] d2.evaluation.evaluator INFO: Inference done 2486/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0176 s/iter. Total: 0.2398 s/iter. ETA=0:10:02
[09/22 15:32:29] d2.evaluation.evaluator INFO: Inference done 2507/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0176 s/iter. Total: 0.2399 s/iter. ETA=0:09:58
[09/22 15:32:35] d2.evaluation.evaluator INFO: Inference done 2528/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0177 s/iter. Total: 0.2399 s/iter. ETA=0:09:53
[09/22 15:32:40] d2.evaluation.evaluator INFO: Inference done 2550/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0177 s/iter. Total: 0.2399 s/iter. ETA=0:09:47
[09/22 15:32:45] d2.evaluation.evaluator INFO: Inference done 2572/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0177 s/iter. Total: 0.2399 s/iter. ETA=0:09:42
[09/22 15:32:50] d2.evaluation.evaluator INFO: Inference done 2594/5000. Dataloading: 0.0015 s/iter. Inference: 0.2206 s/iter. Eval: 0.0177 s/iter. Total: 0.2398 s/iter. ETA=0:09:36
[09/22 15:32:55] d2.evaluation.evaluator INFO: Inference done 2614/5000. Dataloading: 0.0015 s/iter. Inference: 0.2207 s/iter. Eval: 0.0177 s/iter. Total: 0.2399 s/iter. ETA=0:09:32
[09/22 15:33:00] d2.evaluation.evaluator INFO: Inference done 2634/5000. Dataloading: 0.0015 s/iter. Inference: 0.2208 s/iter. Eval: 0.0178 s/iter. Total: 0.2401 s/iter. ETA=0:09:27
[09/22 15:33:06] d2.evaluation.evaluator INFO: Inference done 2655/5000. Dataloading: 0.0015 s/iter. Inference: 0.2208 s/iter. Eval: 0.0178 s/iter. Total: 0.2401 s/iter. ETA=0:09:23
[09/22 15:33:11] d2.evaluation.evaluator INFO: Inference done 2676/5000. Dataloading: 0.0015 s/iter. Inference: 0.2209 s/iter. Eval: 0.0177 s/iter. Total: 0.2401 s/iter. ETA=0:09:18
[09/22 15:33:16] d2.evaluation.evaluator INFO: Inference done 2697/5000. Dataloading: 0.0015 s/iter. Inference: 0.2209 s/iter. Eval: 0.0177 s/iter. Total: 0.2402 s/iter. ETA=0:09:13
[09/22 15:33:21] d2.evaluation.evaluator INFO: Inference done 2719/5000. Dataloading: 0.0015 s/iter. Inference: 0.2209 s/iter. Eval: 0.0177 s/iter. Total: 0.2401 s/iter. ETA=0:09:07
[09/22 15:33:26] d2.evaluation.evaluator INFO: Inference done 2740/5000. Dataloading: 0.0015 s/iter. Inference: 0.2209 s/iter. Eval: 0.0177 s/iter. Total: 0.2402 s/iter. ETA=0:09:02
[09/22 15:33:31] d2.evaluation.evaluator INFO: Inference done 2761/5000. Dataloading: 0.0015 s/iter. Inference: 0.2209 s/iter. Eval: 0.0177 s/iter. Total: 0.2402 s/iter. ETA=0:08:57
[09/22 15:33:36] d2.evaluation.evaluator INFO: Inference done 2782/5000. Dataloading: 0.0015 s/iter. Inference: 0.2210 s/iter. Eval: 0.0177 s/iter. Total: 0.2402 s/iter. ETA=0:08:52
[09/22 15:33:42] d2.evaluation.evaluator INFO: Inference done 2803/5000. Dataloading: 0.0015 s/iter. Inference: 0.2210 s/iter. Eval: 0.0178 s/iter. Total: 0.2403 s/iter. ETA=0:08:47
[09/22 15:33:47] d2.evaluation.evaluator INFO: Inference done 2824/5000. Dataloading: 0.0015 s/iter. Inference: 0.2210 s/iter. Eval: 0.0178 s/iter. Total: 0.2403 s/iter. ETA=0:08:42
[09/22 15:33:52] d2.evaluation.evaluator INFO: Inference done 2844/5000. Dataloading: 0.0015 s/iter. Inference: 0.2211 s/iter. Eval: 0.0178 s/iter. Total: 0.2404 s/iter. ETA=0:08:38
[09/22 15:33:57] d2.evaluation.evaluator INFO: Inference done 2866/5000. Dataloading: 0.0015 s/iter. Inference: 0.2210 s/iter. Eval: 0.0178 s/iter. Total: 0.2403 s/iter. ETA=0:08:32
[09/22 15:34:02] d2.evaluation.evaluator INFO: Inference done 2886/5000. Dataloading: 0.0015 s/iter. Inference: 0.2211 s/iter. Eval: 0.0178 s/iter. Total: 0.2405 s/iter. ETA=0:08:28
[09/22 15:34:07] d2.evaluation.evaluator INFO: Inference done 2907/5000. Dataloading: 0.0015 s/iter. Inference: 0.2212 s/iter. Eval: 0.0178 s/iter. Total: 0.2405 s/iter. ETA=0:08:23
[09/22 15:34:12] d2.evaluation.evaluator INFO: Inference done 2928/5000. Dataloading: 0.0015 s/iter. Inference: 0.2212 s/iter. Eval: 0.0178 s/iter. Total: 0.2405 s/iter. ETA=0:08:18
[09/22 15:34:18] d2.evaluation.evaluator INFO: Inference done 2950/5000. Dataloading: 0.0015 s/iter. Inference: 0.2211 s/iter. Eval: 0.0178 s/iter. Total: 0.2405 s/iter. ETA=0:08:13
[09/22 15:34:23] d2.evaluation.evaluator INFO: Inference done 2973/5000. Dataloading: 0.0015 s/iter. Inference: 0.2211 s/iter. Eval: 0.0178 s/iter. Total: 0.2404 s/iter. ETA=0:08:07
[09/22 15:34:28] d2.evaluation.evaluator INFO: Inference done 2995/5000. Dataloading: 0.0015 s/iter. Inference: 0.2211 s/iter. Eval: 0.0178 s/iter. Total: 0.2404 s/iter. ETA=0:08:01
[09/22 15:34:33] d2.evaluation.evaluator INFO: Inference done 3016/5000. Dataloading: 0.0015 s/iter. Inference: 0.2211 s/iter. Eval: 0.0177 s/iter. Total: 0.2404 s/iter. ETA=0:07:56
[09/22 15:34:38] d2.evaluation.evaluator INFO: Inference done 3036/5000. Dataloading: 0.0015 s/iter. Inference: 0.2213 s/iter. Eval: 0.0177 s/iter. Total: 0.2406 s/iter. ETA=0:07:52
[09/22 15:34:43] d2.evaluation.evaluator INFO: Inference done 3056/5000. Dataloading: 0.0015 s/iter. Inference: 0.2214 s/iter. Eval: 0.0177 s/iter. Total: 0.2407 s/iter. ETA=0:07:47
[09/22 15:34:49] d2.evaluation.evaluator INFO: Inference done 3076/5000. Dataloading: 0.0015 s/iter. Inference: 0.2215 s/iter. Eval: 0.0177 s/iter. Total: 0.2407 s/iter. ETA=0:07:43
[09/22 15:34:54] d2.evaluation.evaluator INFO: Inference done 3096/5000. Dataloading: 0.0015 s/iter. Inference: 0.2216 s/iter. Eval: 0.0177 s/iter. Total: 0.2408 s/iter. ETA=0:07:38
[09/22 15:34:59] d2.evaluation.evaluator INFO: Inference done 3117/5000. Dataloading: 0.0015 s/iter. Inference: 0.2216 s/iter. Eval: 0.0177 s/iter. Total: 0.2409 s/iter. ETA=0:07:33
[09/22 15:35:04] d2.evaluation.evaluator INFO: Inference done 3136/5000. Dataloading: 0.0015 s/iter. Inference: 0.2218 s/iter. Eval: 0.0177 s/iter. Total: 0.2410 s/iter. ETA=0:07:29
[09/22 15:35:09] d2.evaluation.evaluator INFO: Inference done 3156/5000. Dataloading: 0.0015 s/iter. Inference: 0.2218 s/iter. Eval: 0.0177 s/iter. Total: 0.2411 s/iter. ETA=0:07:24
[09/22 15:35:14] d2.evaluation.evaluator INFO: Inference done 3177/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2411 s/iter. ETA=0:07:19
[09/22 15:35:19] d2.evaluation.evaluator INFO: Inference done 3197/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2412 s/iter. ETA=0:07:14
[09/22 15:35:24] d2.evaluation.evaluator INFO: Inference done 3217/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0178 s/iter. Total: 0.2413 s/iter. ETA=0:07:10
[09/22 15:35:29] d2.evaluation.evaluator INFO: Inference done 3238/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0178 s/iter. Total: 0.2413 s/iter. ETA=0:07:05
[09/22 15:35:35] d2.evaluation.evaluator INFO: Inference done 3259/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0178 s/iter. Total: 0.2414 s/iter. ETA=0:07:00
[09/22 15:35:40] d2.evaluation.evaluator INFO: Inference done 3279/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0178 s/iter. Total: 0.2414 s/iter. ETA=0:06:55
[09/22 15:35:45] d2.evaluation.evaluator INFO: Inference done 3299/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:50
[09/22 15:35:50] d2.evaluation.evaluator INFO: Inference done 3320/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:45
[09/22 15:35:55] d2.evaluation.evaluator INFO: Inference done 3342/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:40
[09/22 15:36:00] d2.evaluation.evaluator INFO: Inference done 3363/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:35
[09/22 15:36:05] d2.evaluation.evaluator INFO: Inference done 3385/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:29
[09/22 15:36:11] d2.evaluation.evaluator INFO: Inference done 3407/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0179 s/iter. Total: 0.2414 s/iter. ETA=0:06:24
[09/22 15:36:16] d2.evaluation.evaluator INFO: Inference done 3427/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:19
[09/22 15:36:21] d2.evaluation.evaluator INFO: Inference done 3447/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:06:15
[09/22 15:36:26] d2.evaluation.evaluator INFO: Inference done 3468/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:06:10
[09/22 15:36:31] d2.evaluation.evaluator INFO: Inference done 3490/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:06:04
[09/22 15:36:36] d2.evaluation.evaluator INFO: Inference done 3511/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:05:59
[09/22 15:36:41] d2.evaluation.evaluator INFO: Inference done 3533/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:05:54
[09/22 15:36:47] d2.evaluation.evaluator INFO: Inference done 3554/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:05:49
[09/22 15:36:52] d2.evaluation.evaluator INFO: Inference done 3575/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:05:44
[09/22 15:36:57] d2.evaluation.evaluator INFO: Inference done 3596/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:05:39
[09/22 15:37:02] d2.evaluation.evaluator INFO: Inference done 3617/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:05:34
[09/22 15:37:07] d2.evaluation.evaluator INFO: Inference done 3638/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:05:29
[09/22 15:37:12] d2.evaluation.evaluator INFO: Inference done 3659/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:05:24
[09/22 15:37:18] d2.evaluation.evaluator INFO: Inference done 3680/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:05:19
[09/22 15:37:23] d2.evaluation.evaluator INFO: Inference done 3701/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2418 s/iter. ETA=0:05:14
[09/22 15:37:28] d2.evaluation.evaluator INFO: Inference done 3723/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:05:08
[09/22 15:37:33] d2.evaluation.evaluator INFO: Inference done 3744/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2418 s/iter. ETA=0:05:03
[09/22 15:37:39] d2.evaluation.evaluator INFO: Inference done 3767/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:04:58
[09/22 15:37:44] d2.evaluation.evaluator INFO: Inference done 3788/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:04:52
[09/22 15:37:49] d2.evaluation.evaluator INFO: Inference done 3809/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:04:47
[09/22 15:37:54] d2.evaluation.evaluator INFO: Inference done 3830/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:42
[09/22 15:37:59] d2.evaluation.evaluator INFO: Inference done 3851/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:37
[09/22 15:38:04] d2.evaluation.evaluator INFO: Inference done 3871/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0178 s/iter. Total: 0.2418 s/iter. ETA=0:04:32
[09/22 15:38:09] d2.evaluation.evaluator INFO: Inference done 3893/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:27
[09/22 15:38:14] d2.evaluation.evaluator INFO: Inference done 3914/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:22
[09/22 15:38:19] d2.evaluation.evaluator INFO: Inference done 3935/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:17
[09/22 15:38:24] d2.evaluation.evaluator INFO: Inference done 3956/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0178 s/iter. Total: 0.2418 s/iter. ETA=0:04:12
[09/22 15:38:29] d2.evaluation.evaluator INFO: Inference done 3977/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:07
[09/22 15:38:35] d2.evaluation.evaluator INFO: Inference done 3999/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0178 s/iter. Total: 0.2417 s/iter. ETA=0:04:01
[09/22 15:38:40] d2.evaluation.evaluator INFO: Inference done 4019/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0178 s/iter. Total: 0.2418 s/iter. ETA=0:03:57
[09/22 15:38:45] d2.evaluation.evaluator INFO: Inference done 4039/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2418 s/iter. ETA=0:03:52
[09/22 15:38:50] d2.evaluation.evaluator INFO: Inference done 4060/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2419 s/iter. ETA=0:03:47
[09/22 15:38:55] d2.evaluation.evaluator INFO: Inference done 4081/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2419 s/iter. ETA=0:03:42
[09/22 15:39:00] d2.evaluation.evaluator INFO: Inference done 4101/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2419 s/iter. ETA=0:03:37
[09/22 15:39:05] d2.evaluation.evaluator INFO: Inference done 4122/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2419 s/iter. ETA=0:03:32
[09/22 15:39:10] d2.evaluation.evaluator INFO: Inference done 4143/5000. Dataloading: 0.0015 s/iter. Inference: 0.2225 s/iter. Eval: 0.0179 s/iter. Total: 0.2419 s/iter. ETA=0:03:27
[09/22 15:39:16] d2.evaluation.evaluator INFO: Inference done 4164/5000. Dataloading: 0.0015 s/iter. Inference: 0.2225 s/iter. Eval: 0.0179 s/iter. Total: 0.2420 s/iter. ETA=0:03:22
[09/22 15:39:21] d2.evaluation.evaluator INFO: Inference done 4186/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2419 s/iter. ETA=0:03:16
[09/22 15:39:26] d2.evaluation.evaluator INFO: Inference done 4208/5000. Dataloading: 0.0015 s/iter. Inference: 0.2224 s/iter. Eval: 0.0179 s/iter. Total: 0.2418 s/iter. ETA=0:03:11
[09/22 15:39:31] d2.evaluation.evaluator INFO: Inference done 4231/5000. Dataloading: 0.0015 s/iter. Inference: 0.2223 s/iter. Eval: 0.0179 s/iter. Total: 0.2418 s/iter. ETA=0:03:05
[09/22 15:39:36] d2.evaluation.evaluator INFO: Inference done 4254/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2417 s/iter. ETA=0:03:00
[09/22 15:39:41] d2.evaluation.evaluator INFO: Inference done 4276/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:02:54
[09/22 15:39:46] d2.evaluation.evaluator INFO: Inference done 4298/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0179 s/iter. Total: 0.2416 s/iter. ETA=0:02:49
[09/22 15:39:51] d2.evaluation.evaluator INFO: Inference done 4320/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0179 s/iter. Total: 0.2415 s/iter. ETA=0:02:44
[09/22 15:39:57] d2.evaluation.evaluator INFO: Inference done 4342/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:02:38
[09/22 15:40:02] d2.evaluation.evaluator INFO: Inference done 4364/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:02:33
[09/22 15:40:07] d2.evaluation.evaluator INFO: Inference done 4385/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:02:28
[09/22 15:40:12] d2.evaluation.evaluator INFO: Inference done 4406/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:02:23
[09/22 15:40:17] d2.evaluation.evaluator INFO: Inference done 4427/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:02:18
[09/22 15:40:22] d2.evaluation.evaluator INFO: Inference done 4447/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0178 s/iter. Total: 0.2416 s/iter. ETA=0:02:13
[09/22 15:40:27] d2.evaluation.evaluator INFO: Inference done 4467/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0178 s/iter. Total: 0.2416 s/iter. ETA=0:02:08
[09/22 15:40:32] d2.evaluation.evaluator INFO: Inference done 4489/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:02:03
[09/22 15:40:37] d2.evaluation.evaluator INFO: Inference done 4510/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0178 s/iter. Total: 0.2416 s/iter. ETA=0:01:58
[09/22 15:40:43] d2.evaluation.evaluator INFO: Inference done 4533/5000. Dataloading: 0.0015 s/iter. Inference: 0.2222 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:01:52
[09/22 15:40:48] d2.evaluation.evaluator INFO: Inference done 4554/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2415 s/iter. ETA=0:01:47
[09/22 15:40:53] d2.evaluation.evaluator INFO: Inference done 4575/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2414 s/iter. ETA=0:01:42
[09/22 15:40:58] d2.evaluation.evaluator INFO: Inference done 4597/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2414 s/iter. ETA=0:01:37
[09/22 15:41:03] d2.evaluation.evaluator INFO: Inference done 4619/5000. Dataloading: 0.0015 s/iter. Inference: 0.2221 s/iter. Eval: 0.0178 s/iter. Total: 0.2414 s/iter. ETA=0:01:31
[09/22 15:41:08] d2.evaluation.evaluator INFO: Inference done 4641/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0177 s/iter. Total: 0.2413 s/iter. ETA=0:01:26
[09/22 15:41:13] d2.evaluation.evaluator INFO: Inference done 4663/5000. Dataloading: 0.0015 s/iter. Inference: 0.2220 s/iter. Eval: 0.0177 s/iter. Total: 0.2413 s/iter. ETA=0:01:21
[09/22 15:41:18] d2.evaluation.evaluator INFO: Inference done 4685/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2412 s/iter. ETA=0:01:15
[09/22 15:41:23] d2.evaluation.evaluator INFO: Inference done 4707/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2412 s/iter. ETA=0:01:10
[09/22 15:41:28] d2.evaluation.evaluator INFO: Inference done 4728/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2412 s/iter. ETA=0:01:05
[09/22 15:41:34] d2.evaluation.evaluator INFO: Inference done 4751/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2411 s/iter. ETA=0:01:00
[09/22 15:41:39] d2.evaluation.evaluator INFO: Inference done 4773/5000. Dataloading: 0.0015 s/iter. Inference: 0.2219 s/iter. Eval: 0.0177 s/iter. Total: 0.2411 s/iter. ETA=0:00:54
[09/22 15:41:44] d2.evaluation.evaluator INFO: Inference done 4795/5000. Dataloading: 0.0015 s/iter. Inference: 0.2218 s/iter. Eval: 0.0177 s/iter. Total: 0.2411 s/iter. ETA=0:00:49
[09/22 15:41:49] d2.evaluation.evaluator INFO: Inference done 4817/5000. Dataloading: 0.0015 s/iter. Inference: 0.2218 s/iter. Eval: 0.0177 s/iter. Total: 0.2410 s/iter. ETA=0:00:44
[09/22 15:41:54] d2.evaluation.evaluator INFO: Inference done 4841/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2409 s/iter. ETA=0:00:38
[09/22 15:41:59] d2.evaluation.evaluator INFO: Inference done 4862/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2409 s/iter. ETA=0:00:33
[09/22 15:42:05] d2.evaluation.evaluator INFO: Inference done 4884/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2409 s/iter. ETA=0:00:27
[09/22 15:42:10] d2.evaluation.evaluator INFO: Inference done 4906/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2409 s/iter. ETA=0:00:22
[09/22 15:42:15] d2.evaluation.evaluator INFO: Inference done 4927/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2409 s/iter. ETA=0:00:17
[09/22 15:42:20] d2.evaluation.evaluator INFO: Inference done 4950/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2408 s/iter. ETA=0:00:12
[09/22 15:42:25] d2.evaluation.evaluator INFO: Inference done 4972/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2408 s/iter. ETA=0:00:06
[09/22 15:42:30] d2.evaluation.evaluator INFO: Inference done 4994/5000. Dataloading: 0.0015 s/iter. Inference: 0.2217 s/iter. Eval: 0.0176 s/iter. Total: 0.2408 s/iter. ETA=0:00:01
[09/22 15:42:32] d2.evaluation.evaluator INFO: Total inference time: 0:20:02.489923 (0.240739 s / iter per device, on 1 devices)
[09/22 15:42:32] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:18:27 (0.221633 s / iter per device, on 1 devices)
[09/22 15:42:32] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[09/22 15:42:32] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[09/22 15:42:54] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 35.450 | 56.689 | 38.368 | 20.757 | 37.962 | 48.074 |
[09/22 15:42:54] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 49.864 | bicycle      | 25.043 | car            | 37.223 |
| motorcycle    | 37.124 | airplane     | 61.119 | bus            | 58.081 |
| train         | 56.202 | truck        | 28.630 | boat           | 21.117 |
| traffic light | 24.347 | fire hydrant | 62.804 | stop sign      | 60.631 |
| parking meter | 38.694 | bench        | 19.632 | bird           | 29.671 |
| cat           | 58.210 | dog          | 56.809 | horse          | 51.071 |
| sheep         | 43.321 | cow          | 48.340 | elephant       | 55.116 |
| bear          | 62.820 | zebra        | 61.982 | giraffe        | 61.751 |
| backpack      | 13.003 | umbrella     | 32.293 | handbag        | 9.988  |
| tie           | 27.100 | suitcase     | 31.691 | frisbee        | 57.464 |
| skis          | 19.966 | snowboard    | 30.928 | sports ball    | 45.113 |
| kite          | 38.572 | baseball bat | 23.654 | baseball glove | 34.620 |
| skateboard    | 45.659 | surfboard    | 32.863 | tennis racket  | 39.270 |
| bottle        | 32.343 | wine glass   | 28.212 | cup            | 34.669 |
| fork          | 25.742 | knife        | 12.847 | spoon          | 7.798  |
| bowl          | 31.327 | banana       | 19.891 | apple          | 16.241 |
| sandwich      | 29.937 | orange       | 25.424 | broccoli       | 19.624 |
| carrot        | 16.328 | hot dog      | 28.338 | pizza          | 48.660 |
| donut         | 42.331 | cake         | 33.368 | chair          | 22.942 |
| couch         | 34.281 | potted plant | 22.759 | bed            | 39.416 |
| dining table  | 22.310 | toilet       | 55.919 | tv             | 49.567 |
| laptop        | 53.684 | mouse        | 51.846 | remote         | 25.083 |
| keyboard      | 41.933 | cell phone   | 28.162 | microwave      | 49.947 |
| oven          | 26.933 | toaster      | 20.217 | sink           | 30.175 |
| refrigerator  | 46.403 | book         | 10.407 | clock          | 41.935 |
| vase          | 32.623 | scissors     | 22.660 | teddy bear     | 42.901 |
| hair drier    | 0.601  | toothbrush   | 18.430 |                |        |
[09/22 15:43:25] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 33.710 | 54.236 | 36.171 | 16.547 | 35.172 | 50.534 |
[09/22 15:43:25] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 44.886 | bicycle      | 14.302 | car            | 35.851 |
| motorcycle    | 29.779 | airplane     | 49.861 | bus            | 58.589 |
| train         | 57.499 | truck        | 28.496 | boat           | 17.880 |
| traffic light | 24.549 | fire hydrant | 59.780 | stop sign      | 63.054 |
| parking meter | 40.362 | bench        | 14.464 | bird           | 26.580 |
| cat           | 63.392 | dog          | 57.043 | horse          | 38.085 |
| sheep         | 39.655 | cow          | 42.979 | elephant       | 52.548 |
| bear          | 62.056 | zebra        | 54.282 | giraffe        | 49.924 |
| backpack      | 12.583 | umbrella     | 40.825 | handbag        | 11.220 |
| tie           | 27.034 | suitcase     | 33.383 | frisbee        | 60.673 |
| skis          | 3.598  | snowboard    | 23.365 | sports ball    | 46.240 |
| kite          | 29.289 | baseball bat | 22.388 | baseball glove | 38.500 |
| skateboard    | 25.824 | surfboard    | 29.822 | tennis racket  | 50.933 |
| bottle        | 32.615 | wine glass   | 26.565 | cup            | 36.468 |
| fork          | 11.461 | knife        | 10.012 | spoon          | 7.358  |
| bowl          | 30.283 | banana       | 17.657 | apple          | 16.008 |
| sandwich      | 33.630 | orange       | 25.949 | broccoli       | 18.159 |
| carrot        | 15.275 | hot dog      | 26.661 | pizza          | 50.397 |
| donut         | 45.145 | cake         | 35.632 | chair          | 15.130 |
| couch         | 29.855 | potted plant | 20.969 | bed            | 29.743 |
| dining table  | 12.636 | toilet       | 57.554 | tv             | 53.262 |
| laptop        | 55.807 | mouse        | 56.915 | remote         | 25.416 |
| keyboard      | 43.639 | cell phone   | 30.613 | microwave      | 51.750 |
| oven          | 24.998 | toaster      | 27.359 | sink           | 30.740 |
| refrigerator  | 49.853 | book         | 7.247  | clock          | 44.406 |
| vase          | 33.352 | scissors     | 16.707 | teddy bear     | 43.698 |
| hair drier    | 0.616  | toothbrush   | 13.695 |                |        |
[09/22 15:43:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[09/22 15:43:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 15:43:26] d2.evaluation.testing INFO: copypaste: 35.4500,56.6885,38.3684,20.7573,37.9621,48.0738
[09/22 15:43:26] d2.evaluation.testing INFO: copypaste: Task: segm
[09/22 15:43:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/22 15:43:26] d2.evaluation.testing INFO: copypaste: 33.7101,54.2360,36.1708,16.5473,35.1716,50.5344
[09/28 17:29:36] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 17:29:36] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 17:29:36] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 17:29:36] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 17:29:36] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 17:29:36] d2.utils.env INFO: Using a generated random seed 40146571
[09/28 17:30:52] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 17:30:52] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 17:30:52] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 17:30:52] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 17:30:52] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 17:30:52] d2.utils.env INFO: Using a generated random seed 56314821
[09/28 17:30:52] d2.config.instantiate ERROR: Error when instantiating detectron2.modeling.backbone.hiera_abs_win.HieraAbsWin!
[09/28 17:32:27] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 17:32:28] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 17:32:28] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 17:32:28] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 17:32:28] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 17:32:28] d2.utils.env INFO: Using a generated random seed 31523311
[09/28 18:06:06] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:06:07] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:06:07] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:06:07] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:06:07] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:06:07] d2.utils.env INFO: Using a generated random seed 10892723
[09/28 18:24:58] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:24:58] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:24:58] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.'])
[09/28 18:24:58] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:24:58] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:24:58] d2.utils.env INFO: Using a generated random seed 62383042
[09/28 18:25:42] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:25:43] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:25:43] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:25:43] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:25:43] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:25:43] d2.utils.env INFO: Using a generated random seed 46579899
[09/28 18:26:47] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:26:48] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:26:48] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:26:48] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:26:48] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:26:48] d2.utils.env INFO: Using a generated random seed 51551682
[09/28 18:26:49] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:26:49] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:26:50] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:26:51] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:26:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:26:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:26:51] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:26:51] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:26:51] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:26:51] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:28:56] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:28:56] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:28:56] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:28:56] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:28:56] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:28:56] d2.utils.env INFO: Using a generated random seed 60397453
[09/28 18:28:57] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:28:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:28:58] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:28:59] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:28:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:28:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:28:59] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:28:59] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:28:59] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:28:59] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:38:26] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:38:26] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:38:26] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:38:26] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:38:26] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:38:26] d2.utils.env INFO: Using a generated random seed 30203565
[09/28 18:38:27] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:38:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:38:28] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:38:28] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:38:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:38:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:38:28] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:38:33] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:38:33] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:38:34] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:41:32] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:41:33] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:41:33] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:41:33] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:41:33] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:41:33] d2.utils.env INFO: Using a generated random seed 36940234
[09/28 18:41:34] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:41:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:41:35] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:41:35] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:41:35] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:41:35] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:41:35] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:41:35] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:41:35] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:41:36] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:42:30] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:42:31] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:42:31] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:42:31] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:42:31] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:42:31] d2.utils.env INFO: Using a generated random seed 34596952
[09/28 18:42:32] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:42:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:42:32] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:42:33] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:42:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:42:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:42:33] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:42:33] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:42:33] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:42:34] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:50:48] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:50:48] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:50:48] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:50:48] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:50:48] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:50:48] d2.utils.env INFO: Using a generated random seed 52365423
[09/28 18:50:49] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:50:49] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:50:50] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:50:51] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:50:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:50:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:50:51] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:50:53] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:50:53] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:50:53] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:52:34] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:52:35] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:52:35] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:52:35] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:52:35] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:52:35] d2.utils.env INFO: Using a generated random seed 38816684
[09/28 18:52:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:52:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:52:36] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 18:52:36] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 18:52:36] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:52:37] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:52:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:52:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:52:37] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:52:37] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:52:37] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:52:38] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 18:54:16] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 18:54:17] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 18:54:17] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 18:54:17] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 18:54:17] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 18:54:17] d2.utils.env INFO: Using a generated random seed 20870654
[09/28 18:54:18] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:54:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 18:54:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 18:54:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 18:54:18] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 18:54:19] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 18:54:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 18:54:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 18:54:19] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 18:54:19] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 18:54:19] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 18:54:20] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:05:17] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:05:17] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:05:17] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:05:17] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:05:17] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:05:17] d2.utils.env INFO: Using a generated random seed 21258908
[09/28 19:05:18] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:05:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:05:19] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:05:19] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:05:19] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:05:20] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:05:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:05:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:05:20] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:05:24] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:05:24] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:05:25] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:08:19] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:08:19] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:08:19] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:08:19] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:08:19] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:08:19] d2.utils.env INFO: Using a generated random seed 23305123
[09/28 19:08:35] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:08:36] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:08:36] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:08:36] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:08:36] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:08:36] d2.utils.env INFO: Using a generated random seed 39506368
[09/28 19:10:22] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:10:22] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:10:22] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:10:22] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:10:23] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:10:23] d2.utils.env INFO: Using a generated random seed 26434675
[09/28 19:10:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:10:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:10:24] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:10:24] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:10:24] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:10:25] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:10:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:10:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:10:25] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:10:25] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:10:25] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:10:25] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:19:27] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:19:28] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:19:28] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:19:28] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:19:28] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:19:28] d2.utils.env INFO: Using a generated random seed 31939590
[09/28 19:19:29] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:19:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:19:29] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:19:29] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:19:30] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:19:30] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:19:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:19:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:19:30] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:19:30] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:19:30] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:19:31] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:23:20] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:23:20] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:23:20] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:23:20] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:23:21] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:23:21] d2.utils.env INFO: Using a generated random seed 24475568
[09/28 19:23:21] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:23:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:23:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:23:22] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:23:22] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:23:23] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:23:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:23:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:23:23] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:23:23] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:23:23] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:23:23] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:26:45] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:26:46] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:26:46] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:26:46] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:26:46] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:26:46] d2.utils.env INFO: Using a generated random seed 49611632
[09/28 19:26:47] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:26:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:26:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:26:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:26:47] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:26:48] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:26:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:26:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:26:48] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:26:48] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:26:48] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:26:48] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:27:08] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:27:08] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:27:08] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:27:08] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:27:08] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:27:08] d2.utils.env INFO: Using a generated random seed 12210064
[09/28 19:27:09] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:27:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:27:09] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:27:09] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:27:10] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:27:10] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:27:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:27:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:27:10] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:27:10] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:27:11] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:27:11] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/28 19:28:39] detectron2 INFO: Rank of current process: 0. World size: 1
[09/28 19:28:40] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/28 19:28:40] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/28 19:28:40] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/28 19:28:40] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/28 19:28:40] d2.utils.env INFO: Using a generated random seed 43845182
[09/28 19:28:41] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:28:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/28 19:28:41] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/28 19:28:41] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/28 19:28:42] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/28 19:28:42] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/28 19:28:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/28 19:28:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/28 19:28:42] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/28 19:28:42] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/28 19:28:42] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/28 19:28:43] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 15:03:21] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 15:03:22] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 15:03:22] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 15:03:22] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_512",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=399.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 15:03:22] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 15:03:22] d2.utils.env INFO: Using a generated random seed 25585215
[09/29 15:03:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 15:03:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 15:03:25] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 15:03:25] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 15:03:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 15:03:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 15:03:25] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 15:03:25] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 15:03:25] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 15:03:26] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 15:12:20] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 15:12:20] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 15:12:20] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 15:12:20] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_512",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=399.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 15:12:21] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 15:12:21] d2.utils.env INFO: Using a generated random seed 24521193
[09/29 15:12:21] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 15:12:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 15:12:22] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 15:12:23] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 15:12:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 15:12:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 15:12:23] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 15:12:23] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 15:12:23] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 15:12:23] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 15:12:26] d2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0011 s/iter. Inference: 0.1399 s/iter. Eval: 0.0301 s/iter. Total: 0.1711 s/iter. ETA=0:14:13
[09/29 15:12:31] d2.evaluation.evaluator INFO: Inference done 41/5000. Dataloading: 0.0015 s/iter. Inference: 0.1410 s/iter. Eval: 0.0286 s/iter. Total: 0.1711 s/iter. ETA=0:14:08
[09/29 15:12:36] d2.evaluation.evaluator INFO: Inference done 71/5000. Dataloading: 0.0014 s/iter. Inference: 0.1423 s/iter. Eval: 0.0261 s/iter. Total: 0.1698 s/iter. ETA=0:13:57
[09/29 15:12:42] d2.evaluation.evaluator INFO: Inference done 102/5000. Dataloading: 0.0015 s/iter. Inference: 0.1412 s/iter. Eval: 0.0260 s/iter. Total: 0.1687 s/iter. ETA=0:13:46
[09/29 15:12:47] d2.evaluation.evaluator INFO: Inference done 132/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0263 s/iter. Total: 0.1693 s/iter. ETA=0:13:44
[09/29 15:12:52] d2.evaluation.evaluator INFO: Inference done 161/5000. Dataloading: 0.0014 s/iter. Inference: 0.1424 s/iter. Eval: 0.0264 s/iter. Total: 0.1703 s/iter. ETA=0:13:44
[09/29 15:12:57] d2.evaluation.evaluator INFO: Inference done 192/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0260 s/iter. Total: 0.1696 s/iter. ETA=0:13:35
[09/29 15:13:02] d2.evaluation.evaluator INFO: Inference done 224/5000. Dataloading: 0.0014 s/iter. Inference: 0.1412 s/iter. Eval: 0.0252 s/iter. Total: 0.1679 s/iter. ETA=0:13:22
[09/29 15:13:07] d2.evaluation.evaluator INFO: Inference done 254/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0251 s/iter. Total: 0.1679 s/iter. ETA=0:13:16
[09/29 15:13:12] d2.evaluation.evaluator INFO: Inference done 285/5000. Dataloading: 0.0014 s/iter. Inference: 0.1412 s/iter. Eval: 0.0248 s/iter. Total: 0.1675 s/iter. ETA=0:13:09
[09/29 15:13:17] d2.evaluation.evaluator INFO: Inference done 315/5000. Dataloading: 0.0014 s/iter. Inference: 0.1413 s/iter. Eval: 0.0248 s/iter. Total: 0.1676 s/iter. ETA=0:13:05
[09/29 15:13:22] d2.evaluation.evaluator INFO: Inference done 345/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0247 s/iter. Total: 0.1676 s/iter. ETA=0:12:59
[09/29 15:13:27] d2.evaluation.evaluator INFO: Inference done 376/5000. Dataloading: 0.0014 s/iter. Inference: 0.1416 s/iter. Eval: 0.0244 s/iter. Total: 0.1674 s/iter. ETA=0:12:54
[09/29 15:13:32] d2.evaluation.evaluator INFO: Inference done 406/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0245 s/iter. Total: 0.1675 s/iter. ETA=0:12:49
[09/29 15:13:37] d2.evaluation.evaluator INFO: Inference done 437/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0243 s/iter. Total: 0.1672 s/iter. ETA=0:12:42
[09/29 15:13:42] d2.evaluation.evaluator INFO: Inference done 467/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0242 s/iter. Total: 0.1672 s/iter. ETA=0:12:37
[09/29 15:13:48] d2.evaluation.evaluator INFO: Inference done 498/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0240 s/iter. Total: 0.1670 s/iter. ETA=0:12:32
[09/29 15:13:53] d2.evaluation.evaluator INFO: Inference done 529/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0240 s/iter. Total: 0.1669 s/iter. ETA=0:12:26
[09/29 15:13:58] d2.evaluation.evaluator INFO: Inference done 559/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0242 s/iter. Total: 0.1671 s/iter. ETA=0:12:21
[09/29 15:14:03] d2.evaluation.evaluator INFO: Inference done 590/5000. Dataloading: 0.0014 s/iter. Inference: 0.1413 s/iter. Eval: 0.0242 s/iter. Total: 0.1670 s/iter. ETA=0:12:16
[09/29 15:14:08] d2.evaluation.evaluator INFO: Inference done 620/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0242 s/iter. Total: 0.1672 s/iter. ETA=0:12:12
[09/29 15:14:13] d2.evaluation.evaluator INFO: Inference done 650/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0244 s/iter. Total: 0.1674 s/iter. ETA=0:12:07
[09/29 15:14:18] d2.evaluation.evaluator INFO: Inference done 681/5000. Dataloading: 0.0014 s/iter. Inference: 0.1416 s/iter. Eval: 0.0243 s/iter. Total: 0.1674 s/iter. ETA=0:12:02
[09/29 15:14:23] d2.evaluation.evaluator INFO: Inference done 710/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0245 s/iter. Total: 0.1677 s/iter. ETA=0:11:59
[09/29 15:14:29] d2.evaluation.evaluator INFO: Inference done 741/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0244 s/iter. Total: 0.1676 s/iter. ETA=0:11:53
[09/29 15:14:34] d2.evaluation.evaluator INFO: Inference done 771/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0243 s/iter. Total: 0.1678 s/iter. ETA=0:11:49
[09/29 15:14:39] d2.evaluation.evaluator INFO: Inference done 801/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0243 s/iter. Total: 0.1678 s/iter. ETA=0:11:44
[09/29 15:14:44] d2.evaluation.evaluator INFO: Inference done 833/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0241 s/iter. Total: 0.1675 s/iter. ETA=0:11:37
[09/29 15:14:49] d2.evaluation.evaluator INFO: Inference done 863/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0241 s/iter. Total: 0.1675 s/iter. ETA=0:11:33
[09/29 15:14:54] d2.evaluation.evaluator INFO: Inference done 896/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0238 s/iter. Total: 0.1671 s/iter. ETA=0:11:25
[09/29 15:14:59] d2.evaluation.evaluator INFO: Inference done 927/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0238 s/iter. Total: 0.1670 s/iter. ETA=0:11:20
[09/29 15:15:04] d2.evaluation.evaluator INFO: Inference done 958/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0237 s/iter. Total: 0.1669 s/iter. ETA=0:11:14
[09/29 15:15:09] d2.evaluation.evaluator INFO: Inference done 987/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:11:11
[09/29 15:15:15] d2.evaluation.evaluator INFO: Inference done 1017/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0240 s/iter. Total: 0.1673 s/iter. ETA=0:11:06
[09/29 15:15:20] d2.evaluation.evaluator INFO: Inference done 1048/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:11:00
[09/29 15:15:25] d2.evaluation.evaluator INFO: Inference done 1078/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:10:55
[09/29 15:15:30] d2.evaluation.evaluator INFO: Inference done 1109/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0238 s/iter. Total: 0.1671 s/iter. ETA=0:10:50
[09/29 15:15:35] d2.evaluation.evaluator INFO: Inference done 1139/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0238 s/iter. Total: 0.1673 s/iter. ETA=0:10:45
[09/29 15:15:40] d2.evaluation.evaluator INFO: Inference done 1169/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0238 s/iter. Total: 0.1673 s/iter. ETA=0:10:40
[09/29 15:15:45] d2.evaluation.evaluator INFO: Inference done 1199/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:10:35
[09/29 15:15:50] d2.evaluation.evaluator INFO: Inference done 1229/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:10:30
[09/29 15:15:55] d2.evaluation.evaluator INFO: Inference done 1257/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0240 s/iter. Total: 0.1676 s/iter. ETA=0:10:27
[09/29 15:16:00] d2.evaluation.evaluator INFO: Inference done 1287/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0240 s/iter. Total: 0.1676 s/iter. ETA=0:10:22
[09/29 15:16:05] d2.evaluation.evaluator INFO: Inference done 1318/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0241 s/iter. Total: 0.1675 s/iter. ETA=0:10:16
[09/29 15:16:10] d2.evaluation.evaluator INFO: Inference done 1349/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0240 s/iter. Total: 0.1675 s/iter. ETA=0:10:11
[09/29 15:16:15] d2.evaluation.evaluator INFO: Inference done 1379/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0240 s/iter. Total: 0.1674 s/iter. ETA=0:10:06
[09/29 15:16:20] d2.evaluation.evaluator INFO: Inference done 1410/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:10:00
[09/29 15:16:25] d2.evaluation.evaluator INFO: Inference done 1441/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:09:55
[09/29 15:16:30] d2.evaluation.evaluator INFO: Inference done 1471/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:09:50
[09/29 15:16:36] d2.evaluation.evaluator INFO: Inference done 1502/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:09:44
[09/29 15:16:41] d2.evaluation.evaluator INFO: Inference done 1533/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0240 s/iter. Total: 0.1672 s/iter. ETA=0:09:39
[09/29 15:16:46] d2.evaluation.evaluator INFO: Inference done 1563/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0240 s/iter. Total: 0.1673 s/iter. ETA=0:09:34
[09/29 15:16:51] d2.evaluation.evaluator INFO: Inference done 1594/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:09:29
[09/29 15:16:56] d2.evaluation.evaluator INFO: Inference done 1623/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0240 s/iter. Total: 0.1673 s/iter. ETA=0:09:24
[09/29 15:17:01] d2.evaluation.evaluator INFO: Inference done 1652/5000. Dataloading: 0.0016 s/iter. Inference: 0.1418 s/iter. Eval: 0.0241 s/iter. Total: 0.1675 s/iter. ETA=0:09:20
[09/29 15:17:06] d2.evaluation.evaluator INFO: Inference done 1683/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0240 s/iter. Total: 0.1674 s/iter. ETA=0:09:15
[09/29 15:17:11] d2.evaluation.evaluator INFO: Inference done 1714/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0240 s/iter. Total: 0.1673 s/iter. ETA=0:09:09
[09/29 15:17:16] d2.evaluation.evaluator INFO: Inference done 1745/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:09:04
[09/29 15:17:21] d2.evaluation.evaluator INFO: Inference done 1775/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:08:59
[09/29 15:17:26] d2.evaluation.evaluator INFO: Inference done 1806/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:08:54
[09/29 15:17:32] d2.evaluation.evaluator INFO: Inference done 1837/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:08:48
[09/29 15:17:37] d2.evaluation.evaluator INFO: Inference done 1867/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0239 s/iter. Total: 0.1673 s/iter. ETA=0:08:44
[09/29 15:17:42] d2.evaluation.evaluator INFO: Inference done 1898/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0239 s/iter. Total: 0.1672 s/iter. ETA=0:08:38
[09/29 15:17:47] d2.evaluation.evaluator INFO: Inference done 1929/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0238 s/iter. Total: 0.1671 s/iter. ETA=0:08:33
[09/29 15:17:52] d2.evaluation.evaluator INFO: Inference done 1962/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0237 s/iter. Total: 0.1669 s/iter. ETA=0:08:27
[09/29 15:17:57] d2.evaluation.evaluator INFO: Inference done 1992/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0237 s/iter. Total: 0.1669 s/iter. ETA=0:08:22
[09/29 15:18:02] d2.evaluation.evaluator INFO: Inference done 2021/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0238 s/iter. Total: 0.1670 s/iter. ETA=0:08:17
[09/29 15:18:07] d2.evaluation.evaluator INFO: Inference done 2052/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0238 s/iter. Total: 0.1670 s/iter. ETA=0:08:12
[09/29 15:18:12] d2.evaluation.evaluator INFO: Inference done 2083/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0237 s/iter. Total: 0.1670 s/iter. ETA=0:08:07
[09/29 15:18:17] d2.evaluation.evaluator INFO: Inference done 2114/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0237 s/iter. Total: 0.1669 s/iter. ETA=0:08:01
[09/29 15:18:22] d2.evaluation.evaluator INFO: Inference done 2147/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0236 s/iter. Total: 0.1668 s/iter. ETA=0:07:55
[09/29 15:18:28] d2.evaluation.evaluator INFO: Inference done 2179/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0236 s/iter. Total: 0.1667 s/iter. ETA=0:07:50
[09/29 15:18:33] d2.evaluation.evaluator INFO: Inference done 2211/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0235 s/iter. Total: 0.1665 s/iter. ETA=0:07:44
[09/29 15:18:38] d2.evaluation.evaluator INFO: Inference done 2242/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:39
[09/29 15:18:43] d2.evaluation.evaluator INFO: Inference done 2272/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:34
[09/29 15:18:48] d2.evaluation.evaluator INFO: Inference done 2302/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0235 s/iter. Total: 0.1665 s/iter. ETA=0:07:29
[09/29 15:18:53] d2.evaluation.evaluator INFO: Inference done 2333/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:24
[09/29 15:18:58] d2.evaluation.evaluator INFO: Inference done 2364/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:18
[09/29 15:19:03] d2.evaluation.evaluator INFO: Inference done 2395/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:13
[09/29 15:19:08] d2.evaluation.evaluator INFO: Inference done 2425/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:08
[09/29 15:19:13] d2.evaluation.evaluator INFO: Inference done 2455/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1666 s/iter. ETA=0:07:03
[09/29 15:19:18] d2.evaluation.evaluator INFO: Inference done 2486/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:58
[09/29 15:19:23] d2.evaluation.evaluator INFO: Inference done 2516/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:53
[09/29 15:19:29] d2.evaluation.evaluator INFO: Inference done 2547/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:48
[09/29 15:19:34] d2.evaluation.evaluator INFO: Inference done 2578/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:43
[09/29 15:19:39] d2.evaluation.evaluator INFO: Inference done 2610/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1664 s/iter. ETA=0:06:37
[09/29 15:19:44] d2.evaluation.evaluator INFO: Inference done 2640/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:32
[09/29 15:19:49] d2.evaluation.evaluator INFO: Inference done 2671/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:27
[09/29 15:19:54] d2.evaluation.evaluator INFO: Inference done 2702/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:22
[09/29 15:19:59] d2.evaluation.evaluator INFO: Inference done 2733/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0233 s/iter. Total: 0.1664 s/iter. ETA=0:06:17
[09/29 15:20:04] d2.evaluation.evaluator INFO: Inference done 2764/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0233 s/iter. Total: 0.1664 s/iter. ETA=0:06:12
[09/29 15:20:09] d2.evaluation.evaluator INFO: Inference done 2794/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1664 s/iter. ETA=0:06:07
[09/29 15:20:14] d2.evaluation.evaluator INFO: Inference done 2823/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:06:02
[09/29 15:20:20] d2.evaluation.evaluator INFO: Inference done 2851/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0235 s/iter. Total: 0.1667 s/iter. ETA=0:05:58
[09/29 15:20:25] d2.evaluation.evaluator INFO: Inference done 2882/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0235 s/iter. Total: 0.1666 s/iter. ETA=0:05:52
[09/29 15:20:30] d2.evaluation.evaluator INFO: Inference done 2913/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0235 s/iter. Total: 0.1666 s/iter. ETA=0:05:47
[09/29 15:20:35] d2.evaluation.evaluator INFO: Inference done 2945/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:05:42
[09/29 15:20:40] d2.evaluation.evaluator INFO: Inference done 2976/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:05:37
[09/29 15:20:45] d2.evaluation.evaluator INFO: Inference done 3007/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:05:31
[09/29 15:20:50] d2.evaluation.evaluator INFO: Inference done 3038/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:05:26
[09/29 15:20:55] d2.evaluation.evaluator INFO: Inference done 3069/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:05:21
[09/29 15:21:00] d2.evaluation.evaluator INFO: Inference done 3099/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0233 s/iter. Total: 0.1665 s/iter. ETA=0:05:16
[09/29 15:21:05] d2.evaluation.evaluator INFO: Inference done 3129/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:05:11
[09/29 15:21:10] d2.evaluation.evaluator INFO: Inference done 3160/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0233 s/iter. Total: 0.1665 s/iter. ETA=0:05:06
[09/29 15:21:16] d2.evaluation.evaluator INFO: Inference done 3192/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0233 s/iter. Total: 0.1664 s/iter. ETA=0:05:00
[09/29 15:21:21] d2.evaluation.evaluator INFO: Inference done 3223/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0233 s/iter. Total: 0.1664 s/iter. ETA=0:04:55
[09/29 15:21:26] d2.evaluation.evaluator INFO: Inference done 3255/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1663 s/iter. ETA=0:04:50
[09/29 15:21:31] d2.evaluation.evaluator INFO: Inference done 3285/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:45
[09/29 15:21:36] d2.evaluation.evaluator INFO: Inference done 3315/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:40
[09/29 15:21:41] d2.evaluation.evaluator INFO: Inference done 3347/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1663 s/iter. ETA=0:04:34
[09/29 15:21:46] d2.evaluation.evaluator INFO: Inference done 3377/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:30
[09/29 15:21:51] d2.evaluation.evaluator INFO: Inference done 3408/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:24
[09/29 15:21:56] d2.evaluation.evaluator INFO: Inference done 3438/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:19
[09/29 15:22:01] d2.evaluation.evaluator INFO: Inference done 3467/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:15
[09/29 15:22:07] d2.evaluation.evaluator INFO: Inference done 3498/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:09
[09/29 15:22:12] d2.evaluation.evaluator INFO: Inference done 3529/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:04:04
[09/29 15:22:17] d2.evaluation.evaluator INFO: Inference done 3559/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:03:59
[09/29 15:22:22] d2.evaluation.evaluator INFO: Inference done 3588/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:03:55
[09/29 15:22:27] d2.evaluation.evaluator INFO: Inference done 3619/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:03:49
[09/29 15:22:32] d2.evaluation.evaluator INFO: Inference done 3648/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0233 s/iter. Total: 0.1665 s/iter. ETA=0:03:45
[09/29 15:22:37] d2.evaluation.evaluator INFO: Inference done 3679/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:03:39
[09/29 15:22:42] d2.evaluation.evaluator INFO: Inference done 3709/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:03:35
[09/29 15:22:47] d2.evaluation.evaluator INFO: Inference done 3739/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1666 s/iter. ETA=0:03:30
[09/29 15:22:52] d2.evaluation.evaluator INFO: Inference done 3770/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:03:24
[09/29 15:22:57] d2.evaluation.evaluator INFO: Inference done 3800/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1666 s/iter. ETA=0:03:19
[09/29 15:23:02] d2.evaluation.evaluator INFO: Inference done 3831/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:03:14
[09/29 15:23:08] d2.evaluation.evaluator INFO: Inference done 3863/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:09
[09/29 15:23:13] d2.evaluation.evaluator INFO: Inference done 3894/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:03:04
[09/29 15:23:18] d2.evaluation.evaluator INFO: Inference done 3924/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:02:59
[09/29 15:23:23] d2.evaluation.evaluator INFO: Inference done 3954/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:54
[09/29 15:23:28] d2.evaluation.evaluator INFO: Inference done 3985/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:48
[09/29 15:23:33] d2.evaluation.evaluator INFO: Inference done 4015/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:43
[09/29 15:23:38] d2.evaluation.evaluator INFO: Inference done 4045/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:38
[09/29 15:23:43] d2.evaluation.evaluator INFO: Inference done 4075/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:34
[09/29 15:23:48] d2.evaluation.evaluator INFO: Inference done 4106/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:28
[09/29 15:23:53] d2.evaluation.evaluator INFO: Inference done 4136/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:23
[09/29 15:23:58] d2.evaluation.evaluator INFO: Inference done 4166/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:18
[09/29 15:24:03] d2.evaluation.evaluator INFO: Inference done 4195/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1666 s/iter. ETA=0:02:14
[09/29 15:24:08] d2.evaluation.evaluator INFO: Inference done 4227/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:08
[09/29 15:24:13] d2.evaluation.evaluator INFO: Inference done 4259/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:02:03
[09/29 15:24:18] d2.evaluation.evaluator INFO: Inference done 4288/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:01:58
[09/29 15:24:24] d2.evaluation.evaluator INFO: Inference done 4319/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:01:53
[09/29 15:24:29] d2.evaluation.evaluator INFO: Inference done 4351/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:01:48
[09/29 15:24:34] d2.evaluation.evaluator INFO: Inference done 4383/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:01:42
[09/29 15:24:39] d2.evaluation.evaluator INFO: Inference done 4414/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:01:37
[09/29 15:24:44] d2.evaluation.evaluator INFO: Inference done 4444/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:01:32
[09/29 15:24:49] d2.evaluation.evaluator INFO: Inference done 4475/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:01:27
[09/29 15:24:54] d2.evaluation.evaluator INFO: Inference done 4506/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:01:22
[09/29 15:24:59] d2.evaluation.evaluator INFO: Inference done 4537/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:17
[09/29 15:25:04] d2.evaluation.evaluator INFO: Inference done 4568/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:11
[09/29 15:25:09] d2.evaluation.evaluator INFO: Inference done 4598/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:06
[09/29 15:25:15] d2.evaluation.evaluator INFO: Inference done 4629/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:01
[09/29 15:25:20] d2.evaluation.evaluator INFO: Inference done 4660/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:56
[09/29 15:25:25] d2.evaluation.evaluator INFO: Inference done 4691/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:51
[09/29 15:25:30] d2.evaluation.evaluator INFO: Inference done 4721/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:46
[09/29 15:25:35] d2.evaluation.evaluator INFO: Inference done 4752/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:41
[09/29 15:25:40] d2.evaluation.evaluator INFO: Inference done 4782/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:36
[09/29 15:25:45] d2.evaluation.evaluator INFO: Inference done 4813/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:31
[09/29 15:25:50] d2.evaluation.evaluator INFO: Inference done 4844/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:25
[09/29 15:25:55] d2.evaluation.evaluator INFO: Inference done 4875/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:20
[09/29 15:26:01] d2.evaluation.evaluator INFO: Inference done 4906/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1663 s/iter. ETA=0:00:15
[09/29 15:26:06] d2.evaluation.evaluator INFO: Inference done 4936/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:10
[09/29 15:26:11] d2.evaluation.evaluator INFO: Inference done 4965/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:05
[09/29 15:26:16] d2.evaluation.evaluator INFO: Inference done 4995/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:00:00
[09/29 15:26:16] d2.evaluation.evaluator INFO: Total inference time: 0:13:51.250420 (0.166417 s / iter per device, on 1 devices)
[09/29 15:26:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:11:48 (0.141925 s / iter per device, on 1 devices)
[09/29 15:26:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[09/29 15:26:17] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[09/29 15:26:41] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.191 | 0.308  | 0.231  | 0.227 | 0.203 | 0.026 |
[09/29 15:26:41] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.994 | bicycle      | 0.003 | car            | 0.307 |
| motorcycle    | 0.023 | airplane     | 0.023 | bus            | 0.002 |
| train         | 0.000 | truck        | 0.022 | boat           | 0.009 |
| traffic light | 0.123 | fire hydrant | 0.000 | stop sign      | 1.836 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.002 | horse          | 0.003 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.011 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.594 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 9.725 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.001 | wine glass   | 0.000 | cup            | 0.372 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.637 | banana       | 0.000 | apple          | 0.014 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.074 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.445 | toilet       | 0.000 | tv             | 0.009 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.003 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.005 | toaster      | 0.000 | sink           | 0.001 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.009 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[09/29 15:27:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.209 | 0.291  | 0.247  | 0.248 | 0.243 | 0.017 |
[09/29 15:27:14] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP     |
|:--------------|:------|:-------------|:------|:---------------|:-------|
| person        | 0.889 | bicycle      | 0.000 | car            | 0.500  |
| motorcycle    | 0.006 | airplane     | 0.000 | bus            | 0.000  |
| train         | 0.000 | truck        | 0.007 | boat           | 0.002  |
| traffic light | 0.131 | fire hydrant | 0.000 | stop sign      | 2.110  |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000  |
| cat           | 0.000 | dog          | 0.004 | horse          | 0.000  |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000  |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000  |
| backpack      | 0.000 | umbrella     | 0.014 | handbag        | 0.000  |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.792  |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 10.908 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000  |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000  |
| bottle        | 0.002 | wine glass   | 0.000 | cup            | 0.427  |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000  |
| bowl          | 0.738 | banana       | 0.000 | apple          | 0.014  |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000  |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.074  |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000  |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000  |
| dining table  | 0.082 | toilet       | 0.000 | tv             | 0.011  |
| laptop        | 0.000 | mouse        | 0.001 | remote         | 0.003  |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000  |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.001  |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.008  |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000  |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |        |
[09/29 15:27:15] d2.evaluation.testing INFO: copypaste: Task: bbox
[09/29 15:27:15] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/29 15:27:15] d2.evaluation.testing INFO: copypaste: 0.1906,0.3076,0.2310,0.2267,0.2027,0.0261
[09/29 15:27:15] d2.evaluation.testing INFO: copypaste: Task: segm
[09/29 15:27:15] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/29 15:27:15] d2.evaluation.testing INFO: copypaste: 0.2091,0.2905,0.2474,0.2478,0.2426,0.0166
[09/29 15:33:48] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 15:33:49] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 15:33:49] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 15:33:49] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_512",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=349.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 15:33:49] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 15:33:49] d2.utils.env INFO: Using a generated random seed 52715901
[09/29 15:33:50] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 15:33:50] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 15:33:51] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 15:33:51] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 15:33:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 15:33:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 15:33:51] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 15:33:51] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 15:33:51] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 15:33:52] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 15:33:54] d2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0008 s/iter. Inference: 0.1391 s/iter. Eval: 0.0248 s/iter. Total: 0.1648 s/iter. ETA=0:13:42
[09/29 15:33:59] d2.evaluation.evaluator INFO: Inference done 41/5000. Dataloading: 0.0013 s/iter. Inference: 0.1405 s/iter. Eval: 0.0273 s/iter. Total: 0.1691 s/iter. ETA=0:13:58
[09/29 15:34:04] d2.evaluation.evaluator INFO: Inference done 71/5000. Dataloading: 0.0013 s/iter. Inference: 0.1430 s/iter. Eval: 0.0262 s/iter. Total: 0.1706 s/iter. ETA=0:14:00
[09/29 15:34:10] d2.evaluation.evaluator INFO: Inference done 102/5000. Dataloading: 0.0013 s/iter. Inference: 0.1418 s/iter. Eval: 0.0254 s/iter. Total: 0.1685 s/iter. ETA=0:13:45
[09/29 15:34:15] d2.evaluation.evaluator INFO: Inference done 132/5000. Dataloading: 0.0013 s/iter. Inference: 0.1420 s/iter. Eval: 0.0256 s/iter. Total: 0.1689 s/iter. ETA=0:13:42
[09/29 15:34:20] d2.evaluation.evaluator INFO: Inference done 162/5000. Dataloading: 0.0013 s/iter. Inference: 0.1425 s/iter. Eval: 0.0254 s/iter. Total: 0.1693 s/iter. ETA=0:13:38
[09/29 15:34:25] d2.evaluation.evaluator INFO: Inference done 193/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0251 s/iter. Total: 0.1684 s/iter. ETA=0:13:29
[09/29 15:34:30] d2.evaluation.evaluator INFO: Inference done 225/5000. Dataloading: 0.0013 s/iter. Inference: 0.1411 s/iter. Eval: 0.0246 s/iter. Total: 0.1671 s/iter. ETA=0:13:17
[09/29 15:34:35] d2.evaluation.evaluator INFO: Inference done 256/5000. Dataloading: 0.0014 s/iter. Inference: 0.1413 s/iter. Eval: 0.0242 s/iter. Total: 0.1669 s/iter. ETA=0:13:11
[09/29 15:34:40] d2.evaluation.evaluator INFO: Inference done 286/5000. Dataloading: 0.0013 s/iter. Inference: 0.1413 s/iter. Eval: 0.0242 s/iter. Total: 0.1669 s/iter. ETA=0:13:06
[09/29 15:34:45] d2.evaluation.evaluator INFO: Inference done 317/5000. Dataloading: 0.0013 s/iter. Inference: 0.1412 s/iter. Eval: 0.0239 s/iter. Total: 0.1665 s/iter. ETA=0:12:59
[09/29 15:34:50] d2.evaluation.evaluator INFO: Inference done 347/5000. Dataloading: 0.0013 s/iter. Inference: 0.1414 s/iter. Eval: 0.0239 s/iter. Total: 0.1667 s/iter. ETA=0:12:55
[09/29 15:34:55] d2.evaluation.evaluator INFO: Inference done 378/5000. Dataloading: 0.0013 s/iter. Inference: 0.1415 s/iter. Eval: 0.0235 s/iter. Total: 0.1664 s/iter. ETA=0:12:49
[09/29 15:35:00] d2.evaluation.evaluator INFO: Inference done 409/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0235 s/iter. Total: 0.1664 s/iter. ETA=0:12:43
[09/29 15:35:06] d2.evaluation.evaluator INFO: Inference done 440/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0233 s/iter. Total: 0.1661 s/iter. ETA=0:12:37
[09/29 15:35:11] d2.evaluation.evaluator INFO: Inference done 471/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0233 s/iter. Total: 0.1661 s/iter. ETA=0:12:32
[09/29 15:35:16] d2.evaluation.evaluator INFO: Inference done 501/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0234 s/iter. Total: 0.1663 s/iter. ETA=0:12:28
[09/29 15:35:21] d2.evaluation.evaluator INFO: Inference done 532/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0234 s/iter. Total: 0.1662 s/iter. ETA=0:12:22
[09/29 15:35:26] d2.evaluation.evaluator INFO: Inference done 562/5000. Dataloading: 0.0014 s/iter. Inference: 0.1414 s/iter. Eval: 0.0235 s/iter. Total: 0.1664 s/iter. ETA=0:12:18
[09/29 15:35:31] d2.evaluation.evaluator INFO: Inference done 593/5000. Dataloading: 0.0014 s/iter. Inference: 0.1413 s/iter. Eval: 0.0236 s/iter. Total: 0.1664 s/iter. ETA=0:12:13
[09/29 15:35:36] d2.evaluation.evaluator INFO: Inference done 623/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0237 s/iter. Total: 0.1667 s/iter. ETA=0:12:09
[09/29 15:35:41] d2.evaluation.evaluator INFO: Inference done 653/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0238 s/iter. Total: 0.1667 s/iter. ETA=0:12:04
[09/29 15:35:46] d2.evaluation.evaluator INFO: Inference done 684/5000. Dataloading: 0.0014 s/iter. Inference: 0.1415 s/iter. Eval: 0.0237 s/iter. Total: 0.1666 s/iter. ETA=0:11:59
[09/29 15:35:51] d2.evaluation.evaluator INFO: Inference done 714/5000. Dataloading: 0.0014 s/iter. Inference: 0.1416 s/iter. Eval: 0.0237 s/iter. Total: 0.1667 s/iter. ETA=0:11:54
[09/29 15:35:56] d2.evaluation.evaluator INFO: Inference done 743/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0237 s/iter. Total: 0.1670 s/iter. ETA=0:11:50
[09/29 15:36:02] d2.evaluation.evaluator INFO: Inference done 774/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0237 s/iter. Total: 0.1670 s/iter. ETA=0:11:45
[09/29 15:36:07] d2.evaluation.evaluator INFO: Inference done 804/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0237 s/iter. Total: 0.1671 s/iter. ETA=0:11:40
[09/29 15:36:12] d2.evaluation.evaluator INFO: Inference done 836/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:11:34
[09/29 15:36:17] d2.evaluation.evaluator INFO: Inference done 866/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0236 s/iter. Total: 0.1670 s/iter. ETA=0:11:30
[09/29 15:36:22] d2.evaluation.evaluator INFO: Inference done 898/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0233 s/iter. Total: 0.1666 s/iter. ETA=0:11:23
[09/29 15:36:27] d2.evaluation.evaluator INFO: Inference done 929/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0234 s/iter. Total: 0.1666 s/iter. ETA=0:11:18
[09/29 15:36:32] d2.evaluation.evaluator INFO: Inference done 960/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0233 s/iter. Total: 0.1664 s/iter. ETA=0:11:12
[09/29 15:36:37] d2.evaluation.evaluator INFO: Inference done 989/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:11:08
[09/29 15:36:42] d2.evaluation.evaluator INFO: Inference done 1019/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1667 s/iter. ETA=0:11:03
[09/29 15:36:47] d2.evaluation.evaluator INFO: Inference done 1050/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:10:58
[09/29 15:36:53] d2.evaluation.evaluator INFO: Inference done 1080/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:53
[09/29 15:36:58] d2.evaluation.evaluator INFO: Inference done 1111/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:10:48
[09/29 15:37:03] d2.evaluation.evaluator INFO: Inference done 1141/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:43
[09/29 15:37:08] d2.evaluation.evaluator INFO: Inference done 1171/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:38
[09/29 15:37:13] d2.evaluation.evaluator INFO: Inference done 1202/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0233 s/iter. Total: 0.1668 s/iter. ETA=0:10:33
[09/29 15:37:18] d2.evaluation.evaluator INFO: Inference done 1232/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:28
[09/29 15:37:23] d2.evaluation.evaluator INFO: Inference done 1261/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0235 s/iter. Total: 0.1670 s/iter. ETA=0:10:24
[09/29 15:37:28] d2.evaluation.evaluator INFO: Inference done 1291/5000. Dataloading: 0.0014 s/iter. Inference: 0.1421 s/iter. Eval: 0.0235 s/iter. Total: 0.1670 s/iter. ETA=0:10:19
[09/29 15:37:33] d2.evaluation.evaluator INFO: Inference done 1323/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:13
[09/29 15:37:38] d2.evaluation.evaluator INFO: Inference done 1353/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:08
[09/29 15:37:43] d2.evaluation.evaluator INFO: Inference done 1383/5000. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:10:03
[09/29 15:37:48] d2.evaluation.evaluator INFO: Inference done 1414/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0234 s/iter. Total: 0.1668 s/iter. ETA=0:09:58
[09/29 15:37:53] d2.evaluation.evaluator INFO: Inference done 1445/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:09:52
[09/29 15:37:58] d2.evaluation.evaluator INFO: Inference done 1475/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:09:47
[09/29 15:38:03] d2.evaluation.evaluator INFO: Inference done 1506/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:09:42
[09/29 15:38:08] d2.evaluation.evaluator INFO: Inference done 1537/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0235 s/iter. Total: 0.1666 s/iter. ETA=0:09:36
[09/29 15:38:14] d2.evaluation.evaluator INFO: Inference done 1567/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1667 s/iter. ETA=0:09:32
[09/29 15:38:19] d2.evaluation.evaluator INFO: Inference done 1598/5000. Dataloading: 0.0014 s/iter. Inference: 0.1417 s/iter. Eval: 0.0234 s/iter. Total: 0.1666 s/iter. ETA=0:09:26
[09/29 15:38:24] d2.evaluation.evaluator INFO: Inference done 1628/5000. Dataloading: 0.0014 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1667 s/iter. ETA=0:09:22
[09/29 15:38:29] d2.evaluation.evaluator INFO: Inference done 1658/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:09:17
[09/29 15:38:34] d2.evaluation.evaluator INFO: Inference done 1688/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1669 s/iter. ETA=0:09:12
[09/29 15:38:39] d2.evaluation.evaluator INFO: Inference done 1719/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:09:07
[09/29 15:38:44] d2.evaluation.evaluator INFO: Inference done 1749/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:09:02
[09/29 15:38:49] d2.evaluation.evaluator INFO: Inference done 1779/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:08:57
[09/29 15:38:54] d2.evaluation.evaluator INFO: Inference done 1809/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:08:52
[09/29 15:38:59] d2.evaluation.evaluator INFO: Inference done 1840/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:08:47
[09/29 15:39:04] d2.evaluation.evaluator INFO: Inference done 1870/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0236 s/iter. Total: 0.1669 s/iter. ETA=0:08:42
[09/29 15:39:09] d2.evaluation.evaluator INFO: Inference done 1900/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0236 s/iter. Total: 0.1669 s/iter. ETA=0:08:37
[09/29 15:39:15] d2.evaluation.evaluator INFO: Inference done 1932/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0235 s/iter. Total: 0.1668 s/iter. ETA=0:08:31
[09/29 15:39:20] d2.evaluation.evaluator INFO: Inference done 1964/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1666 s/iter. ETA=0:08:25
[09/29 15:39:25] d2.evaluation.evaluator INFO: Inference done 1994/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1666 s/iter. ETA=0:08:20
[09/29 15:39:30] d2.evaluation.evaluator INFO: Inference done 2024/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0235 s/iter. Total: 0.1667 s/iter. ETA=0:08:16
[09/29 15:39:35] d2.evaluation.evaluator INFO: Inference done 2054/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0235 s/iter. Total: 0.1667 s/iter. ETA=0:08:11
[09/29 15:39:40] d2.evaluation.evaluator INFO: Inference done 2085/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0234 s/iter. Total: 0.1667 s/iter. ETA=0:08:05
[09/29 15:39:45] d2.evaluation.evaluator INFO: Inference done 2116/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0234 s/iter. Total: 0.1666 s/iter. ETA=0:08:00
[09/29 15:39:50] d2.evaluation.evaluator INFO: Inference done 2148/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0234 s/iter. Total: 0.1665 s/iter. ETA=0:07:54
[09/29 15:39:55] d2.evaluation.evaluator INFO: Inference done 2181/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0233 s/iter. Total: 0.1663 s/iter. ETA=0:07:48
[09/29 15:40:00] d2.evaluation.evaluator INFO: Inference done 2213/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0232 s/iter. Total: 0.1662 s/iter. ETA=0:07:43
[09/29 15:40:05] d2.evaluation.evaluator INFO: Inference done 2243/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:07:38
[09/29 15:40:10] d2.evaluation.evaluator INFO: Inference done 2273/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0232 s/iter. Total: 0.1663 s/iter. ETA=0:07:33
[09/29 15:40:15] d2.evaluation.evaluator INFO: Inference done 2304/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0232 s/iter. Total: 0.1662 s/iter. ETA=0:07:28
[09/29 15:40:20] d2.evaluation.evaluator INFO: Inference done 2335/5000. Dataloading: 0.0015 s/iter. Inference: 0.1415 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:07:22
[09/29 15:40:26] d2.evaluation.evaluator INFO: Inference done 2365/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:07:18
[09/29 15:40:31] d2.evaluation.evaluator INFO: Inference done 2396/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:07:12
[09/29 15:40:36] d2.evaluation.evaluator INFO: Inference done 2426/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:07:07
[09/29 15:40:41] d2.evaluation.evaluator INFO: Inference done 2456/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:07:02
[09/29 15:40:46] d2.evaluation.evaluator INFO: Inference done 2487/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:06:57
[09/29 15:40:51] d2.evaluation.evaluator INFO: Inference done 2518/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:06:52
[09/29 15:40:56] d2.evaluation.evaluator INFO: Inference done 2549/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:06:47
[09/29 15:41:01] d2.evaluation.evaluator INFO: Inference done 2580/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:06:42
[09/29 15:41:06] d2.evaluation.evaluator INFO: Inference done 2611/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:06:36
[09/29 15:41:11] d2.evaluation.evaluator INFO: Inference done 2640/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:06:32
[09/29 15:41:16] d2.evaluation.evaluator INFO: Inference done 2670/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:06:27
[09/29 15:41:21] d2.evaluation.evaluator INFO: Inference done 2701/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:06:22
[09/29 15:41:27] d2.evaluation.evaluator INFO: Inference done 2732/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0230 s/iter. Total: 0.1662 s/iter. ETA=0:06:17
[09/29 15:41:32] d2.evaluation.evaluator INFO: Inference done 2764/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0230 s/iter. Total: 0.1662 s/iter. ETA=0:06:11
[09/29 15:41:37] d2.evaluation.evaluator INFO: Inference done 2794/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:06:06
[09/29 15:41:42] d2.evaluation.evaluator INFO: Inference done 2824/5000. Dataloading: 0.0015 s/iter. Inference: 0.1416 s/iter. Eval: 0.0231 s/iter. Total: 0.1662 s/iter. ETA=0:06:01
[09/29 15:41:47] d2.evaluation.evaluator INFO: Inference done 2851/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:05:57
[09/29 15:41:52] d2.evaluation.evaluator INFO: Inference done 2882/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:05:52
[09/29 15:41:57] d2.evaluation.evaluator INFO: Inference done 2913/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:05:47
[09/29 15:42:02] d2.evaluation.evaluator INFO: Inference done 2944/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:05:42
[09/29 15:42:07] d2.evaluation.evaluator INFO: Inference done 2975/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:05:36
[09/29 15:42:12] d2.evaluation.evaluator INFO: Inference done 3005/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0232 s/iter. Total: 0.1664 s/iter. ETA=0:05:31
[09/29 15:42:17] d2.evaluation.evaluator INFO: Inference done 3036/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:05:26
[09/29 15:42:22] d2.evaluation.evaluator INFO: Inference done 3066/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:05:21
[09/29 15:42:28] d2.evaluation.evaluator INFO: Inference done 3096/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:05:16
[09/29 15:42:33] d2.evaluation.evaluator INFO: Inference done 3125/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0232 s/iter. Total: 0.1665 s/iter. ETA=0:05:12
[09/29 15:42:38] d2.evaluation.evaluator INFO: Inference done 3156/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:05:06
[09/29 15:42:43] d2.evaluation.evaluator INFO: Inference done 3188/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:05:01
[09/29 15:42:48] d2.evaluation.evaluator INFO: Inference done 3219/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:04:56
[09/29 15:42:53] d2.evaluation.evaluator INFO: Inference done 3250/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:04:51
[09/29 15:42:58] d2.evaluation.evaluator INFO: Inference done 3280/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:04:46
[09/29 15:43:03] d2.evaluation.evaluator INFO: Inference done 3311/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1663 s/iter. ETA=0:04:40
[09/29 15:43:08] d2.evaluation.evaluator INFO: Inference done 3343/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0230 s/iter. Total: 0.1663 s/iter. ETA=0:04:35
[09/29 15:43:13] d2.evaluation.evaluator INFO: Inference done 3373/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0230 s/iter. Total: 0.1663 s/iter. ETA=0:04:30
[09/29 15:43:18] d2.evaluation.evaluator INFO: Inference done 3404/5000. Dataloading: 0.0015 s/iter. Inference: 0.1417 s/iter. Eval: 0.0230 s/iter. Total: 0.1663 s/iter. ETA=0:04:25
[09/29 15:43:24] d2.evaluation.evaluator INFO: Inference done 3434/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1663 s/iter. ETA=0:04:20
[09/29 15:43:29] d2.evaluation.evaluator INFO: Inference done 3464/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0230 s/iter. Total: 0.1663 s/iter. ETA=0:04:15
[09/29 15:43:34] d2.evaluation.evaluator INFO: Inference done 3494/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:04:10
[09/29 15:43:39] d2.evaluation.evaluator INFO: Inference done 3525/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:04:05
[09/29 15:43:44] d2.evaluation.evaluator INFO: Inference done 3554/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:04:00
[09/29 15:43:49] d2.evaluation.evaluator INFO: Inference done 3584/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:55
[09/29 15:43:54] d2.evaluation.evaluator INFO: Inference done 3615/5000. Dataloading: 0.0015 s/iter. Inference: 0.1418 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:50
[09/29 15:43:59] d2.evaluation.evaluator INFO: Inference done 3644/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:45
[09/29 15:44:04] d2.evaluation.evaluator INFO: Inference done 3675/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:40
[09/29 15:44:09] d2.evaluation.evaluator INFO: Inference done 3705/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:35
[09/29 15:44:14] d2.evaluation.evaluator INFO: Inference done 3735/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:30
[09/29 15:44:19] d2.evaluation.evaluator INFO: Inference done 3765/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:25
[09/29 15:44:24] d2.evaluation.evaluator INFO: Inference done 3795/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:20
[09/29 15:44:30] d2.evaluation.evaluator INFO: Inference done 3826/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:15
[09/29 15:44:35] d2.evaluation.evaluator INFO: Inference done 3858/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:03:10
[09/29 15:44:40] d2.evaluation.evaluator INFO: Inference done 3890/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:03:04
[09/29 15:44:45] d2.evaluation.evaluator INFO: Inference done 3921/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:59
[09/29 15:44:50] d2.evaluation.evaluator INFO: Inference done 3951/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:54
[09/29 15:44:55] d2.evaluation.evaluator INFO: Inference done 3982/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:49
[09/29 15:45:00] d2.evaluation.evaluator INFO: Inference done 4012/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:44
[09/29 15:45:05] d2.evaluation.evaluator INFO: Inference done 4042/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:02:39
[09/29 15:45:10] d2.evaluation.evaluator INFO: Inference done 4072/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1664 s/iter. ETA=0:02:34
[09/29 15:45:15] d2.evaluation.evaluator INFO: Inference done 4102/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:29
[09/29 15:45:20] d2.evaluation.evaluator INFO: Inference done 4132/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:24
[09/29 15:45:25] d2.evaluation.evaluator INFO: Inference done 4162/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1665 s/iter. ETA=0:02:19
[09/29 15:45:30] d2.evaluation.evaluator INFO: Inference done 4192/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0231 s/iter. Total: 0.1665 s/iter. ETA=0:02:14
[09/29 15:45:36] d2.evaluation.evaluator INFO: Inference done 4224/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1665 s/iter. ETA=0:02:09
[09/29 15:45:41] d2.evaluation.evaluator INFO: Inference done 4256/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:02:03
[09/29 15:45:46] d2.evaluation.evaluator INFO: Inference done 4285/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1665 s/iter. ETA=0:01:59
[09/29 15:45:51] d2.evaluation.evaluator INFO: Inference done 4315/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1665 s/iter. ETA=0:01:54
[09/29 15:45:56] d2.evaluation.evaluator INFO: Inference done 4347/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:48
[09/29 15:46:01] d2.evaluation.evaluator INFO: Inference done 4378/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:43
[09/29 15:46:06] d2.evaluation.evaluator INFO: Inference done 4410/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:38
[09/29 15:46:11] d2.evaluation.evaluator INFO: Inference done 4440/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:33
[09/29 15:46:16] d2.evaluation.evaluator INFO: Inference done 4471/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0230 s/iter. Total: 0.1664 s/iter. ETA=0:01:28
[09/29 15:46:21] d2.evaluation.evaluator INFO: Inference done 4502/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:01:22
[09/29 15:46:26] d2.evaluation.evaluator INFO: Inference done 4534/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:01:17
[09/29 15:46:31] d2.evaluation.evaluator INFO: Inference done 4565/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:01:12
[09/29 15:46:37] d2.evaluation.evaluator INFO: Inference done 4595/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:01:07
[09/29 15:46:42] d2.evaluation.evaluator INFO: Inference done 4625/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:01:02
[09/29 15:46:47] d2.evaluation.evaluator INFO: Inference done 4656/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:57
[09/29 15:46:52] d2.evaluation.evaluator INFO: Inference done 4687/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:52
[09/29 15:46:57] d2.evaluation.evaluator INFO: Inference done 4717/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:47
[09/29 15:47:02] d2.evaluation.evaluator INFO: Inference done 4748/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:41
[09/29 15:47:07] d2.evaluation.evaluator INFO: Inference done 4778/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:36
[09/29 15:47:12] d2.evaluation.evaluator INFO: Inference done 4809/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:31
[09/29 15:47:17] d2.evaluation.evaluator INFO: Inference done 4841/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1662 s/iter. ETA=0:00:26
[09/29 15:47:22] d2.evaluation.evaluator INFO: Inference done 4871/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0229 s/iter. Total: 0.1663 s/iter. ETA=0:00:21
[09/29 15:47:27] d2.evaluation.evaluator INFO: Inference done 4903/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0228 s/iter. Total: 0.1662 s/iter. ETA=0:00:16
[09/29 15:47:32] d2.evaluation.evaluator INFO: Inference done 4933/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0228 s/iter. Total: 0.1662 s/iter. ETA=0:00:11
[09/29 15:47:38] d2.evaluation.evaluator INFO: Inference done 4963/5000. Dataloading: 0.0015 s/iter. Inference: 0.1419 s/iter. Eval: 0.0228 s/iter. Total: 0.1663 s/iter. ETA=0:00:06
[09/29 15:47:43] d2.evaluation.evaluator INFO: Inference done 4993/5000. Dataloading: 0.0014 s/iter. Inference: 0.1419 s/iter. Eval: 0.0228 s/iter. Total: 0.1663 s/iter. ETA=0:00:01
[09/29 15:47:44] d2.evaluation.evaluator INFO: Total inference time: 0:13:50.458024 (0.166258 s / iter per device, on 1 devices)
[09/29 15:47:44] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:11:48 (0.141942 s / iter per device, on 1 devices)
[09/29 15:47:44] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[09/29 15:47:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[09/29 15:48:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.191 | 0.308  | 0.231  | 0.227 | 0.203 | 0.026 |
[09/29 15:48:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.994 | bicycle      | 0.003 | car            | 0.307 |
| motorcycle    | 0.023 | airplane     | 0.023 | bus            | 0.002 |
| train         | 0.000 | truck        | 0.022 | boat           | 0.009 |
| traffic light | 0.123 | fire hydrant | 0.000 | stop sign      | 1.836 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.002 | horse          | 0.003 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.011 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.594 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 9.725 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.001 | wine glass   | 0.000 | cup            | 0.372 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.637 | banana       | 0.000 | apple          | 0.014 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.074 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.445 | toilet       | 0.000 | tv             | 0.009 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.003 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.005 | toaster      | 0.000 | sink           | 0.001 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.009 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[09/29 15:48:37] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.209 | 0.291  | 0.247  | 0.248 | 0.243 | 0.017 |
[09/29 15:48:37] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP     |
|:--------------|:------|:-------------|:------|:---------------|:-------|
| person        | 0.889 | bicycle      | 0.000 | car            | 0.500  |
| motorcycle    | 0.006 | airplane     | 0.000 | bus            | 0.000  |
| train         | 0.000 | truck        | 0.007 | boat           | 0.002  |
| traffic light | 0.131 | fire hydrant | 0.000 | stop sign      | 2.110  |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000  |
| cat           | 0.000 | dog          | 0.004 | horse          | 0.000  |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000  |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000  |
| backpack      | 0.000 | umbrella     | 0.014 | handbag        | 0.000  |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.792  |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 10.908 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000  |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000  |
| bottle        | 0.002 | wine glass   | 0.000 | cup            | 0.427  |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000  |
| bowl          | 0.738 | banana       | 0.000 | apple          | 0.014  |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000  |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.074  |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000  |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000  |
| dining table  | 0.082 | toilet       | 0.000 | tv             | 0.011  |
| laptop        | 0.000 | mouse        | 0.001 | remote         | 0.003  |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000  |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.001  |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.008  |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000  |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |        |
[09/29 15:48:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[09/29 15:48:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/29 15:48:38] d2.evaluation.testing INFO: copypaste: 0.1906,0.3076,0.2310,0.2267,0.2027,0.0261
[09/29 15:48:38] d2.evaluation.testing INFO: copypaste: Task: segm
[09/29 15:48:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[09/29 15:48:38] d2.evaluation.testing INFO: copypaste: 0.2091,0.2905,0.2474,0.2478,0.2426,0.0166
[09/29 16:30:40] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 16:30:41] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 16:30:41] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 16:30:41] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 16:30:41] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 16:30:41] d2.utils.env INFO: Using a generated random seed 44584086
[09/29 16:30:42] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 16:30:42] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 16:30:43] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/29 16:30:43] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/29 16:30:43] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 16:30:44] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 16:30:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 16:30:44] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 16:30:44] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 16:30:44] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 16:30:44] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 16:30:45] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 16:39:27] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 16:39:27] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 16:39:27] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 16:39:27] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 16:39:27] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 16:39:27] d2.utils.env INFO: Using a generated random seed 31392649
[09/29 16:39:28] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 16:39:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 16:39:29] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/29 16:39:29] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/29 16:39:29] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 16:39:30] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 16:39:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 16:39:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 16:39:30] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 16:39:30] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 16:39:30] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 16:39:30] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 16:44:12] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 16:44:12] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 16:44:12] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 16:44:12] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 16:44:12] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 16:44:12] d2.utils.env INFO: Using a generated random seed 16149152
[09/29 16:44:13] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 16:44:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 16:44:14] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.blocks.0.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.0.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.1.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.10.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.11.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.2.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.3.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.4.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.5.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.6.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.7.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.8.mlp.layers.1.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.0.{bias, weight}[0m
[34mbackbone.bottom_up.blocks.9.mlp.layers.1.{bias, weight}[0m
[09/29 16:44:14] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[09/29 16:44:14] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 16:44:14] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 16:44:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 16:44:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 16:44:14] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 16:44:15] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 16:44:15] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 16:44:15] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:34:04] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:34:04] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:34:04] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:34:04] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:34:04] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:34:04] d2.utils.env INFO: Using a generated random seed 8260230
[09/29 17:34:05] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:34:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:34:06] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:34:07] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:34:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:34:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:34:07] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:34:07] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:34:07] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:34:07] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:35:55] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:35:55] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:35:55] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:35:55] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:35:55] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:35:55] d2.utils.env INFO: Using a generated random seed 59384388
[09/29 17:35:56] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:35:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:35:57] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:35:58] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:35:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:35:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:35:58] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:35:58] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:35:58] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:35:58] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:37:09] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:37:10] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:37:10] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:37:10] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:37:10] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:37:10] d2.utils.env INFO: Using a generated random seed 13920362
[09/29 17:37:11] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:37:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:37:12] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:37:12] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:37:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:37:12] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:37:12] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:37:13] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:37:13] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:37:13] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:40:16] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:40:17] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:40:17] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:40:17] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:40:17] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:40:17] d2.utils.env INFO: Using a generated random seed 20964944
[09/29 17:40:18] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:40:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:40:19] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:40:19] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:40:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:40:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:40:19] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:40:19] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:40:19] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:40:20] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:42:10] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:42:11] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:42:11] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:42:11] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:42:11] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:42:11] d2.utils.env INFO: Using a generated random seed 14902565
[09/29 17:42:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:42:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:42:13] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:42:13] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:42:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:42:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:42:13] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:42:13] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:42:13] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:42:14] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:43:20] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:43:21] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:43:21] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:43:21] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:43:21] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:43:21] d2.utils.env INFO: Using a generated random seed 24585617
[09/29 17:43:21] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:43:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:43:22] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:43:23] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:43:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:43:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:43:23] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:43:26] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:43:26] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:43:27] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:48:26] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:48:26] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:48:26] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:48:26] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:48:26] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:48:26] d2.utils.env INFO: Using a generated random seed 30292793
[09/29 17:48:27] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:48:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:48:28] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:48:28] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:48:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:48:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:48:28] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:48:29] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:48:29] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:48:29] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:49:10] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:49:10] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:49:10] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:49:10] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:49:10] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:49:10] d2.utils.env INFO: Using a generated random seed 14386921
[09/29 17:49:11] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:49:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:49:12] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:49:13] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:49:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:49:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:49:13] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:49:15] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:49:15] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:49:15] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:50:09] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:50:09] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:50:09] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:50:09] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:50:09] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:50:09] d2.utils.env INFO: Using a generated random seed 13140083
[09/29 17:50:10] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:50:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:50:11] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:50:11] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:50:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:50:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:50:11] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:50:11] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:50:12] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:50:12] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 17:52:24] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 17:52:24] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 17:52:24] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 17:52:24] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 17:52:24] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 17:52:24] d2.utils.env INFO: Using a generated random seed 28281765
[09/29 17:52:25] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:52:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 17:52:26] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 17:52:26] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 17:52:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 17:52:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 17:52:26] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 17:52:27] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 17:52:28] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 17:52:28] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/29 20:30:35] detectron2 INFO: Rank of current process: 0. World size: 1
[09/29 20:30:36] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/29 20:30:36] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/29 20:30:36] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/29 20:30:36] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/29 20:30:36] d2.utils.env INFO: Using a generated random seed 39527717
[09/29 20:30:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 20:30:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/29 20:30:38] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/29 20:30:38] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/29 20:30:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/29 20:30:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/29 20:30:38] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/29 20:30:38] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/29 20:30:38] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/29 20:30:39] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/30 23:47:17] detectron2 INFO: Rank of current process: 0. World size: 1
[09/30 23:47:18] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/30 23:47:18] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/30 23:47:18] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/30 23:47:18] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/30 23:47:18] d2.utils.env INFO: Using a generated random seed 22381499
[09/30 23:47:19] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/30 23:47:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/30 23:47:20] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/30 23:47:20] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/30 23:47:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/30 23:47:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/30 23:47:20] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/30 23:47:22] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/30 23:47:22] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/30 23:47:23] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[09/30 23:48:27] detectron2 INFO: Rank of current process: 0. World size: 1
[09/30 23:48:28] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[09/30 23:48:28] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[09/30 23:48:28] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[09/30 23:48:28] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[09/30 23:48:28] d2.utils.env INFO: Using a generated random seed 32287050
[09/30 23:48:29] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/30 23:48:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[09/30 23:48:29] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[09/30 23:48:30] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[09/30 23:48:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[09/30 23:48:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[09/30 23:48:30] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[09/30 23:48:30] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[09/30 23:48:30] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[09/30 23:48:30] d2.evaluation.evaluator INFO: Start inference on 5000 batches
[10/01 00:03:39] detectron2 INFO: Rank of current process: 0. World size: 1
[10/01 00:03:40] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/01 00:03:40] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[10/01 00:03:40] detectron2 INFO: Contents of args.config_file=./projects/Hiera/configs/mask_rcnn_hiera_abs_win_t_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone.hiera_abs_win import HieraAbsWin

from .common.coco_loader_lsj import dataloader

model = model_zoo.get_config("common/models/mask_rcnn_fpn.py").model
constants = model_zoo.get_config("common/data/constants.py").constants
model.pixel_mean = constants.imagenet_rgb256_mean
model.pixel_std = constants.imagenet_rgb256_std
model.input_format = "RGB"
model.backbone.bottom_up = L(HieraAbsWin)(
    model_name = "mae_hiera_abs_win_tiny_224",
    img_size=1024,
    embed_dim=96,
    num_heads=1,
    stages=(1, 2, 7, 2),
    out_features=["stage_0", "stage_1", "stage_2", "stage_3"],
)

model.backbone.in_features = "${.bottom_up.out_features}"

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512"
train.bottom_up_ckpt = '/home/s108061519/hiera_moe//logs/in1k_mae/mae_hiera_abs_win_tiny_512/epoch-epoch=99.ckpt'
dataloader.train.total_batch_size = 32

# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[10/01 00:03:40] detectron2 INFO: Full config saved to /home/lynuc/hiera_multi_scale/output/mask_rcnn_hiera_abs_win_t_512/config.yaml
[10/01 00:03:40] d2.utils.env INFO: Using a generated random seed 44212431
[10/01 00:03:41] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[10/01 00:03:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[10/01 00:03:42] d2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[10/01 00:03:42] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[10/01 00:03:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[10/01 00:03:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/01 00:03:42] d2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[10/01 00:03:43] d2.data.common INFO: Serialized dataset takes 19.10 MiB
[10/01 00:03:43] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[10/01 00:03:43] d2.evaluation.evaluator INFO: Start inference on 5000 batches

[10/01 17:44:38] detectron2 INFO: Rank of current process: 1. World size: 2
[10/01 17:44:38] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 18:27:27) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/home/lynuc/hiera_multi_scale/detectron2-hiera-MoE-hiera/detectron2
detectron2._C                    not built correctly: No module named 'detectron2._C'
Compiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
CUDA compiler                    Not found
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce GTX 1080 (arch=6.1)
Driver version                   550.78
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision
torchvision arch flags           /home/lynuc/miniconda3/envs/test/lib/python3.12/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                           0.1.5.post20221221
iopath                           0.1.10
cv2                              4.10.0
-------------------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/01 17:44:38] detectron2 INFO: Command line arguments: Namespace(config_file='./projects/HieraDet/configs/mask_rcnn_hieradet_b_plus_512.py', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50175', opts=['train.init_checkpoint=/home/lynuc/model_0079999.pth'])
[10/01 17:44:38] detectron2 INFO: Contents of args.config_file=./projects/HieraDet/configs/mask_rcnn_hieradet_b_plus_512.py:
from functools import partial
from fvcore.common.param_scheduler import MultiStepParamScheduler

from detectron2 import model_zoo
from detectron2.config import LazyCall as L
from detectron2.layers import ShapeSpec
from detectron2.modeling.meta_arch import GeneralizedRCNN
from detectron2.modeling.anchor_generator import DefaultAnchorGenerator
from detectron2.modeling.backbone.fpn import LastLevelMaxPool
from detectron2.modeling.backbone import BasicStem, FPN, ResNet
from detectron2.modeling.box_regression import Box2BoxTransform
from detectron2.modeling.matcher import Matcher
from detectron2.modeling.poolers import ROIPooler
from detectron2.modeling.roi_heads import (
    StandardROIHeads,
    FastRCNNOutputLayers,
    MaskRCNNConvUpsampleHead,
    FastRCNNConvFCHead,
)

from detectron2.modeling.proposal_generator import RPN, StandardRPNHead

from detectron2.solver import WarmupParamScheduler
from detectron2.modeling.backbone.vit import get_vit_lr_decay_rate
from detectron2.modeling.backbone import HieraDet, FpnNeck_HieraDet, ImageEncoder_HieraDet

from sam2.modeling.position_encoding import PositionEmbeddingSine

from .common.coco_loader_lsj import dataloader

constants = model_zoo.get_config("common/data/constants.py").constants


model = L(GeneralizedRCNN)(
    backbone=L(ImageEncoder_HieraDet)(
        trunk=L(HieraDet)(
            embed_dim=112,
            num_heads=2,
            stages=(2, 3, 16, 3),
        ),
        neck=L(FpnNeck_HieraDet)(
            position_encoding=PositionEmbeddingSine(
                num_pos_feats=256,
                normalize=True,
                temperature=10000,
            ),
            d_model=256,
            backbone_channel_list=[896, 448, 224, 112],
            fpn_top_down_levels= [2, 3],
            fpn_interp_model = 'bicubic'
        )
    ),
    proposal_generator=L(RPN)(
        in_features=["stage_0", "stage_1", "stage_2", "stage_3"],
        head=L(StandardRPNHead)(in_channels=256, num_anchors=3),
        anchor_generator=L(DefaultAnchorGenerator)(
            sizes=[[32], [64], [128], [256], [512]],
            aspect_ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64],
            offset=0.0,
        ),
        anchor_matcher=L(Matcher)(
            thresholds=[0.3, 0.7], labels=[0, -1, 1], allow_low_quality_matches=True
        ),
        box2box_transform=L(Box2BoxTransform)(weights=[1.0, 1.0, 1.0, 1.0]),
        batch_size_per_image=256,
        positive_fraction=0.5,
        pre_nms_topk=(2000, 1000),
        post_nms_topk=(1000, 1000),
        nms_thresh=0.7,
    ),
    roi_heads=L(StandardROIHeads)(
        num_classes=80,
        batch_size_per_image=512,
        positive_fraction=0.25,
        proposal_matcher=L(Matcher)(
            thresholds=[0.5], labels=[0, 1], allow_low_quality_matches=False
        ),
        box_in_features=["stage_0", "stage_1", "stage_2", "stage_3"],
        box_pooler=L(ROIPooler)(
            output_size=7,
            scales=(1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32),
            sampling_ratio=0,
            pooler_type="ROIAlignV2",
        ),
        box_head=L(FastRCNNConvFCHead)(
            input_shape=ShapeSpec(channels=256, height=7, width=7),
            conv_dims=[],
            fc_dims=[1024, 1024],
        ),
        box_predictor=L(FastRCNNOutputLayers)(
            input_shape=ShapeSpec(channels=1024),
            test_score_thresh=0.05,
            box2box_transform=L(Box2BoxTransform)(weights=(10, 10, 5, 5)),
            num_classes="${..num_classes}",
        ),
        mask_in_features=["stage_0", "stage_1", "stage_2", "stage_3"],
        mask_pooler=L(ROIPooler)(
            output_size=14,
            scales=(1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32),
            sampling_ratio=0,
            pooler_type="ROIAlignV2",
        ),
        mask_head=L(MaskRCNNConvUpsampleHead)(
            input_shape=ShapeSpec(channels=256, width=14, height=14),
            num_classes="${..num_classes}",
            conv_dims=[256, 256, 256, 256, 256],
        ),
    ),
    pixel_mean=constants.imagenet_rgb256_mean,
    pixel_std=constants.imagenet_rgb256_std,
    input_format="RGB",
)

# Initialization and trainer settings
train = model_zoo.get_config("common/train.py").train
train.amp.enabled = True
train.ddp.fp16_compression = True
#train.init_checkpoint = "/media/Pluto/andy/detectron2/projects/Hiera/init_ckpt/hiera_official/mae_hiera_tiny_224-model_state.pth"
# train.output_dir = "./output/mask_rcnn_hieradet_b_plus_512"
# train.trunk_ckpt = '/home/s108061519/hiera_moe/logs/in1k_mae/mae_hiera_base_plus_512/epoch-epoch=259.ckpt'
dataloader.train.total_batch_size = 1
train.init_checkpoint = "/home/lynuc/model_0079999.pth"
train.output_dir = "/home/lynuc/hiera_multi_scale/output/mask_rcnn_hieradet_b_plus_512"
train.trunk_ckpt = '/home/lynuc/last.ckpt'


# 36 epochs
train.max_iter = 67500 * 64 // dataloader.train.total_batch_size
lr_multiplier = L(WarmupParamScheduler)(
    scheduler=L(MultiStepParamScheduler)(
        values=[1.0, 0.1, 0.01],
        milestones=[52500, 62500, 67500],
    ),
    warmup_length=250 / train.max_iter,
    warmup_factor=0.001,
)

optimizer = model_zoo.get_config("common/optim.py").AdamW
optimizer.params.overrides = {
    "pos_embed": {"weight_decay": 0.0},
    "rel_pos_h": {"weight_decay": 0.0},
    "rel_pos_w": {"weight_decay": 0.0},
}
optimizer.lr = 1.6e-4

[10/01 17:44:38] detectron2.utils.env INFO: Using a generated random seed 42593942
[10/01 17:44:39] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/lynuc/model_0079999.pth ...
[10/01 17:44:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/lynuc/model_0079999.pth ...
[10/01 17:44:39] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.neck.convs.0.conv.{bias, weight}[0m
[34mbackbone.neck.convs.1.conv.{bias, weight}[0m
[34mbackbone.neck.convs.2.conv.{bias, weight}[0m
[34mbackbone.neck.convs.3.conv.{bias, weight}[0m
[34mbackbone.trunk.blocks.0.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.0.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.0.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.0.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.0.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.0.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.1.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.1.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.1.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.1.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.1.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.1.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.10.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.10.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.10.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.10.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.10.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.10.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.11.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.11.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.11.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.11.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.11.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.11.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.12.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.12.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.12.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.12.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.12.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.12.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.13.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.13.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.13.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.13.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.13.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.13.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.14.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.14.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.14.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.14.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.14.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.14.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.15.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.15.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.15.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.15.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.15.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.15.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.16.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.16.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.16.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.16.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.16.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.16.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.17.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.17.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.17.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.17.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.17.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.17.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.18.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.18.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.18.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.18.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.18.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.18.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.19.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.19.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.19.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.19.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.19.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.19.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.2.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.20.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.20.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.20.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.20.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.20.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.20.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.21.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.22.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.22.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.22.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.22.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.22.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.22.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.23.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.23.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.23.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.23.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.23.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.23.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.3.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.3.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.3.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.3.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.3.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.3.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.4.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.4.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.4.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.4.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.4.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.4.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.5.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.6.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.6.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.6.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.6.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.6.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.6.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.7.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.7.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.7.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.7.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.7.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.7.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.8.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.8.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.8.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.8.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.8.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.8.norm2.{bias, weight}[0m
[34mbackbone.trunk.blocks.9.attn.proj.{bias, weight}[0m
[34mbackbone.trunk.blocks.9.attn.qkv.{bias, weight}[0m
[34mbackbone.trunk.blocks.9.mlp.fc1.{bias, weight}[0m
[34mbackbone.trunk.blocks.9.mlp.fc2.{bias, weight}[0m
[34mbackbone.trunk.blocks.9.norm1.{bias, weight}[0m
[34mbackbone.trunk.blocks.9.norm2.{bias, weight}[0m
[34mbackbone.trunk.patch_embed.proj.{bias, weight}[0m
[34mbackbone.trunk.{pos_embed, pos_embed_window}[0m
[10/01 17:44:39] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mbackbone.fpn_lateral2.{bias, weight}[0m
  [35mbackbone.fpn_output2.{bias, weight}[0m
  [35mbackbone.fpn_lateral3.{bias, weight}[0m
  [35mbackbone.fpn_output3.{bias, weight}[0m
  [35mbackbone.fpn_lateral4.{bias, weight}[0m
  [35mbackbone.fpn_output4.{bias, weight}[0m
  [35mbackbone.fpn_lateral5.{bias, weight}[0m
  [35mbackbone.fpn_output5.{bias, weight}[0m
  [35mbackbone.bottom_up.{pos_embed, pos_embed_window}[0m
  [35mbackbone.bottom_up.patch_embed.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.0.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.1.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.2.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.3.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.4.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.5.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.6.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.7.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.8.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.9.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.mlp.fc2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.10.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.norm1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.attn.qkv.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.attn.proj.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.norm2.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc1.{bias, weight}[0m
  [35mbackbone.bottom_up.blocks.11.mlp.fc2.{bias, weight}[0m
[10/01 17:44:40] detectron2.data.datasets.coco INFO: Loaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[10/01 17:44:40] detectron2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[10/01 17:44:40] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333)]
[10/01 17:44:40] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/01 17:44:40] detectron2.data.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[10/01 17:44:40] detectron2.data.common INFO: Serialized dataset takes 19.10 MiB
[10/01 17:44:40] detectron2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[10/01 17:44:41] detectron2.evaluation.evaluator INFO: Start inference on 2500 batches
[10/01 17:44:50] detectron2.evaluation.evaluator INFO: Inference done 11/2500. Dataloading: 0.0010 s/iter. Inference: 0.2287 s/iter. Eval: 0.0005 s/iter. Total: 0.2301 s/iter. ETA=0:09:32
[10/01 17:44:55] detectron2.evaluation.evaluator INFO: Inference done 33/2500. Dataloading: 0.0013 s/iter. Inference: 0.2311 s/iter. Eval: 0.0006 s/iter. Total: 0.2331 s/iter. ETA=0:09:34
[10/01 17:45:00] detectron2.evaluation.evaluator INFO: Inference done 54/2500. Dataloading: 0.0013 s/iter. Inference: 0.2350 s/iter. Eval: 0.0005 s/iter. Total: 0.2368 s/iter. ETA=0:09:39
[10/01 17:45:05] detectron2.evaluation.evaluator INFO: Inference done 75/2500. Dataloading: 0.0013 s/iter. Inference: 0.2355 s/iter. Eval: 0.0004 s/iter. Total: 0.2373 s/iter. ETA=0:09:35
[10/01 17:45:10] detectron2.evaluation.evaluator INFO: Inference done 98/2500. Dataloading: 0.0014 s/iter. Inference: 0.2330 s/iter. Eval: 0.0004 s/iter. Total: 0.2348 s/iter. ETA=0:09:24
[10/01 17:45:15] detectron2.evaluation.evaluator INFO: Inference done 119/2500. Dataloading: 0.0014 s/iter. Inference: 0.2351 s/iter. Eval: 0.0004 s/iter. Total: 0.2369 s/iter. ETA=0:09:24
[10/01 17:45:21] detectron2.evaluation.evaluator INFO: Inference done 140/2500. Dataloading: 0.0014 s/iter. Inference: 0.2368 s/iter. Eval: 0.0004 s/iter. Total: 0.2387 s/iter. ETA=0:09:23
[10/01 17:45:26] detectron2.evaluation.evaluator INFO: Inference done 161/2500. Dataloading: 0.0014 s/iter. Inference: 0.2375 s/iter. Eval: 0.0004 s/iter. Total: 0.2393 s/iter. ETA=0:09:19
[10/01 17:45:31] detectron2.evaluation.evaluator INFO: Inference done 182/2500. Dataloading: 0.0014 s/iter. Inference: 0.2383 s/iter. Eval: 0.0004 s/iter. Total: 0.2401 s/iter. ETA=0:09:16
[10/01 17:45:36] detectron2.evaluation.evaluator INFO: Inference done 203/2500. Dataloading: 0.0014 s/iter. Inference: 0.2395 s/iter. Eval: 0.0004 s/iter. Total: 0.2413 s/iter. ETA=0:09:14
[10/01 17:45:42] detectron2.evaluation.evaluator INFO: Inference done 224/2500. Dataloading: 0.0014 s/iter. Inference: 0.2403 s/iter. Eval: 0.0004 s/iter. Total: 0.2421 s/iter. ETA=0:09:11
[10/01 17:45:47] detectron2.evaluation.evaluator INFO: Inference done 245/2500. Dataloading: 0.0014 s/iter. Inference: 0.2402 s/iter. Eval: 0.0004 s/iter. Total: 0.2420 s/iter. ETA=0:09:05
[10/01 17:45:52] detectron2.evaluation.evaluator INFO: Inference done 266/2500. Dataloading: 0.0014 s/iter. Inference: 0.2403 s/iter. Eval: 0.0004 s/iter. Total: 0.2421 s/iter. ETA=0:09:00
[10/01 17:45:57] detectron2.evaluation.evaluator INFO: Inference done 286/2500. Dataloading: 0.0014 s/iter. Inference: 0.2409 s/iter. Eval: 0.0004 s/iter. Total: 0.2428 s/iter. ETA=0:08:57
[10/01 17:46:02] detectron2.evaluation.evaluator INFO: Inference done 307/2500. Dataloading: 0.0014 s/iter. Inference: 0.2409 s/iter. Eval: 0.0004 s/iter. Total: 0.2428 s/iter. ETA=0:08:52
[10/01 17:46:07] detectron2.evaluation.evaluator INFO: Inference done 328/2500. Dataloading: 0.0014 s/iter. Inference: 0.2411 s/iter. Eval: 0.0004 s/iter. Total: 0.2429 s/iter. ETA=0:08:47
[10/01 17:46:12] detectron2.evaluation.evaluator INFO: Inference done 348/2500. Dataloading: 0.0014 s/iter. Inference: 0.2419 s/iter. Eval: 0.0004 s/iter. Total: 0.2437 s/iter. ETA=0:08:44
[10/01 17:46:17] detectron2.evaluation.evaluator INFO: Inference done 369/2500. Dataloading: 0.0014 s/iter. Inference: 0.2417 s/iter. Eval: 0.0003 s/iter. Total: 0.2434 s/iter. ETA=0:08:38
[10/01 17:46:22] detectron2.evaluation.evaluator INFO: Inference done 389/2500. Dataloading: 0.0014 s/iter. Inference: 0.2424 s/iter. Eval: 0.0003 s/iter. Total: 0.2442 s/iter. ETA=0:08:35
[10/01 17:46:27] detectron2.evaluation.evaluator INFO: Inference done 410/2500. Dataloading: 0.0014 s/iter. Inference: 0.2427 s/iter. Eval: 0.0003 s/iter. Total: 0.2445 s/iter. ETA=0:08:30
[10/01 17:46:33] detectron2.evaluation.evaluator INFO: Inference done 431/2500. Dataloading: 0.0014 s/iter. Inference: 0.2426 s/iter. Eval: 0.0004 s/iter. Total: 0.2444 s/iter. ETA=0:08:25
[10/01 17:46:38] detectron2.evaluation.evaluator INFO: Inference done 452/2500. Dataloading: 0.0014 s/iter. Inference: 0.2427 s/iter. Eval: 0.0004 s/iter. Total: 0.2445 s/iter. ETA=0:08:20
[10/01 17:46:43] detectron2.evaluation.evaluator INFO: Inference done 472/2500. Dataloading: 0.0014 s/iter. Inference: 0.2430 s/iter. Eval: 0.0004 s/iter. Total: 0.2448 s/iter. ETA=0:08:16
